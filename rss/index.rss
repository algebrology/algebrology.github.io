<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/" version="2.0"><channel><title>Algebrology</title><description>A gentle introduction to insanity.</description><link>http://localhost:2368/</link><generator>Ghost 0.11</generator><lastBuildDate>Mon, 03 Apr 2017 01:29:26 GMT</lastBuildDate><atom:link href="http://localhost:2368/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title>Mathematical Induction</title><description>In mathematics, we come across patterns all the time. For instance, here's a pattern you may have noticed before...</description><link>http://localhost:2368/mathematical-induction/</link><guid isPermaLink="false">f697003e-520c-45c6-8f3e-72cbe20e0f5a</guid><dc:creator>Eric Shapiro</dc:creator><pubDate>Sun, 02 Apr 2017 22:53:45 GMT</pubDate><content:encoded>&lt;h3 id="contents"&gt;Contents&lt;/h3&gt;

&lt;p&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href="http://localhost:2368/mathematical-induction/#the-axiom-of-choice-and-well-ordering-principle"&gt;The axiom of choice and well-ordering principle&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="http://localhost:2368/mathematical-induction/#the-principle-of-mathematical-induction"&gt;The principle of mathematical induction&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="http://localhost:2368/mathematical-induction/#examples"&gt;Examples&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;hr&gt;

&lt;p&gt;This post is a much needed break from my steady stream of posts concerning topology. Before my next post on bases for topologies, I need to introduce a proof technique that I haven't used so far.&lt;/p&gt;

&lt;p&gt;In mathematics, we come across patterns all the time. For instance, here's a pattern you may have noticed before:&lt;/p&gt;

&lt;p&gt;$$\begin{align}
1       = 1\phantom{0}  &amp;amp;= 1^2 \\ &lt;br&gt;
1+3     = 4\phantom{0}  &amp;amp;= 2^2 \\ &lt;br&gt;
1+3+5   = 9\phantom{0}  &amp;amp;= 3^2 \\ &lt;br&gt;
1+3+5+7 = 16 &amp;amp;= 4^2 \\ &lt;br&gt;
&amp;amp;\phantom{0}\vdots \\
1+3+5+7+\dotsc +(2n+1) &amp;amp;= n^2 &lt;br&gt;
\end{align}$$&lt;/p&gt;

&lt;p&gt;It turns out that for any natural number $n$, if you add the first $n$ odd numbers the result is always $n^2$. (Remember that the $n$th odd number is $2n-1$.) Here's a visual depiction of the pattern:&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/sum_of_odds-2.svg" alt=""&gt;&lt;/p&gt;

&lt;p&gt;From this image, it is evident that adding together the first $n$ odd numbers literally results in a square of side length $n$. But how can we come up with a convincing argument that this pattern always holds? In answering this question, we will discuss a method that can also be applied to many other similar problems.&lt;/p&gt;

&lt;h3 id="theaxiomofchoiceandwellorderingprincipleanametheaxiomofchoiceandwellorderingprinciple"&gt;The axiom of choice and well-ordering principle&lt;a name="the-axiom-of-choice-and-well-ordering-principle"&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;Before we start, I should mention that you cannot do a proof by induction unless you accept the &lt;strong&gt;axiom of choice&lt;/strong&gt;. The axiom of choice is an extra axiom of set theory which is somewhat controversial (among mathematicians). This is because at first glance it seems obviously true, but it actually leads to some bizarre and unexpected results.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Axiom of Choice.&lt;/strong&gt; Suppose $I$ is an indexing set and $C$ is a collection of nonempty sets $X_i$ for each $i\in I$. Then there exists a function $f:C\to\bigcup\limits_{i\in I} X_i$ such that $f(X_i)\in X_i$ for every $i$.&lt;/p&gt;

&lt;p&gt;In simpler words, the axiom of choice ensures that, given any number of nonempty sets, it is possible to choose precisely one element from each set. This is probably something you never would have dreamt was controversial, and it certainly seems like a natural assumption, but as I said before it allows for some strange results.&lt;/p&gt;

&lt;p&gt;For instance, it leads to the &lt;strong&gt;Banach-Tarski Paradox&lt;/strong&gt;, that is, the fact that given a solid ball in three dimensions ($\mathbb{R}^3$), it is possible to break the ball up into a finite number of disjoint pieces and rearrange these pieces using rigid transformations into two solid balls which are each identical to the original. This is perhaps at least slightly suspicious.&lt;/p&gt;

&lt;p&gt;I'm always going to assume the axiom of choice, mostly because I like it and it makes a lot of proofs considerably easier. Sometimes it is the only thing that makes proofs possible at all, like the proof of the principle of mathematical induction. Which I promise I'm getting to.&lt;/p&gt;

&lt;p&gt;For this proof, we're going to need the axiom of choice in a slightly different form. This form is actually so commonly referred to that it even has a special name. The axiom of choice is equivalent to the statement that any set can be well-ordered. I'm not going to go into orderings right now, but I will state what this means for the natural numbers because we'll need to use it in our proof.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Well-Ordering Principle.&lt;/strong&gt; Any nonempty set of natural numbers contains a least element.&lt;/p&gt;

&lt;p&gt;This assumes the ordering you're familiar with for the natural numbers. You know, the one where $0&amp;lt;1&amp;lt;2&amp;lt;3$ and so on. This only holds because the natural numbers are bounded below. That is, there is a smallest natural number: $0$. If we wanted to extend this principle to the integers, we'd have to add the condition that our nonempty set of integers has a lower bound.&lt;/p&gt;

&lt;p&gt;The well-ordering principle should hopefully seem very obvious to you as well, and I'm not going to show how it implies the principle of mathematical induction.&lt;/p&gt;

&lt;h3 id="theprincipleofmathematicalinductionanametheprincipleofmathematicalinduction"&gt;The principle of mathematical induction&lt;a name="the-principle-of-mathematical-induction"&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;I'll stop beating around the bush and just do the thing already.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;strong&gt;Principle of Mathematical Induction.&lt;/strong&gt; Suppose P(n) is a (true/false) statement about a natural number $n$, and that the following two criteria hold:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Base Case:&lt;/strong&gt; $P(0)$ is true.  &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Inductive Step:&lt;/strong&gt; If $P(n)$ is true for some $n\in\mathbb{N}$ then so is $P(n+1)$.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Then $P(n)$ is true for every $n\in\mathbb{N}$.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; We give a proof by contradiction. That is, we're going to assume that the statement is false and show that this leads to an absurd result. We will then be forced to accept the principle of mathematical induction because we will have shown that it cannot be false.&lt;/p&gt;

&lt;p&gt;Suppose then that both criteria hold, but that $P$ is not true for at least one natural number. Let $S$ denote the set of natural numbers for which $P$ is false. By assumption, $S$ is not empty, so the well-ordering theorem tells us that $S$ contains a least element. Call this element $x$. Then $x-1\notin S$ since $x$ is the smallest element of $S$. That is, $P(x)$ is false but $P(x-1)$ is true. However, the second criterion tells us that $P\big((x-1)+1\big)=P(x)$ must be true. This is a contradiction, since $P(x)$ cannot be simultaneously true and false. It follows that $P(n)$ is true for every natural number $n$.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;The proof is not terribly important, so don't spend too much time dissecting it. What really matters to us is the statement itself, which might seem daunting at first, so let's break it down piece by piece.&lt;/p&gt;

&lt;p&gt;We start off with a statement which is either true or false depending on what number we feed it. The following are examples of such statements&lt;sup id="fnref:1"&gt;&lt;a href="http://localhost:2368/mathematical-induction/#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;$P(n):=n$ is a prime number.&lt;/li&gt;
&lt;li&gt;$Q(n):=n$ sandwiches are on fire.&lt;/li&gt;
&lt;li&gt;$R(n):=1+3+5+\dotsc+(2n-1)=n^2$.&lt;/li&gt;
&lt;li&gt;$S(n):=$ the $n$th domino will fall over.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If we want to show that such a statement is true for all natural numbers, we must first verify the base case, which means showing that if we set $n=1$ then the resulting statement is true. This is usually the easy part of a proof by induction, but it is still necessary.&lt;/p&gt;

&lt;p&gt;The last thing we have to do is show that if the statement holds for an arbitrary natural number $n$, then the statement also holds for $n+1$. This is the inductive step, which is usually where the most work and insight are needed.&lt;/p&gt;

&lt;p&gt;If we can do these two things, then we have shown that the statement is true for every natural number! Just remember: base case, then inductive step. Now let's look more closely at the example statements from above:&lt;/p&gt;

&lt;p&gt;By definition, $P(n)$ is true only when $n$ is prime. For instance, $P(1)$ is false because $1$ is not prime, but $P(2)$ is true because $2$ is prime.&lt;/p&gt;

&lt;p&gt;On the other hand, $Q(n)$ is presumably false for all $n&gt;0$. I, for one, have never seen an exploding sandwich.&lt;/p&gt;

&lt;p&gt;$R(n)$ is the same statement we discussed earlier: that the sum of the first $n$ odd numbers is $n^2$. We will come back to this in a few moments and show it to be true for any $n$ using an inductive argument.&lt;/p&gt;

&lt;p&gt;For now, let's focus on $S(n)$ because it is a helpful and illustrative example of why induction works. Suppose we have a line of dominoes extending infinitely to the right, all standing up and close enough together that if one falls over it will hit the next domino in line:&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/dominoes-1.svg" alt="line of dominoes"&gt;&lt;/p&gt;

&lt;p&gt;What are the base case and inductive step for this example? The base case would be $S(1)$, which corresponds to whether or not the first domino will be knocked over. The inductive step is the fact that, if the $n$th domino falls, then the $(n+1)$th domino will also fall. The inductive step is clearly true because each domino knocks over the next one when it falls. However, if the first domino is never knocked over, none of the other ones will be either. This illustrates the importance of the base case! If the base case does not hold, then a proof by induction is invalid even if the inductive step does hold.&lt;/p&gt;

&lt;p&gt;So in other words, if we know for certain that the first domino will fall, this means that &lt;em&gt;every&lt;/em&gt; domino will fall because we have verified both the base case and the inductive step.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/dominoes_falling.svg" alt="dominoes falling"&gt;&lt;/p&gt;

&lt;p&gt;The argument we have just given shows an infinite number of things to be true! This is part of the power of inductive arguments.&lt;/p&gt;

&lt;h3 id="examplesanameexamples"&gt;Examples&lt;a name="examples"&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;Let's now prove that the pattern I introduced at beginning of this post always holds.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; For any $n\geq 1$,&lt;/p&gt;

&lt;p&gt;$$1+3+5+\dotsc+(2n-1)=n^2.$$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; We give a proof by induction on $n$.&lt;/p&gt;

&lt;p&gt;For our base case, we need to show that the statement is true when we let $n=1$. This is simple enough, because $1$ is certainly the sum of the first $1$ odd numbers, and it is equal to its square. That is, $1=1^2$, so we have shown that our base case is true.&lt;/p&gt;

&lt;p&gt;Now for the inductive step. We will assume that&lt;/p&gt;

&lt;p&gt;$$1+3+5+\dotsc+(2n-1)=n^2,$$&lt;/p&gt;

&lt;p&gt;and use this to show that &lt;/p&gt;

&lt;p&gt;$$1+3+5+\dotsc+(2n-1)+(2n+1)=(n+1)^2.$$&lt;/p&gt;

&lt;p&gt;This requires a tiny bit of algebraic manipulation, but isn't at all difficult:&lt;/p&gt;

&lt;p&gt;$$\begin{align}
1+3+5+\dotsc+(2n-1)+(2n+1) &amp;amp;= n^2+(2n+1) \\ &lt;br&gt;
                           &amp;amp;= (n+1)^2.
\end{align}$$&lt;/p&gt;

&lt;p&gt;In the first step above, we used our assumption that the sum of the first $n$ odd numbers is $n^2$ and substituted this result into the equation. In the second step, we factored our resulting quadratic, and subsequently showed that our inductive step holds.&lt;/p&gt;

&lt;p&gt;It follows from the principle of mathematical induction that our assertion is true.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;This proof is a good indicator of a trend that such proofs tend to follow. If we can show that the base case is true, we can frequently break down the statement for higher numbers into smaller pieces and then use our base case to glue everything back together.&lt;/p&gt;

&lt;p&gt;In my first post on set theory, I stated without proof that De Morgan's Laws extend to arbitrary collections of sets. I still won't prove that in full, but I'll prove something that's nearly as powerful.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; Let $A_1,A_2,\dotsc,A_n\subseteq X$. Then&lt;/p&gt;

&lt;p&gt;$$X-\bigcup\limits_{i=1}^n A_i=\bigcap\limits_{i=1}^n (X-A_i).$$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; We proceed by induction on $n$. For our base case, we choose $n=2$. That is, we need to show that&lt;/p&gt;

&lt;p&gt;$$X-(A_1\cup A_2)=(X-A_1)\cap (X-A_2).$$&lt;/p&gt;

&lt;p&gt;But this is just one of De Morgan's Laws, which we already know to be true! So we don't actually have to do any work to establish that the first criterion holds.&lt;/p&gt;

&lt;p&gt;Next, let $n\geq 2$ be a natural number and suppose that&lt;/p&gt;

&lt;p&gt;$$X-\bigcup\limits_{i=1}^n A_i=\bigcap\limits_{i=1}^n (X-A_i).$$&lt;/p&gt;

&lt;p&gt;It is easy to see that &lt;/p&gt;

&lt;p&gt;$$\begin{align}
X-\bigcup\limits_{i=1}^{n+1}A_i &amp;amp;= X-\left(\bigcup\limits_{i=1}^nA_i\cup A_{n+1}\right) \\ &lt;br&gt;
&amp;amp;= \left(X-\bigcup\limits_{i=1}^nA_i\right)\cap (X-A_{n+1}) \\
&amp;amp;= \bigcap\limits_{i=1}^n(X-A_i)\cap(X-A_{n+1}) \\
&amp;amp;= \bigcap\limits_{i=1}^{n+1}(X-A_i).
\end{align}$$&lt;/p&gt;

&lt;p&gt;This completes the proof.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;Let's look at another example. This is one of my favorites, and it lends itself nicely to a visual representation.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; A $2^n\times 2^n$ checkerboard can be covered by L-shaped tiles, with the exception of one arbitrary square.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Let's break down this statement a little bit first. When we talk about a $2^n\times 2^n$ checkerboard, we are talking about a square board with sides of length $2^n$. So&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;$n=1$ corresponds to the $2\times 2$ board,&lt;/li&gt;
&lt;li&gt;$n=2$ corresponds to the $4\times 4$ board,&lt;/li&gt;
&lt;li&gt;$n=3$ corresponds to the $8\times 8$ board, etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For instance, here is the $2^3\times 2^3$ checkerboard:&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/2-3_x_2-3_board.svg" alt="2^3 by 2^3 board"&gt;&lt;/p&gt;

&lt;p&gt;By 'L-shaped tile,' we mean a tile comprised of three squares which is shaped sort of like the letter L:&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/L_shaped_tile-1.svg" alt="L-shaped tile"&gt;&lt;/p&gt;

&lt;p&gt;Lastly, when we say that a board can be covered by these tiles with the exception of one arbitrary square, we mean something like this:&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/tiled_4x4_board.svg" alt="tiled 4 by 4 board"&gt;&lt;/p&gt;

&lt;p&gt;It's important to point out that we could have left out &lt;em&gt;any&lt;/em&gt; one square on the board above and still been able to tile the rest of the board. It does not matter which square we choose to exclude; we should still be able to cover the rest of the board. Try playing around with boards of different sizes, leaving one random square empty, and trying to come up with such a tiling. For larger boards, this quickly becomes no easy task.&lt;/p&gt;

&lt;p&gt;Now that we have a better understanding of the problem, it is our goal to show that we can cover any $2^n\times 2^n$ board in this manner, and we will do so by induction on $n$.&lt;/p&gt;

&lt;p&gt;For our base case ($n=1$), we must show that the $2\times 2$ board can be tiled by L-shaped tiles, no matter which square we choose to omit. Since there are only four squares on this board, we can 'brute-force' the base case by demonstrating that with any square missing, the rest of the board can be tiled quite trivially using a single L-shaped tile:&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/base_case.svg" alt="base case"&gt;&lt;/p&gt;

&lt;p&gt;We have shown that any $2\times 2$ board can be covered in the desired manner, so the base case has been verified.&lt;/p&gt;

&lt;p&gt;Next we argue the inductive step. We begin with the assumption that for an arbitrary $n\geq 1$, we can cover the $2^n\times 2^n$ checkerboard (with any one arbitrary square omitted) as desired. We must use this information to show that we can then tile the $2^{n+1}\times 2^{n+1}$ board in the same manner.&lt;/p&gt;

&lt;p&gt;Notice that if we are given a $2^{n+1}\times 2^{n+1}$ board, the missing tile will necessarily lie in precisely one of its four quadrants:&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/quadrants.svg" alt="quadrants"&gt;&lt;/p&gt;

&lt;p&gt;But each of these quadrants is actually a $2^n\times 2^n$ board, which we already know can be covered! So one of our quadrants has a missing tile already chosen for us, and the other three quadrants we can cover however we choose. So we do so in the following crafty way:&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/quadrants_tiled.svg" alt="quadrants tiled"&gt;&lt;/p&gt;

&lt;p&gt;We've now covered the entire $2^{n+1}\times 2^{n+1}$ board with the exception of our arbitrary missing square and a nice L-shaped hole in the middle, which we can fill in with a single L-shaped tile, leaving only the chosen square uncovered. We have thus shown that the inductive step holds, completing the proof.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;I think that's more than enough for one post, so I'm going to leave it at that. We will be using induction for many of our future proofs, though, so this won't be the last time you'll see it!&lt;/p&gt;

&lt;hr&gt;

&lt;div class="footnotes"&gt;&lt;ol&gt;&lt;li class="footnote" id="fn:1"&gt;&lt;p&gt;The symbol $:=$ means 'is defined as.' &lt;a href="http://localhost:2368/mathematical-induction/#fnref:1" title="return to article"&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;</content:encoded></item><item><title>A First Look at Topological Spaces</title><description>So far we've put a lot of effort into defining notions of distance, even giving these ideas fancy names. Distance is an important property...</description><link>http://localhost:2368/a-first-look-at-topological-spaces/</link><guid isPermaLink="false">74b6fe0d-1ee4-43a7-84ab-fa241c6a2c06</guid><dc:creator>Eric Shapiro</dc:creator><pubDate>Fri, 31 Mar 2017 17:01:23 GMT</pubDate><content:encoded>&lt;h3 id="contents"&gt;Contents&lt;/h3&gt;

&lt;p&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href="http://localhost:2368/a-first-look-at-topological-spaces/#motivation"&gt;Motivation&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="http://localhost:2368/a-first-look-at-topological-spaces/#the-definition"&gt;The definition&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="http://localhost:2368/a-first-look-at-topological-spaces/#examples"&gt;Examples&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;hr&gt;

&lt;h3 id="motivationanamemotivation"&gt;Motivation&lt;a name="motivation"&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;So far we've put a lot of effort into defining notions of distance, even giving these ideas fancy names. Distance is an important property in many situations, and you probably don't need me telling you this because you think about distances every day.&lt;/p&gt;

&lt;p&gt;However, there are also many circumstances in which we care about the shape of a space but couldn't care less about distances. For instance, a famous puzzle that influenced the development of the entire field of topology is the problem of the &lt;strong&gt;Seven Bridges of Königsberg&lt;/strong&gt;. Basically, the city of Königsberg had two major islands at its center, completely disconnected from the mainland by a river except for seven bridges.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/bridges.svg" alt="bridges of Königsberg"&gt;&lt;/p&gt;

&lt;p&gt;Here is my &lt;em&gt;beautiful&lt;/em&gt; depiction of the scenario. It should be obvious from my exceptional artistic ability, but the blue crud is the river and the grey smudges are the bridges. For a far inferior — though perhaps more descriptive — picture of the problem, I suggest a Google Image search.&lt;/p&gt;

&lt;p&gt;The puzzle is as follows: &lt;strong&gt;Is it possible to walk across every bridge precisely once without getting wet?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Try drawing a couple paths and you'll quickly begin to suspect that the answer is no. This is correct, but proving it is tricky. The solution to a problem like this has nothing whatsoever to do with the distance between bridges. Stretch the river, move the bridges slightly, and the solution remains the same. This indicates that there may be more fundamental properties intrinsic to the space in this puzzle than distance.&lt;/p&gt;

&lt;p&gt;The branch of mathematics called &lt;strong&gt;topology&lt;/strong&gt; is, loosely speaking, the study of the properties of space which remain unaltered by continuous deformations. This probably sounds kind of like poo at this point, but bear with me. Continuous deformations are, intuitively, ways in which we can stretch, bend and move objects but not tear or cut them. As an example, an egg and a pancake are in some sense topologically equivalent, since you can squish an egg down until it becomes sufficiently cake-shaped. You won't even see this idea again for a while, but I find it helps to have some idea of where we're headed in the long run.&lt;/p&gt;

&lt;h3 id="thedefinitionanamethedefinition"&gt;The definition&lt;a name="the-definition"&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;Before we proceed, let's recall a few of the nice properties I've previously showed are true of open sets in metric spaces:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The empty set and the space itself are open.&lt;/li&gt;
&lt;li&gt;The union of any collection of open sets is open.&lt;/li&gt;
&lt;li&gt;The intersection of any finite collection of open sets is open.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As I mentioned before, we need to trash any definitions we have that mention metrics or distances, so the old definition of open sets in a metric space won't work for the more general topological spaces. What we do instead is kind of neat.&lt;/p&gt;

&lt;p&gt;We define a topology in terms of which sets are open, and these open sets must obey certain properties. Actually, they must obey the properties I just listed! These properties talk about open sets only in terms of set theory, and never mention distance, so we simply demand that all of these properties hold.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; A &lt;strong&gt;topology&lt;/strong&gt; $\cal T$ on a set $X$ is a collection of subsets of $X$ called &lt;strong&gt;open sets&lt;/strong&gt; which satisfy the following properties.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;The empty set $\varnothing$ and the set $X$ are in $\cal T$.  &lt;/li&gt;
&lt;li&gt;The union of any collection of sets in $\cal T$ is in $\cal T$.  &lt;/li&gt;
&lt;li&gt;The intersection of any finite collection of sets in $\cal T$ is in $\cal T$.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;A &lt;strong&gt;topological space&lt;/strong&gt; is a set $X$ together with a topology $\cal T$ on $X$.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;As a slight abuse of notation, the set $X$ will usually be referred to as a topological space, and it will go without saying that we're talking about some topology on $X$. This is much the same as when we talk about a set as a metric space and it is implicitly understood to have some distance function.&lt;/p&gt;

&lt;p&gt;This probably all feels a bit anticlimactic. I've been building up to this for a while, and it probably seems like this isn't anything new at all. At first, it might seem odd to define a topological space as a collection of sets that are open, but it's actually fairly natural. Hopefully at the very least you understand why the three properties in the definition are a natural choice. I spent the last two posts trying to get it to feel that way.&lt;/p&gt;

&lt;p&gt;There is a sort of topological analogue to the concept in metric spaces of an open ball centered at a point:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; A &lt;strong&gt;neighborhood&lt;/strong&gt; of a point $x$ in a topological space is an open set containing $x$.&lt;/p&gt;

&lt;p&gt;And of course, whenever there are open sets there are also closed sets:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; A subset $U$ of a topological space $X$ is &lt;strong&gt;closed&lt;/strong&gt; in $X$ if its complement, $X-U$, is open.&lt;/p&gt;

&lt;p&gt;Notice again that sets in a topological space can be open, closed, both or neither. In every topological space $X$, we have that $\varnothing$ and $X$ are both open and closed. This information is now part of the very definition of open and closed sets!&lt;/p&gt;

&lt;h3 id="examplesanameexamples"&gt;Examples&lt;a name="examples"&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;I haven't been including terribly many examples so far, so I should probably try to fix that. Most people don't learn too well being relentlessly bombarded by definitions and theorems and not ever having an opportunity to step back and apply what they've just learned.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; Consider the set $X=\{a,b,c\}$ with just three elements. Let's determine whether the following is a valid topology on $X$:&lt;/p&gt;

&lt;p&gt;$${\cal T} = \big\{\varnothing,\{a\}, \{a,b\}, \{a,b,c\}\big\}$$&lt;/p&gt;

&lt;p&gt;Let's look at this topology visually:&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/top-abc-1.svg" alt="example topology"&gt;&lt;/p&gt;

&lt;p&gt;The ellipses in this diagram depict the open sets in the topology. Each ellipse is a subset of all the ellipses that encompass it. The empty set is a subset of every set and is not depicted.&lt;/p&gt;

&lt;p&gt;Even without the picture, it's easy to verify that all the required properties hold and that this is a topology on $X$. If you take the union of any collection of these open sets, you wind up with another open set in the topology. The same is true of intersections. (We could list out all such unions and intersections, but that would take up too much space.) The empty set and $X$ itself are explicitly listed and so clearly they are open, and thus $\cal T$ is indeed a topology on $X$.&lt;/p&gt;

&lt;p&gt;One last thing: the set $\{b\}$ in this topological space is neither open nor closed, as an example of what I was saying before.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;There are two topologies that we can define right off the bat on any set $X$.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; The &lt;strong&gt;trivial topology&lt;/strong&gt; on $X$ is the set $\{\varnothing, X\}$.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; The &lt;strong&gt;discrete topology&lt;/strong&gt; on $X$ is the set $2^X$ of all subsets of $X$.&lt;/p&gt;

&lt;p&gt;The trivial topology only has two&lt;sup id="fnref:1"&gt;&lt;a href="http://localhost:2368/a-first-look-at-topological-spaces/#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt; open sets, and it is in a sense the smallest topology we can define because those sets are required to be open by the definition of a topology. On the other hand, every set is open in the discrete topology, so it is in some sense the largest. Let's make rigorous these notions by defining the concepts of coarseness and fineness.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; Given two topologies ${\cal T}_1, {\cal T}_2$ on a set $X$, we say that ${\cal T}_1$ is &lt;strong&gt;coarser&lt;/strong&gt; than ${\cal T}_2$ if ${\cal T}_1\subseteq {\cal T}_2$. That is, every open set in ${\cal T}_1$ is also open in ${\cal T}_2$. Equivalently, we also sometimes say that ${\cal T}_2$ is &lt;strong&gt;finer&lt;/strong&gt; than ${\cal T}_1$.&lt;/p&gt;

&lt;p&gt;Notice that the trivial topology is always the coarsest topology we can define, and the discrete topology is always the finest. Also notice that there can exist topologies on a set that cannot be compared with each other in this way because it is possible for each topology to contain open sets that are not contained in the other.&lt;/p&gt;

&lt;p&gt;Here's just one more example for now, and this should hopefully feel a lot like the "correct" definition to you. We can still talk about open balls in $\mathbb{R}^n$ purely as the sets $B(x_0,r)=\{x\in\mathbb{R}^n\mid d(x,x_0)&amp;lt; r\}$. We can define a topology using these that is very similar to the standard metric on $\mathbb{R}^n$:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; The &lt;strong&gt;standard topology&lt;/strong&gt; on $\mathbb{R}^n$ is the topology whose nonempty open sets are precisely the unions of open balls in $\mathbb{R}^n$.&lt;/p&gt;

&lt;p&gt;The last thing I want to mention right now is that our definition of a topological space is broad. So broad, in fact, that many such spaces often behave in ways that are not at all desirable. Very frequently, we will talk about certain "tame" types of topological spaces. For instance, soon I'll introduce you to Hausdorff spaces, which have a number of nice properties that we'd generally expect "space" to have.&lt;/p&gt;

&lt;p&gt;Next time we'll look again at some more properties of metric spaces. Fair warning: the next post is where things will start getting fairly technical, so make sure you're really comfortable with everything I've discussed so far!&lt;/p&gt;

&lt;hr&gt;

&lt;div class="footnotes"&gt;&lt;ol&gt;&lt;li class="footnote" id="fn:1"&gt;&lt;p&gt;Unless $X=\varnothing$, in which case it only has one and is particularly uninteresting. &lt;a href="http://localhost:2368/a-first-look-at-topological-spaces/#fnref:1" title="return to article"&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;</content:encoded></item><item><title>Metric Spaces (2)</title><description>Looking back through my first post about metric spaces, it occurred to me that I should probably have emphasized a few things that could be a bit confusing.</description><link>http://localhost:2368/metric-spaces-2/</link><guid isPermaLink="false">632ca07f-d7e1-4903-87c3-0700039bf796</guid><dc:creator>Eric Shapiro</dc:creator><pubDate>Fri, 31 Mar 2017 14:42:15 GMT</pubDate><content:encoded>&lt;h3 id="contents"&gt;Contents&lt;/h3&gt;

&lt;p&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href="http://localhost:2368/metric-spaces-2/#review-from-previous-post"&gt;Review from previous post&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="http://localhost:2368/metric-spaces-2/#open-sets"&gt;Open sets&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="http://localhost:2368/metric-spaces-2/#closed-sets"&gt;Closed sets&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="http://localhost:2368/metric-spaces-2/#now-what"&gt;Now what?&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;hr&gt;

&lt;h3 id="reviewfrompreviouspostanamereviewfrompreviouspost"&gt;Review from previous post&lt;a name="review-from-previous-post"&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;Looking back through my first post about metric spaces, it occurred to me that I should probably have emphasized a few things that could be a bit confusing, so let me address those first before pressing forward. &lt;/p&gt;

&lt;p&gt;I briefly mentioned the &lt;strong&gt;standard metric&lt;/strong&gt; on $\mathbb{R}^n$ ($n$-dimensional Euclidean space), but I didn't relate it back to anything concrete. I defined this metric by&lt;/p&gt;

&lt;p&gt;$$d({\bf x},{\bf y})=\sqrt{\sum\limits_{i=1}^n(x_i-y_i)^2},$$&lt;/p&gt;

&lt;p&gt;where ${\bf x},{\bf y}\in\mathbb{R}^n$. For $n=1$, this whole thing collapses down to&lt;/p&gt;

&lt;p&gt;$$d(x,y)=\sqrt{(x-y)^2}=\vert x-y\vert,$$&lt;/p&gt;

&lt;p&gt;where $x,y\in\mathbb{R}$. Thus, the standard metric in one-dimensional Euclidean space is precisely the distance function that motivated the entirety of my last post. Moreover, the open balls $B(x,r)$ in this metric are open intervals of the form $(x-r,x+r)$. I'm sure you can figure out for yourself what the closed balls are.&lt;/p&gt;

&lt;p&gt;For ${\bf x},{\bf y}\in\mathbb{R}^2$, where ${\bf x}=(x_1,x_2)$ and ${\bf y}=(y_1,y_2)$, the standard metric becomes&lt;/p&gt;

&lt;p&gt;$$d({\bf x},{\bf y})=\sqrt{(x_1-y_1)^2+(x_2-y_2)^2}.$$&lt;/p&gt;

&lt;p&gt;This is the distance function we all saw in high school, and it's easy enough to verify that it is, in fact, a metric. However, it's somewhat challenging to show that the standard metric satisfied the properties of a metric for Euclidean spaces of arbitrary dimension, so I won't do that here.&lt;/p&gt;

&lt;p&gt;I also want to be clear that the standard metric isn't even close to the only metric we can define. In fact, we can define the following metric on any set at all:&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; Let $X$ be a metric space. The &lt;strong&gt;discrete metric&lt;/strong&gt; on $X$ is specified by&lt;/p&gt;

&lt;p&gt;$$d(a,b)=
\begin{cases}
0 &amp;amp; \text{if } a=b,\\ &lt;br&gt;
1 &amp;amp; \text{if } a\neq b &lt;br&gt;
\end{cases}$$&lt;/p&gt;

&lt;p&gt;where $a,b\in X$.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;It's easy to show that the discrete metric is in fact a metric. Furthermore, we can actually use the discrete metric as a basis to generate an infinite number of metrics on any set! (How?)&lt;/p&gt;

&lt;p&gt;There are less trivial metrics, too. For instance, if $X$ is the set of real-valued functions which are continuous on the closed interval $[a,b]$, then&lt;/p&gt;

&lt;p&gt;$$d(f,g)=\int\limits_0^1\vert f(x)-g(x)\vert\mathrm{d}x,$$&lt;/p&gt;

&lt;p&gt;where $f,g\in X$, is a metric on $X$. If this example is gibberish to you, don't worry. I haven't defined integration, or even continuity, yet. I just wanted to show that there are even meaningful concepts of distance between functions, which is an enticing concept.&lt;/p&gt;

&lt;p&gt;I think that's about all I wanted to clarify from last time. Now we can move on to some more exciting new stuff!&lt;/p&gt;

&lt;h3 id="opensetsanameopensets"&gt;Open sets&lt;a name="open-sets"&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;We already defined open sets in the last post, but let's restate that definition here so you don't have to go looking it up:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; A subset $U$ of a metric space $X$ is &lt;strong&gt;open&lt;/strong&gt; in $X$ if for every point $x\in U$ there exists a real number $r&gt;0$ for which the open ball $B(x,r)\subseteq U$.&lt;/p&gt;

&lt;p&gt;I didn't explicitly say this last time, but this definition for open sets applies only for metric spaces. When we talk about the more general topological spaces, we'll have to throw out this definition (although it will serve to motivate the general definition).&lt;/p&gt;

&lt;p&gt;Now, armed only with this definition and a few notions from set theory, we can already say quite a bit about open sets.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; The union of any collection of open sets in a metric space is open.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Let $X$ denote a metric space and let $I$ be an indexing set such that $A_i\subseteq X$ is an open set for each $i\in I$. Define $U=\bigcup\limits_{i\in I}A_i$.&lt;/p&gt;

&lt;p&gt;If every $A_i$ is empty then $U=\varnothing$, which is open. So if this is the case, then we're done.&lt;/p&gt;

&lt;p&gt;Suppose then that $U\neq\varnothing$. We need to show that for any $x\in U$, there exists a real number $r&gt;0$ for which $B(x,r)\subseteq U$. But this is extremely easy!&lt;/p&gt;

&lt;p&gt;Since $x\in U$, we know from the definition of the union operation that $x\in A_j$ for some $j\in I$. Since $A_j$ is open by assumption, there exists a real number $r_j&gt;0$ such that $B(x,r_j)\subseteq A_j$. Since every point in $A_j$ is also in $U$, choosing $r=r_j$ gives us that $B(x,r)\subseteq U$.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;This is an important property, so never forget it. Also notice that essentially all we had to do in the above proof was notice that, for each point in the union, we already had an open ball that served our purposes.&lt;/p&gt;

&lt;p&gt;Next, let's prove a similar result:&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; The intersection of a finite collection of open sets in a metric space is open.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Let $X$ denote a metric space and let $A_1,A_2,\dotsc,A_n\subseteq X$ be open sets for some $n\in\mathbb{N}$. Define $I=\bigcap\limits_{i=1}^n A_i$.&lt;/p&gt;

&lt;p&gt;First, consider the case where the intersection $I$ is empty. If this is true, then we're done since the empty set is open.&lt;/p&gt;

&lt;p&gt;Suppose then that $I\neq\varnothing$. We need to show that for every $x\in I$ there exists some real number $r&gt;0$ for which $B(x,r)\subseteq I$. This time the choice of $r$ isn't quite so obvious, but hopefully my reasoning is clear. (If it isn't, try drawing a picture!)&lt;/p&gt;

&lt;p&gt;Since $x\in I$, the point $x$ is in every set $A_1,A_2,\dotsc,A_n$. Since each of these sets is open, there exist real numbers $r_1,r_2,\dotsc,r_n&gt;0$ such that&lt;/p&gt;

&lt;p&gt;$$B(x,r_1)\subseteq A_1, \\
  B(x,r_2)\subseteq A_2, \\
  \vdots                  \\
  B(x,r_n)\subseteq A_n.$$&lt;/p&gt;

&lt;p&gt;Since there are only a finite number of sets, simply picking the smallest radius, that is, $r=\min\limits_{1\leq i\leq n} r_i$, will ensure that $B(x,r)\subseteq A_i$ for $1\leq i\leq n$. It follows immediately that $B(x,r)\subseteq I$.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;Hopefully you're wondering why I only argued that a &lt;em&gt;finite&lt;/em&gt; intersection of open sets is open. After all, I showed that an infinite union work, and unions and intersections are pretty similar, right? Well, not really. In fact, I can easily come up with an example of an infinite collection of open sets whose intersection isn't open:&lt;/p&gt;

&lt;p&gt;Consider $\mathbb{R}$ equipped with the standard metric, and the infinite collection of open intervals defined by $A_n=\left(-\frac{1}{n},\frac{1}{n}\right)$ for $n\in\mathbb{N}$. It's easy enough to see that $\bigcap\limits_{n=1}^\infty \left(-\frac{1}{n},\frac{1}{n}\right)=\{0\}$. For any $x&gt;0$, the quantity $\frac{1}{n}$ eventually becomes smaller than $x$ as $n$ grows larger, so the only point common to all these sets is $0$ because $\frac{1}{n}\neq 0$ for any $n\in\mathbb{N}$, no matter how large.&lt;sup id="fnref:1"&gt;&lt;a href="http://localhost:2368/metric-spaces-2/#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt; The set $\{0\}$ is not open because no open ball of positive radius is contained within it.&lt;/p&gt;

&lt;h3 id="closedsetsanameclosedsets"&gt;Closed sets&lt;a name="closed-sets"&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;Again, we defined closed sets last time, but we'll restate their definition here as well for convenience:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; A subset $U$ of a metric space $X$ is &lt;strong&gt;closed&lt;/strong&gt; in $X$ if its complement, $X-U$, is open in $X$.&lt;/p&gt;

&lt;p&gt;Let's pause for a second to think about what this means in terms of open balls. This definition tells us that $U$ is closed when any point that it not in $U$ is at the center of some open ball which is disjoint from $U$. This is the concept we used in the last post to prove that a closed ball was closed.&lt;/p&gt;

&lt;p&gt;Now we're going to prove two theorems about closed sets that closely mirror the theorems about open sets that we just proved above. Rather than go through a similar process of trying to find a radius which works, we'll make use of the previous results and apply De Morgan's Laws.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; The union of a finite collection of closed sets in a metric space is closed.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Let $X$ denote a metric space and let $A_1,A_2,\dotsc,A_n\subseteq X$ be closed sets for some $n\in\mathbb{N}$. From the definition of a closed set we see immediately that their complements, $X-A_1$, $X-A_2$, $\dotsc$, $X-A_n$ are each open. Since the intersection of a finite number of open sets is open,&lt;/p&gt;

&lt;p&gt;$$\bigcap\limits_{i=1}^n (X-A_i)=X-\bigcup\limits_{i=1}^n A_i$$&lt;/p&gt;

&lt;p&gt;is open by De Morgan's Laws. Since the complement of an open set is closed, we have that $\bigcup\limits_{i=1}^n A_i$ is closed, and we are done.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;Hopefully by now you can see the next theorem coming from a mile away, simply from the symmetry of things. I'll prove it anyway for completeness.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; The intersection of any collection of closed sets in a metric space is closed.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Let $$ denote a metric space and let $I$ be an indexing set such that $A_i\subseteq X$ is a closed set for each $i\in I$. Then the complement of each set, $X-A_i$, is open for every $i\in I$. Since the union of an arbitrary collection of open sets is open,&lt;/p&gt;

&lt;p&gt;$$\bigcup\limits_{i\in I} (X-A_i)=X-\bigcap\limits_{i\in I}A_i$$&lt;/p&gt;

&lt;p&gt;is open by De Morgan's Laws. Therefore its complement, $\bigcap\limits_{i\in I}A_i$, is closed, completing the proof.&lt;/p&gt;

&lt;hr&gt;

&lt;h3 id="nowwhatanamenowwhat"&gt;Now what?&lt;a name="now-what"&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;What's fairly awesome is that we now actually know everything we need to know about open and closed sets. Well, not really. But we &lt;em&gt;do&lt;/em&gt; know enough now to take another leap forward and define a &lt;strong&gt;topology&lt;/strong&gt; on a set! I'm not going to do that right now, though. Instead I'm going to show you that everything we've done so far is really perfectly natural, in that it gives us the results we'd expect when talking about familiar sets.&lt;/p&gt;

&lt;p&gt;Let's first look at the set of real numbers. To be formal, I'm talking about $\mathbb{R}$ equipped with the standard metric $d(x,y)=\vert x-y\vert$. I think I said this earlier, but unless I say otherwise you should always assume that I'm talking about the standard metric whenever I say words about the real numbers. I asserted above that the open balls in this metric space are open intervals. That is,&lt;/p&gt;

&lt;p&gt;$$\begin{align}
B(x,r) &amp;amp;= \{x\in\mathbb{R}\mid d(x,y)&amp;lt; r\} \\ &lt;br&gt;
       &amp;amp;= (x-r,x+r).
\end{align}$$&lt;/p&gt;

&lt;p&gt;What are the simplest open sets in this metric space? We'll talk about this in a more formal sense when we discuss bases for topologies, but it turns out that in a very real sense, these open intervals are the fundamental building blocks for all open sets on the real number line. That is, any nonempty open set in $\mathbb{R}$ can actually be written as the union of some collection of open intervals!&lt;/p&gt;

&lt;p&gt;This may seem obvious, but it's actually a very nice property. I'll give you a hand-wavy reason why it's true. The definition of an open set is that every point in the set is at the center of some open ball which is, in turn, contained entirely in the set. So if we take any open set and union together the largest such open balls centered at each point, we really ought to get our entire open set!&lt;/p&gt;

&lt;p&gt;In the plane, $\mathbb{R}^2$ or $\mathbb{C}$, the same is true. However, we're now talking about the standard metric in two dimensions, so open balls look like open disks instead of open line segments. Nonempty open sets in the plane can all be formed by joining together these open balls. Even open &lt;em&gt;rectangles&lt;/em&gt; can be expressed as unions of open balls.&lt;/p&gt;

&lt;p&gt;An &lt;strong&gt;open rectangle&lt;/strong&gt; is the Cartesian product of two open intervals, say $(a,b)\times(c,d)$. The proof that they are open is similar to the proof that open balls are open, and it is not particularly informative so I won't include it . here. But I think it's pretty neat that even the &lt;em&gt;corners&lt;/em&gt; of these rectangles can be expressed as the union of a bunch of sufficiently small open balls. What might be even more interesting is that open rectangles can alternatively be thought as the primitive open sets in the plane, and you can get any open set by unioning rectangles together. That includes open balls!&lt;/p&gt;

&lt;p&gt;In my next post I'll finally define topological spaces. It will likely be fairly short, since we don't have much to say about them yet, but it will at least give you a sense of what we'll be working with from here on out. From then on, I'll probably alternate between metric spaces and topological spaces. It's usually easiest to introduce topological concepts such as convergence, continuity, connectedness and compactness in terms of metric spaces first, and then take what we need from those definitions to talk about them in the more general setting of topological spaces.&lt;/p&gt;

&lt;hr&gt;

&lt;div class="footnotes"&gt;&lt;ol&gt;&lt;li class="footnote" id="fn:1"&gt;&lt;p&gt;Technically I should have used the Archimedian property of the real numbers to show this, but it's extremely obvious and not particularly necessary for any of our other purposes. After all, this isn't a post about analysis or the foundations of the real number system. &lt;a href="http://localhost:2368/metric-spaces-2/#fnref:1" title="return to article"&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;</content:encoded></item><item><title>Metric Spaces (1)</title><description>Taken by themselves, sets do not have much structure to them. They are essentially barren wastelands with no relationships at all between their elements.</description><link>http://localhost:2368/metric-spaces-1/</link><guid isPermaLink="false">01099326-6fc1-4271-a4cb-4791eb439f72</guid><dc:creator>Eric Shapiro</dc:creator><pubDate>Fri, 31 Mar 2017 02:51:53 GMT</pubDate><content:encoded>&lt;h3 id="contents"&gt;Contents&lt;/h3&gt;

&lt;p&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href="http://localhost:2368/metric-spaces-1/#motivation"&gt;Motivation&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="http://localhost:2368/metric-spaces-1/#metrics"&gt;Metrics&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="http://localhost:2368/metric-spaces-1/#open-and-closed-sets"&gt;Open and closed sets&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;hr&gt;

&lt;p&gt;Taken by themselves, sets do not have much structure to them. They are essentially barren wastelands with no relationships at all between their elements. In this post we will remedy that by defining a way to add a measure of proximity to the points in a set.&lt;/p&gt;

&lt;h3 id="motivationanamemotivation"&gt;Motivation&lt;a name="motivation"&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;First, I'd like to motivate the definition of a metric space a little bit. Recall the set $\mathbb{R}$ of real numbers. Given two numbers $a,b\in\mathbb{R}$ with $a&amp;lt; b$, we make the following definitions:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; The &lt;strong&gt;open interval&lt;/strong&gt; with endpoints $a$ and $b$ is the set $(a,b)=\{x\in\mathbb{R}\mid a&amp;lt; x&amp;lt; b\}$.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; The &lt;strong&gt;closed interval&lt;/strong&gt; with endpoints $a$ and $b$ is the set $[a,b]=\{x\in\mathbb{R}\mid a\leq x\leq b\}$.&lt;/p&gt;

&lt;p&gt;Notice how the only difference between these two types of intervals is that the closed interval includes its endpoints whereas the open interval does not. You've no doubt been exposed to these definitions before so there isn't terribly much to discuss, but these will be our prototypes for the concepts of open and closed sets.&lt;/p&gt;

&lt;p&gt;How do we measure the distance between two real numbers? We would like our distance to always be positive, so we take whichever number is higher and subtract it from the lower number. If we don't know which number is higher or we want to make a general statement, we make use of the &lt;strong&gt;absolute value function&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;$$\vert x \vert=
\begin{cases}
x  &amp;amp; \text{if } x\geq 0,\\ &lt;br&gt;
-x &amp;amp; \text{if } x&amp;lt;0.
\end{cases}$$&lt;/p&gt;

&lt;p&gt;Notice that $\vert -x \vert = \vert x \vert$ for every $x\in\mathbb{R}$. Armed with this function which always returns a positive value, we can rephrase our notion of distance between real numbers $a$ and $b$. We'll call this distance $\vert a - b \vert$. The order in which the points appear no longer matters, which is a good sign.&lt;/p&gt;

&lt;p&gt;Now let's explore some of the very nice properties of this distance function we've just defined.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;$\vert a-b \vert \geq 0$ for all $a,b\in\mathbb{R}$.  &lt;/li&gt;
&lt;li&gt;$\vert a-b \vert = 0$ if and only if $a=b$.  &lt;/li&gt;
&lt;li&gt;$\vert a-b \vert = \vert b-a \vert$ for all $a,b\in\mathbb{R}$.  &lt;/li&gt;
&lt;li&gt;$\vert a-c \vert \leq \vert a-b \vert + \vert b-c \vert$ for all $a,b,c\in\mathbb{R}$.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The first three properties above should be somewhat obvious, and I will not bother proving them. The fourth property is known as the &lt;strong&gt;triangle inequality&lt;/strong&gt;, and it is very important so I will prove it in two different ways so you'll have to believe it twice as hard.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; Let $a,b$ and $c$ denote real numbers. Then $\vert a-c \vert \leq \vert a-b \vert + \vert b-c \vert$.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Proof 1.&lt;/strong&gt; From the definition of the absolute value function, we have the following two facts:&lt;/p&gt;

&lt;p&gt;$$-\vert a-b\vert\leq a-b\leq\vert a-b\vert,$$
$$-\vert b-c\vert\leq b-c\leq\vert b-c\vert.$$&lt;/p&gt;

&lt;p&gt;Adding together these two inequalities, we see that &lt;/p&gt;

&lt;p&gt;$$-\vert a-b\vert-\vert b-c\vert\leq (a-b)+(b-c)\leq\vert a-b\vert+\vert b-c\vert,$$&lt;/p&gt;

&lt;p&gt;which simplifies to&lt;/p&gt;

&lt;p&gt;$$-\big(\vert a-b\vert+\vert b-c\vert\big)\leq a-c\leq\vert a-b\vert+\vert b-c\vert.$$&lt;/p&gt;

&lt;p&gt;If we use the definition of the absolute value function yet again, it follows that $\vert a-c\vert\leq\vert a-b\vert+\vert b-c\vert$, as desired.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Proof 2.&lt;/strong&gt; We proceed directly by the following computation:&lt;/p&gt;

&lt;p&gt;$$\begin{aligned} 
\vert a-c\vert^2 &amp;amp;=\big\vert (a-b)+(b-c)\big\vert^2\\
&amp;amp;= \big((a-b)+(b-c)\big)\big((a-b)+(b-c)\big)\\
&amp;amp;=(a-b)^2+2(a-b)(b-c)+(b-c)^2\\
&amp;amp;=\vert a-b\vert^2+2(a-b)(b-c)+\vert b-c\vert^2\\
&amp;amp;\leq \vert a-b\vert^2+2\vert a-b\vert\vert b-c\vert+\vert b-c\vert^2\\
&amp;amp;=\big(\vert a-b\vert+\vert b-c\vert\big)^2.
\end{aligned}$$&lt;/p&gt;

&lt;p&gt;Taking the positive square root of each side, we see that $\vert a-c\vert\leq\vert a-b\vert+\vert b-c\vert$, completing the proof.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;It may not be too obvious why right now, but the four properties above are extremely nice. Let's now move away from the real numbers to more general sets.&lt;/p&gt;

&lt;h3 id="metricsanamemetrics"&gt;Metrics&lt;a name="metrics"&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;As I mentioned before, sets do not come with any notion of distance between their elements. We can remedy this problem with the concept of a metric function, which is really just a way to define a concept of distance between every pair of points. This can tell us quite a lot about the set we're dealing with. We would like our metrics to be meaningful in some sense, so we define them in such a way that they obey precisely the four properties we just discussed pertaining to the absolute value function.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; A &lt;strong&gt;metric&lt;/strong&gt; (or &lt;strong&gt;distance function&lt;/strong&gt;) on a set $X$ is a function $d:X\times X\to\mathbb{R}$ which satisfies the following four properties:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;$d(x,y)\geq 0$ for all $x,y\in X$.  &lt;/li&gt;
&lt;li&gt;$d(x,y) = 0$ if and only if $x=y$.  &lt;/li&gt;
&lt;li&gt;$d(x,y)=d(y,x)$ for all $x,y\in X$.  &lt;/li&gt;
&lt;li&gt;$d(x,z)\leq d(x,y)+d(y,x)$ for all $x,y,z\in X$.&lt;/li&gt;
&lt;/ol&gt;

&lt;hr&gt;

&lt;p&gt;The concept of a metric thus captures many of the properties we associate with the concept of distance. For instance, the distance between a point and itself is always zero, which makes a lot of sense. The distance between two points is the same regardless of which direction you measure it. The distance between two points is never negative.&lt;/p&gt;

&lt;p&gt;We add the triangle inequality into the mix because it ensures our metrics don't become too unruly (we will see later that without it, open balls wouldn't necessarily be open sets). There's a silly, but perhaps insightful, quote justifying it: "The triangle inequality means that if you are going from $x$ to $z$ and you stop for a beer, it's going to take a little longer."&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; A &lt;strong&gt;metric space&lt;/strong&gt; is a set $X$ together with a metric on $X$.&lt;/p&gt;

&lt;p&gt;Notice that we can turn any set into a metric space! This means that we can talk about distances between points in any set. Not all such metrics are particularly useful, but we can at least define them.&lt;/p&gt;

&lt;p&gt;We'll frequently just refer to the set $X$ as a metric space if its metric is implicitly understood. When talking about $n$-dimensional Euclidean space, $\mathbb{R}^n$, it should be understood that we are always referring to it as a metric space with the following metric, unless otherwise stated. This is really just the distance function you're used to extended to $n$-dimensional space:&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; The &lt;strong&gt;standard metric&lt;/strong&gt; (or &lt;strong&gt;Euclidean metric&lt;/strong&gt;) on $\mathbb{R}^n$ is defined by&lt;/p&gt;

&lt;p&gt;$$ d({\bf x,y})=\sqrt{\sum\limits_{i=1}^n(x_i-y_i)^2}$$&lt;/p&gt;

&lt;p&gt;for all ${\bf x,y}\in\mathbb{R}^n$, where &lt;/p&gt;

&lt;p&gt;$${\bf x}=(x_1,x_2,\dotsc,x_n)$$
$${\bf y}=(y_1,y_2,\dotsc,y_n)$$&lt;/p&gt;

&lt;p&gt;for some $x_1,x_2,\dotsc,x_n,y_1,y_2,\dotsc,y_n\in\mathbb{R}$.&lt;/p&gt;

&lt;hr&gt;

&lt;h3 id="openandclosedsetsanameopenandclosedsets"&gt;Open and closed sets&lt;a name="open-and-closed-sets"&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;Next, let's generalize the notions of open and closed intervals to arbitrary metric spaces. In each of the following definitions, let $X$ denote a metric space with distance function $d$, and let $r\in\mathbb{R}$.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; An &lt;strong&gt;open ball&lt;/strong&gt; of radius $r&gt;0$ centered at the point $x_0\in X$ is the set $B(x_0,r)=\{x\in X\mid d(x,x_0)&amp;lt; r\}$.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; A &lt;strong&gt;closed ball&lt;/strong&gt; of radius $r&gt;0$ centered at the point $x_0\in X$ is the set $\overline{B}(x_0,r)=\{x\in X\mid d(x,x_0)\leq r\}$.&lt;/p&gt;

&lt;p&gt;Both open and closed balls contain all the points of distance less than $r$ from $x_0$. The only difference is that a closed ball also contains the points precisely $r$ away from $x_0$.&lt;/p&gt;

&lt;p&gt;We're now set up to define the concept of an open set. This definition is crucial, so be certain to &lt;a href="http://i.imgur.com/qdWoQQr.jpg"&gt;firmly grasp it&lt;/a&gt; before moving on.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; A subset $U$ of a metric space $X$ is &lt;strong&gt;open&lt;/strong&gt; in $X$ if for every point $x\in U$ there exists a real number $r&gt;0$ for which the open ball $B(x,r)\subseteq U$.&lt;/p&gt;

&lt;p&gt;I'm going to rephrase this definition slightly before moving on, just to really drill it into your head. A set is open if every point in the set is at the center of some open ball which is itself completely contained in that set. In the familiar metric spaces, this definition neatly captures the idea that no matter how close you get to the edge of an open set, there are always more points inside which are closer to the edge.&lt;/p&gt;

&lt;p&gt;Now let's prove something that really ought to be true. I'll even throw in a pretty picture for clarity.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; In any metric space, an open ball is an open set.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Suppose we are given an arbitrary open ball of radius $r_0$ centered at a point $x_0$ in a metric space $X$. We need to show that for every point $x\in B(x_0,r_0)$, we can find a real number $r&gt;0$ such that $B(x,r)\subseteq B(x_0,r_0)$.&lt;/p&gt;

&lt;p&gt;Before making this argument rigorous, let's take a look at the following diagram of an open ball in $\mathbb{R}^2$ for a hint as to how we should proceed:&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/03/open-ball-is-open.png" alt="open ball is open"&gt;&lt;/p&gt;

&lt;p&gt;It certainly looks like we could choose $r=r_0-d(x,x_0)$, at least for the open ball above. We'd like to confirm that this choice will work for any open ball in any metric space. We'll argue that, given this choice of $r$, any point $y\in B(x,r)$ is also in $B(x_0,r_0)$. This will certainly show that $B(x,r)\subseteq B(x_0,r_0)$, and that's all we need to do!&lt;/p&gt;

&lt;p&gt;With all this in mind, choose any point $y\in B(x,r)$. Notice first that, from our choice of $r$, we have that $d(x,x_0)=r_0-r$. Observe also that $d(x,y)&amp;lt; r$ by the definition of our open ball $B(x,r)$. We now proceed with the following computation:&lt;/p&gt;

&lt;p&gt;$$\begin{aligned}
d(x_0,y) &amp;amp;\leq d(x_0,x)+d(x,y)\\ &lt;br&gt;
&amp;amp;&amp;lt;(r_0-r)+r\\
&amp;amp;=r_0.
\end{aligned}$$&lt;/p&gt;

&lt;p&gt;But this implies, by the definition of our open ball $B(x_0,r_0)$, that $y\in B(x_0,r_0)$. Thus we have shown that $B(x,r)\subseteq B(x_0,r_0)$, as desired.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;That was actually a decent amount of work to prove something which seemed obvious, right? Notice how without the triangle inequality in the first line of this computation, we could not have finished this proof.&lt;/p&gt;

&lt;p&gt;Before going any further, let's look at some results which are easier to prove.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; In any metric space $X$, the entire set $X$ is itself open.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; For any point $x\in X$, every real number $r&gt;0$ satisfies the condition that $B(x,r)\subseteq X$, because every open ball consists only of points in $X$. It follows that $X$ is an open set.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;That was short! Here's an even simpler one:&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; In any metric space $X$, the empty set $\varnothing=\{\}$ is open.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Since there are by definition no points in the empty set, it is vacuously true that every point in $\varnothing$ is at the center of an open ball contained in $\varnothing$. It follows that the empty set is open.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;Since we're on a roll, let's move on to the definition of a closed set, shall we?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; A subset $U$ of a metric space $X$ is &lt;strong&gt;closed&lt;/strong&gt; in $X$ if its complement, $X-U$, is open in $X$.&lt;/p&gt;

&lt;p&gt;This leads to another closely-related pair of theorems with even easier proofs.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; In any metric space $X$, the empty set is closed.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; The complement of the empty set is $X-\varnothing=X$. Since $X$ is open, it follows that the empty set is closed.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;I bet you can already guess the next one.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; In any metric space $X$, the entire set $X$ is itself closed.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; The complement of $X$ is $X-X=\varnothing$. Since the empty set is open, it follows that $X$ is closed.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;At first glance, these might seem like they contradict our earlier statements about these very same sets being open. The empty set and the space itself are both open and closed? I've heard several times the phrase "a set is not a door." Yes, sets can be both open and closed. The two are not mutually exclusive. It's also easy to find examples of sets in metric spaces which are neither open nor closed!&lt;/p&gt;

&lt;p&gt;The next thing we should do is confirm that a closed ball is a closed set — otherwise we'd be in a fair bit of trouble. This proof is pretty similar to the proof that an open ball is open, but a teensy bit trickier.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; In any metric space, a closed ball is a closed set.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Suppose we are given an arbitrary closed ball of radius $r_0$ centered at a point $x_0$ in a metric space $X$. If we can show that its complement, $X-\overline{B}(x_0,r_0)$, is open, then by the definition of a closed set, we will be done. Thus, we need to show that for every point $x\in X-\overline{B}(x_0,r_0)$ we can find a real number $r&gt;0$ such that $B(x,r)\subseteq X-\overline{B}(x_0,r_0)$.&lt;/p&gt;

&lt;p&gt;Once again, let's look at a diagram for some intuition before we dive any further into the proof:&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/03/closed-ball-is-closed.png" alt="closed ball is closed"&gt;&lt;/p&gt;

&lt;p&gt;A little bit of inspection indicates that it might suffice to choose $r=d(x,x_0)-r_0$. We'll argue that, given this choice of $r$, any point $y\in B(x,r)$ is also in $X-\overline{B}(x_0,r_0)$. This will certainly show that $B(x,r)\subseteq X-\overline{B}(x_0,r_0)$, and then we'll be finished.&lt;/p&gt;

&lt;p&gt;With all this in mind, choose any point $y\in B(x,r)$. Notice first that, from our choice of $r$, we have that $d(x,x_0)=r+r_0$. Observe also that $d(x,y)&amp;lt; r$ by the definition of our open ball $B(x,r)$. We now proceed with the following computation, again starting with a slightly rearranged form of the triangle inequality:&lt;/p&gt;

&lt;p&gt;$$\begin{aligned}
d(x_0,y)&amp;amp;\geq d(x,x_0)-d(x,y)\\ &lt;br&gt;
&amp;amp;=(r+r_0)-d(x,y)\\
&amp;amp;&gt;r_0.
\end{aligned}$$&lt;/p&gt;

&lt;p&gt;The last step above may take a little bit of explanation. Since $d(x,y)&amp;lt; r$, clearly $r-d(x,y)&gt;0$. Thus, $r+r_0-d(x,y)&gt;r_0$, which hopefully makes things a bit clearer.&lt;/p&gt;

&lt;p&gt;Since $d(x_0,y)&gt;r_0$, it follows that $y\notin\overline{B}(x_0,r_0)$ by the definition of this closed ball. It follows that $y\in X-\overline{B}(x_0,r_0)$. Thus, $X-\overline{B}(x_0,r_0)$ is open and so its complement $\overline{B}(x_0,r_0)$ is closed, as desired.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;That's enough for one post, I think. Don't worry though — we've only just begun with the &lt;em&gt;joys&lt;/em&gt; of metric spaces!&lt;/p&gt;</content:encoded></item><item><title>Set Theory</title><description>Everything in mathematics is built from sets. Even objects such as functions and arithmetic operations like addition are formally defined in terms of sets, although you would likely never expect it. </description><link>http://localhost:2368/set-theory/</link><guid isPermaLink="false">9471d781-5f1d-427e-bf80-97492f34cb01</guid><category>set-theory</category><dc:creator>Eric Shapiro</dc:creator><pubDate>Wed, 29 Mar 2017 00:49:23 GMT</pubDate><content:encoded>&lt;h3 id="contents"&gt;Contents&lt;/h3&gt;

&lt;p&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href="http://localhost:2368/set-theory/#what-are-sets"&gt;What are sets?&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="http://localhost:2368/set-theory/#basic-facts-about-sets"&gt;Basic facts about sets&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="http://localhost:2368/set-theory/#operations-on-sets"&gt;Operations on sets&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="http://localhost:2368/set-theory/#functions"&gt;Functions&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;hr&gt;

&lt;p&gt;Everything in mathematics is built from sets.&lt;sup id="fnref:1"&gt;&lt;a href="http://localhost:2368/set-theory/#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt; Even objects such as functions and arithmetic operations like addition are formally defined in terms of sets, although you would likely never expect it. A consequence of this fact is that a basic familiarity with set theory is necessary in order to understand the topics I'll be discussing here. For this reason, I've decided to include this introductory post on the topic so that adventurous readers with little mathematical background will be able to understand my future posts without having to leave the confines of this blog.&lt;/p&gt;

&lt;h3 id="whataresetsanamewhataresets"&gt;What are sets?&lt;a name="what-are-sets"&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;Already we encounter something of a problem — one which took mathematicians quite a while to resolve, and should not be underestimated. The issue is that, because we wish to use set theory as the foundation of all future mathematical exploration, we don't actually have a place to start when defining sets themselves.&lt;/p&gt;

&lt;p&gt;It takes quite a bit of logical sophistication to arrive at a truly satisfactory definition of a set. If you're interested in such things, I encourage you to look into any resource you can find on &lt;em&gt;Zermelo-Fraenkel Set Theory with the Axiom of Choice&lt;/em&gt; (usually abbreviated &lt;em&gt;ZFC&lt;/em&gt;), which is a more rigorous set of axioms which govern the behavior of sets.&lt;/p&gt;

&lt;p&gt;For our purposes, the standard "naïve" set theory will do just fine. It is largely intuition-based, because it relies on the primitive notion that sets contain elements and elements are what make up sets. However, as long as we take certain precautions when dealing with sets, we should never encounter any problems stemming from this treatment:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; A &lt;strong&gt;set&lt;/strong&gt; is a collection of &lt;strong&gt;elements&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id="basicfactsaboutsetsanamebasicfactsaboutsets"&gt;Basic facts about sets&lt;a name="basic-facts-about-sets"&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;Traditionally, capital letters like $A$, $B$ or $X$ are used to denote sets. If $x$ is an element of a set $X$, we write $x\in X$ and we say that "$x$ is in $X$."&lt;/p&gt;

&lt;p&gt;Sets are determined solely by the elements they contain. For instance, if the numbers $1$, $2$ and $3$ are the only elements of the set $X$, we can indicate this by writing $X=\{1,2,3\}$. When we define sets in this manner, by specifying a complete list of elements they contain, we always sandwich the list of elements between curly braces, as above.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; If two sets $A$ and $B$ contain precisely the same elements, we say that they are &lt;strong&gt;equal&lt;/strong&gt; and we write $A=B$. If they are &lt;strong&gt;not equal&lt;/strong&gt;, we write $A\neq B$.&lt;/p&gt;

&lt;p&gt;If two sets are not equal, then by definition they do not contain the same elements. It follows then that one of them must contain at least one element that the other does not.&lt;/p&gt;

&lt;p&gt;This definition of set equality should hopefully seem reasonable. Note that it does imply that the sets $\{x, y, z\}$ and $\{x, x, z, y, x, z\}$ are equal because they contain the same elements. Although some elements may appear more than once in the description of a set, or the elements may by written in a different order, a set either contains an element or it does not. &lt;strong&gt;Sets do not have any concept of multiplicity or order for their elements.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;There is nothing to prevent sets from containing other sets, but be careful when dealing with sets that have other sets as elements. If $x$ is some element, then $\big\{x, \{x\}\big\} \neq \{x\}$ because the set $\{x\}$ is not the same thing as the element $x$.&lt;/p&gt;

&lt;p&gt;It may be helpful to think of sets as bags, and their elements as objects inside these bags. If $x$ is an apple, then $\big\{x, \{x\}\big\}$ represents a bag inside of which are two things: an apple and a bag. Inside of the inner bag is also an apple. This is very clearly not the same thing as $\{x\}$, which is just a bad with only an apple inside.&lt;/p&gt;

&lt;p&gt;Equality is not the only relationship between sets that we will be concerned with. The following definitions give us a way to talk about sets which contain some of the same elements.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; Let $A$ and $B$ denote two sets. If every element of $A$ is also and element of $B$, we say that $A$ is a &lt;strong&gt;subset&lt;/strong&gt; of $B$ and we write $A\subseteq B$.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; If $A\subseteq B$ but $A\neq B$, we say that $A$ is a &lt;strong&gt;proper subset&lt;/strong&gt; of $B$ and we write $A\subset B$.&lt;/p&gt;

&lt;p&gt;Notice that, by these definitions, every set is a subset of itself. Also note that if $A\subset B$, it follows that $B$ contains some element that $A$ does not. Thus, if both sets are finite then $B$ is larger than $A$. Infinite sets are weird and do weird things, so we cannot necessarily make the same claim when they get involved.&lt;/p&gt;

&lt;p&gt;Again, we must take care and realize that $A\subseteq B$ is a completely different statement than $A\in B$. To visualize this, we refer again to our analogy between sets and bags. Take as an example the case where $A$ is a bag containing only an apple, while $B$ is a bag containing an apple and an orange. It should be clear that $A$ is not actually an element of $B$, but it is a subset.&lt;/p&gt;

&lt;p&gt;We're ready now for our first proof!&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; Let $A$ and $B$ denote sets. If $A\subseteq B$ and $B\subseteq A$, then $A=B$.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Since $A$ is a subset of $B$, every element of $A$ is also an element of $B$. Likewise, since $B$ is a subset of $A$, every element of $B$ is also an element of $A$. It follows that the elements of each set are precisely the same, so $A=B$, as desired.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;One important set will come up in our discussions quite often:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; The &lt;strong&gt;empty set&lt;/strong&gt; is the unique set containing no elements.&lt;/p&gt;

&lt;p&gt;It is easy to see that the empty set is a subset of every set, since all of the elements it contains (none) are trivially also in every other set.&lt;/p&gt;

&lt;p&gt;In many upcoming posts, I am going to assume familiarity with the following sets:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The set $\mathbb{N} = \{0, 1, 2, \dotsc\}$ of &lt;strong&gt;natural numbers&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;The set $\mathbb{Z} = \{\dotsc, -1, 0, 1, \dotsc\}$ of &lt;strong&gt;integers&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;The set $\mathbb{Q}$ of &lt;strong&gt;rational numbers&lt;/strong&gt; whose elements are of the form $\frac{p}{q}$, where $p, q \in \mathbb{Z}$ and $q \neq 0$.&lt;/li&gt;
&lt;li&gt;The set $\mathbb{R}$ of &lt;strong&gt;real numbers&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;The set $\mathbb{C}$ of &lt;strong&gt;complex numbers&lt;/strong&gt; whose elements are of the form $a+bi$, where $a, b \in \mathbb{R}$ and $i^2 = -1$.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It is convenient and natural to assume that $\mathbb{N}\subset\mathbb{Z}\subset\mathbb{Q}\subset\mathbb{R}\subset\mathbb{C}$, and I encourage you to think this way.&lt;sup id="fnref:2"&gt;&lt;a href="http://localhost:2368/set-theory/#fn:2" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;It is often desirable to specify certain subsets of sets with which we are already acquainted in terms of some property that every element in the subset must possess. How would we, for instance, denote the set of positive real numbers? Or the set of even integers?&lt;/p&gt;

&lt;p&gt;We can construct such subsets using &lt;strong&gt;set-builder notation&lt;/strong&gt;. This is basically a fancy notation describing the form that elements in the set take, followed by a vertical bar which means "such that," and then a property which every element obeys — all sandwiched between the usual set brackets.&lt;/p&gt;

&lt;p&gt;In this new notation, $\{x\in\mathbb{R} \mid x&gt;0\}$ would be the set of positive real numbers. Similarly, $\{2n \mid n\in\mathbb{Z}\}$ is the set of even integers.&lt;/p&gt;

&lt;h3 id="operationsofsetsanameoperationsonsets"&gt;Operations of sets&lt;a name="operations-on-sets"&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;Given two or more sets, we will often find the need to combine them in certain ways to create new sets. Below are four very common ways of creating new sets from old. Each of their definitions can be extended to combine any finite collection of sets, and sometimes even an infinite collection. Make certain that you are comfortable with each of these definitions, since they will show up everywhere ever.&lt;/p&gt;

&lt;p&gt;Let $A$ and $B$ denote sets. Let's say, for illustration, that they're sets of points in the plane of your screen and they look like these blobs:&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/03/sets.svg" alt=""&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; The &lt;strong&gt;union&lt;/strong&gt; of $A$ and $B$ is the set of all elements in either $A$ or in $B$, or both. It is written $A\cup B$ and is defined as the set $\{x \mid x\in A \text{ or } x\in B\}$.&lt;/p&gt;

&lt;p&gt;The union of the sets above would look like this:&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/03/union.svg" alt=""&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; The &lt;strong&gt;intersection&lt;/strong&gt; of $A$ and $B$ is the set of all elements in both $A$ and $B$. It is written $A\cap B$ and is defined as the set $\{x \mid x\in A \text{ and } x\in B\}$.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; Two sets are said to be &lt;strong&gt;disjoint&lt;/strong&gt; if their intersection is empty.&lt;/p&gt;

&lt;p&gt;The intersection of the above sets would look like this:&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/03/intersection.svg" alt=""&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; The &lt;strong&gt;complement&lt;/strong&gt; (or &lt;strong&gt;difference&lt;/strong&gt;) of $A$ in $B$ is the set of all elements that are in $B$ but not in $A$. It is written $B-A$ and is defined as the set $\{x\in B \mid x\notin A\}$.&lt;/p&gt;

&lt;p&gt;For the sets above, the complement of $A$ in $B$ would look like this:&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/03/complement.svg" alt=""&gt;&lt;/p&gt;

&lt;p&gt;It is worth nothing that, unlike unlike unions and intersections, complements depend on which set comes first. That is, $A-B\neq B-A$.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; The &lt;strong&gt;Cartesian product&lt;/strong&gt; of $A$ and $B$, written $A \times B$, is the set of all ordered pairs whose first component is in $A$ and whose second component is in $B$.&lt;/p&gt;

&lt;p&gt;The Cartesian product of the above sets would be a bit trickier to draw since this would require four spacial dimensions. As a simpler example, suppose that $A$ and $B$ are both $\mathbb{R}$, the set of real numbers. Then $A\times B=\mathbb{R}\times\mathbb{R}$ and this set would consist of all points in the plane. This is because $\mathbb{R}\times\mathbb{R}$ by definition contains all pairs of the form $(x,y)$ where $x$ and $y$ are real numbers. This is why two-dimensional Euclidean space is often written as $\mathbb{R}^2$, as shorthand for $\mathbb{R}\times\mathbb{R}$.&lt;/p&gt;

&lt;p&gt;It should be somewhat obvious how to take the union of an arbitrary collection of sets. For a finite collection of $n$ sets — $A_1, A_2, \dotsc, A_n$ — their union contains all of the elements that are in at least one of the sets:&lt;/p&gt;

&lt;p&gt;$$\bigcup\limits_{i=1}^n A_i = \{x\mid x\in A_1 \text{ or } x\in A_2 \text{ or } \dotsc \text{ or } x\in A_n\}.$$&lt;/p&gt;

&lt;p&gt;We can go even further, and take the union of any collection of sets. To do so, we first let $I$ be some &lt;strong&gt;indexing set&lt;/strong&gt; such that $A_i$ is a set for every $i\in I$. Notice that there is nothing to stop $I$ from being an infinite set, in which case there would be infinitely many sets $A_i$ in our collection. We can take the union of all these sets as follows:&lt;/p&gt;

&lt;p&gt;$$\bigcup\limits_{i\in I} A_i = \{x \mid x\in A_i \text{ for some } i\in I\}.$$&lt;/p&gt;

&lt;p&gt;The same type of thinking allows for intersections and Cartesian products to be defined for more than two sets. In the case of Cartesian products, multiplying $n$ sets yields a set whose elements are ordered $n$-tuples, where the $i$th component is an element of the $i$th set being multiplied. Cartesian products of infinitely many sets are a bit too complicated to discuss here, although we can easily take the intersection of an arbitrary collection of sets, much as we did for their union:&lt;/p&gt;

&lt;p&gt;$$\bigcap\limits_{i\in I} A_i = \{x \mid x\in A_i \text{ for every } i\in I\}.$$&lt;/p&gt;

&lt;p&gt;There are two interesting ways in which the operation of set difference distributes over the operations of unions and intersections. These are called &lt;strong&gt;De Morgan's Laws&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;$$X - (A \cup B) = (X - A) \cap (X - B),$$
$$X - (A \cap B) = (X - A) \cup (X - B).$$&lt;/p&gt;

&lt;p&gt;These highly symmetric rules often turn out to be very useful, and I encourage you to draw some pictures to try to understand them. I will not prove them here. To illustrate the second rule, here is an example: if a ball is not both red and blue, then it is not red or it is not blue (or possibly both).&lt;/p&gt;

&lt;p&gt;De Morgan's Laws also extend naturally to arbitrary collections of sets:&lt;/p&gt;

&lt;p&gt;$$X - \bigcup\limits_{i\in I} A_i = \bigcap\limits_{i\in I} (X - A_i),$$
$$X - \bigcap\limits_{i\in I} A_i = \bigcup\limits_{i\in I} (X - A_i).$$&lt;/p&gt;

&lt;h3 id="functionsanamefunctions"&gt;Functions&lt;a name="functions"&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;The last topic I'll talk about in this post is the concept of a function, as well as several important traits that functions may or may not possess. You've likely encountered functions before as things that eat variables and poo out numbers, and that's not a terrible way of thinking about them. We're going to make things a bit more formal though.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; A &lt;strong&gt;function&lt;/strong&gt; from a set $A$ to a set $B$, denoted $f:A\to B$, is a subset of $A\times B$ such that for each $x\in A$, there is exactly one $y\in B$ for which $(x, y)\in f$. In this definition, the set $A$ is called the &lt;strong&gt;domain&lt;/strong&gt; of $f$ and $B$ is called the &lt;strong&gt;codomain&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; The &lt;strong&gt;range&lt;/strong&gt; (or &lt;strong&gt;image&lt;/strong&gt;) of a function $f$ is the set $\text{im } f = \{y\in B \mid (x,y)\in f \text{ for some } x\in A\}$.&lt;/p&gt;

&lt;p&gt;If you've never seen the above definition of a function before, it's natural to wonder at this point just what the crud I'm talking about. Why are we defining functions as sets? As I stated earlier, &lt;em&gt;everything&lt;/em&gt; in mathematics is defined in terms of sets, and functions are no exception. We don't usually think of functions as sets of ordered pairs, but it is useful to define them this way so that we can make precise statements about them which stem from their definition. It also allows us to immediately infer what is meant by function equality, because it is inherited from our earlier definition of set equality.&lt;/p&gt;

&lt;p&gt;So using this definition, a function is basically a list of $(x,y)$ values where $y$ is what you'd usually call $f(x)$. That is, the first component is the "input" to the function and the second component is the "output." The second condition in the definition is a rephrasing of what you may know as the "vertical line test." In two dimensions, a function from $\mathbb{R}$ to $\mathbb{R}$ is anything you can draw that exists above every value on the $x$-axis, but not more than once.&lt;/p&gt;

&lt;p&gt;As I mentioned above, a more familiar way of rephrasing the last part of the definition might be this:&lt;/p&gt;

&lt;p&gt;... for each $x\in A$, there exists exactly one $y\in B$ for which $y=f(x)$.&lt;/p&gt;

&lt;p&gt;This notation is much more common, and I'll be using it almost exclusively from now on. Often, $f(x)$ is referred to as the &lt;strong&gt;image&lt;/strong&gt; of $x$ under the function $f$. This is an unfortunate overloading of the word "image," but it will not lead to confusion if we are careful.&lt;/p&gt;

&lt;p&gt;One of the nice things about our definition of a function it that it allows us to define functions between any two sets we want, and the values of the function don't have to obey any particular rule. We can simply check each point and its image to make sure they obey the definition.&lt;/p&gt;

&lt;p&gt;If you're a bit confused by all this, just sit and absorb it for a minute. Realize that ordinary things like the function $f:\mathbb{R}\to\mathbb{R}$, defined by $f(x)=x^2$ for every $x\in\mathbb{R}$, still satisfy our new definition. Think everything through — maybe draw some pictures — and then continue reading.&lt;/p&gt;

&lt;p&gt;Now, notice that something like $f:\mathbb{R}\to\mathbb{R}$ defined by $f(x)=\frac{1}{x}$ for all $x\in\mathbb{R}$ is not actually a function! This is because not every element of the domain gets mapped to a real number. In particular, there is no $y\in\mathbb{R}$ for which $y=f(0)$. We would need to restrict the domain to $\mathbb{R} - \{0\}$ to turn this thing into a function.&lt;/p&gt;

&lt;p&gt;The next thing we'll do is introduce some common classes of functions. &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; A function $f:A\to B$ is &lt;strong&gt;injective&lt;/strong&gt; if for every $y\in B$ there exists at most one $x\in A$ for which $y=f(x)$.&lt;/p&gt;

&lt;p&gt;Basically, an injective function cannot have two points in its domain get mapped to the same point in its codomain. We can check that a function is injective by showing that if $x\neq y$ then $f(x)\neq f(y)$. Equivalently, we can do this by instead showing that if $f(x)=f(y)$ then $x=y$. (These two statements are contrapositives so they are logically equivalent, but sometimes one will be easier to show than the other.) Injective functions in the plane satisfy what might constitute a "horizontal line test," in that any horizontal line will intersect their graph at most once.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; A function $f:A\to B$ is &lt;strong&gt;surjective&lt;/strong&gt; if for every $y\in B$, there exists at least one $x\in A$ for which $y=f(x)$.&lt;/p&gt;

&lt;p&gt;A surjective function has every point in its codomain get mapped to by some point in the domain. That is, every element of the codomain is the image of some element in the domain. In this case, the codomain of the function is equal to its range. Notice that we can turn any function into a surjective function by restricting its codomain to its range.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; A function $f:A\to B$ is &lt;strong&gt;bijective&lt;/strong&gt; if for every $y\in B$, there exists exactly one $x\in A$ for which $y=f(x)$. Equivalently, a function is bijective if it is both injective and surjective.&lt;/p&gt;

&lt;p&gt;Bijective functions are particularly nice because they have &lt;strong&gt;inverse functions&lt;/strong&gt;. That is, if $f:A\to B$ is bijective, we can find a function $f:B\to A$ with the property that $f\big(g(y)\big)=y$ for every $y\in B$ and $g\big(f(x)\big)=x$ for every $x\in A$. &lt;/p&gt;

&lt;p&gt;A function's inverse essentially allows us to undo what that function did in the first place. It turns out that if a function has an inverse, then that inverse is unique and thus we can unambiguously write the inverse of $f$ as $f^{-1}$.&lt;/p&gt;

&lt;p&gt;Functions that aren't bijective do not have inverses, but we can still define something similar:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; The &lt;strong&gt;preimage&lt;/strong&gt; of a set $Y\subseteq B$ under a function $f:A\to B$ is the set of all $X\in A$ for which $f(x)\in Y$. We write $f^{-1}[Y]=\{x\in A\mid f(x)\in Y\}$.&lt;/p&gt;

&lt;p&gt;Note that $f^{-1}$ here does &lt;em&gt;not&lt;/em&gt; denote an inverse function! We haven't even defined the preimage as a function at all (yet). The square brackets around its argument (which is always a set) help us to distinguish between whether we are talking about inverse functions or preimages. Given a subset of the codomain, the preimage tells us which elements in the domain get mapped into that set.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; The &lt;strong&gt;power set&lt;/strong&gt; of a set $X$ is the set of all subset of $X$.&lt;/p&gt;

&lt;p&gt;We often denote the power set of $X$ as $2^X$ because a simple combinatorial argument shows that if $X$ is a finite set with $n$ elements, then $X$ has $2^n$ distinct subsets.&lt;/p&gt;

&lt;p&gt;Preimages are technically functions themselves, though perhaps not in the way you might expect. Since preimages take subsets of a function's codomain and map them to subsets of a function's domain, the preimage of a function $f:X\to Y$ is a set-valued function $f^{-1}:2^Y\to 2^X$ defined by $f^{-1}[U]=\{x\in X\mid f(x)\in U\}$ for every $U\in 2^Y$.&lt;/p&gt;

&lt;p&gt;Now the overloading of the symbol $f^{-1}$ is even worse, because we have defined both inverses and preimages as functions! However, careful use of square brackets for the preimage and the fact that one function is set-valued while the other is usually not will help us to avoid confusion. Further, inverse functions only exist for bijections, but preimages are defined for all functions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; Given two functions $f:A\to B$ and $g:B\to C$ we can form a new function $g\circ f:A\to C$, called the &lt;strong&gt;composition&lt;/strong&gt; of $f$ and $g$, by defining $(g\circ f)(x)=g\big(f(x)\big)$ for every $x\in A$.&lt;/p&gt;

&lt;p&gt;Intuitively, when taking the composition of $f$ and $g$, we first take $f(x)$ and then feed the result into $g$. Note that the composition of functions is only defined when the first function's codomain is equal to the second function's domain.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; For any set $X$, we can define an &lt;strong&gt;identity function&lt;/strong&gt; $1_X:X\to X$ by $1_X(x)=x$ for every $x\in X$.&lt;/p&gt;

&lt;p&gt;An identity function maps every element of a set to itself, so essentially it does nothing at all. If no confusion can arise about which set we're talking about, we sometimes drop the subscript and write $1$ instead of $1_X$ to denote this function.&lt;/p&gt;

&lt;p&gt;Notice now that we can phrase the definition of an inverse function more compactly: A function $f:A\to B$ has an inverse $f:B\to A$ if $g\circ g=1_B$ and $g\circ f=1_A$. That is, the two possible compositions of $f$ and $g$ are equal to the identity functions on their respective domains.&lt;/p&gt;

&lt;p&gt;One final remark I will make is that the composition of functions is always &lt;strong&gt;associative&lt;/strong&gt;. That is, if we have three functions $f:A\to B$, $g:B\to C$ and $h:C\to D$, then $(h\circ g)\circ f=h\circ(g\circ f)$. This may look obvious, but the proof — while straightforward — might elude you if you are not accustomed to writing proofs. Nonetheless, I encourage you to try showing this fact for yourself. Here's a hint: use the definition of function composition. If you've done the proof right, it will probably feel as though you haven't really done anything at all.&lt;/p&gt;

&lt;hr&gt;

&lt;div class="footnotes"&gt;&lt;ol&gt;&lt;li class="footnote" id="fn:1"&gt;&lt;p&gt;One sentence in and I'm already lying to you. There are alternative formulations of mathematics, most notably via topos theory or type theory. If you are a beginner, I would recommend not looking these things up or you will likely be very confused. Set theory is by far the simplest foundation to start from, which explains why it is the most common approach (and the one I will take here). &lt;a href="http://localhost:2368/set-theory/#fnref:1" title="return to article"&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li class="footnote" id="fn:2"&gt;&lt;p&gt;More formally it happens that each set, equipped with a certain algebraic structure, is isomorphic to a subobject of the next set, equipped with its own structure. If I ever decide to write a post (or five) detailing the constructions of each of the aforementioned sets, you'll see this idea in excruciating detail. &lt;a href="http://localhost:2368/set-theory/#fnref:2" title="return to article"&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;</content:encoded></item></channel></rss>