<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/" version="2.0"><channel><title>Algebrology</title><description>A gentle introduction to insanity.</description><link>http://localhost:2368/</link><image><url>http://localhost:2368/favicon.png</url><title>Algebrology</title><link>http://localhost:2368/</link></image><generator>Ghost 2.14</generator><lastBuildDate>Mon, 25 Feb 2019 09:31:39 GMT</lastBuildDate><atom:link href="http://localhost:2368/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title>Constructing the Rational Numbers (2)</title><description>This is a continuation of Constructing the Rational Numbers (1). Before moving forward with the rest of the construction, I'd like to formally change my notation for rational numbers from that of equivalence classes of ordered pairs of integers to that of fractions.</description><link>http://localhost:2368/constructing-the-rational-numbers-2/</link><guid isPermaLink="false">5c6f446575042202e3d9fce2</guid><dc:creator>Eric Shapiro</dc:creator><pubDate>Fri, 22 Feb 2019 00:38:35 GMT</pubDate><content:encoded>&lt;h3 id="contents"&gt;Contents&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#canonical-form"&gt;Canonical Form&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#where-is-z"&gt;Where is $\Z$?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#ordering-the-rationals"&gt;Ordering the Rationals&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#filling-the-gaps"&gt;Filling the Gaps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#field-axioms"&gt;Field Axioms&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="canonicalformanamecanonicalform"&gt;Canonical Form&lt;a name="canonical-form"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;This is a continuation of &lt;a href="http://localhost:2368/constructing-the-rational-numbers-1/"&gt;Constructing the Rational Numbers (1)&lt;/a&gt;. Before moving forward with the rest of the construction, I'd like to formally change my notation for rational numbers from that of equivalence classes of ordered pairs of integers to that of fractions.&lt;/p&gt;
&lt;p&gt;That is, from here on out the rational number $[(a,b)]$ will simply be written as the &lt;strong&gt;fraction&lt;/strong&gt; $\frac{a}{b}$. And now rational numbers look exactly how you would expect. Yay! Note that the bar doesn't really mean anything yet, this notation is currently just a formalism.&lt;/p&gt;
&lt;p&gt;Remember that there are many choices of representative for each rational number. For instance, $\frac{1}{2}=\frac{2}{4}$ in the same way that $[(1,2)]=[(2,4)]$ because, in the language of my last post, $(1,2)\sim_\Q (2,4)$. Last time we defined this equivalence relation, $\sim_\Q$, which determines whether two fractions are really the same rational number. Let's rephrase this in terms of fractions and without the formality of the equivalence relation, because it's very important:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Rule (Cross Multiplication).&lt;/strong&gt; Two fractions $\frac{a}{b}$ and $\frac{c}{d}$ represent the same rational number if and only if $ad=bc$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;We know in our hearts that although there are many fractional representations of each rational, there is always one preferred representation. That is, although $\frac{1}{2}$ and $\frac{2}{4}$ are both valid representations of the same number, we definitely prefer to call it $\frac{1}{2}$ because it's simpler somehow.&lt;/p&gt;
&lt;p&gt;We can easily make this decision rigorous, but first we need to recall the following definition:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; Given two integers $a$ and $b$, their &lt;strong&gt;greatest common divisor&lt;/strong&gt;, written $\gcd(a,b)$, is the largest positive integer which is a factor of both $a$ and $b$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Here are some examples, although you have likely seen this concept before.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; Consider $4$ and $6$. We can write $4=2\cdot 2$ and $6=2\cdot 3$. They both have one factor in common: $2$. Thus, $\gcd(4,6)=2$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; Consider $15$ and $30$. We can write $15=3\cdot 5$ and $30=2\cdot 3\cdot 5$. They have two prime factors in common, so their greatest common divisor is the product of these factors: $\gcd(15, 30)=15$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; Consider $0$ and $6$. We can trivially write $0=0\cdot 6$, and so $\gcd(0, 6) = 6$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; Consider $3$ and $7$. We cannot simplify either number further since they are both prime. Clearly they have no factors in common other than $1$, so $\gcd(3, 7)=1$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; Consider $4$ and $9$. Neither is prime, so we can write $4=2\cdot 2$ and $9=3\cdot 3$. There are still no common factors other than $1$, so $\gcd(4,9)=1$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;That last example is particularly interesting, since we had two integers which were not prime, and whose greatest common divisor was still 1. We have a special name for this:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; Two integers $a$ and $b$ are &lt;strong&gt;coprime&lt;/strong&gt; (or &lt;strong&gt;relatively prime&lt;/strong&gt;) if $\gcd(a,b)=1$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I will not prove it, since we are taking properties of the integers for granted, but the greatest common divisor of two integers always exists as long as they are not both zero.&lt;/p&gt;
&lt;p&gt;We now have the tools to choose a preferred representation for each rational number.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; A fractional representation $\frac{a}{b}$ for a rational number is in &lt;strong&gt;canonical form&lt;/strong&gt; if $a$ and $b$ are coprime and $b&amp;gt;0$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This definition should hopefully make sense to you. It means, for instance, that $\frac{1}{2}$ is the canonical form for the rational number which is also represented by $\frac{2}{4}$, $\frac{-1}{-2}$, etc.&lt;/p&gt;
&lt;p&gt;However, whenever we make a definition like this it is important to determine two things. Does it always exist? And if it exists, is it unique? In this case, the answer to both questions is yet. There is always exactly one canonical form for each rational number, and so we may refer to it as &lt;em&gt;the&lt;/em&gt; canonical form. Let's prove this!&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Proposition.&lt;/strong&gt; Every rational number has a unique canonical form.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Choose a rational number $q$. We argue first that a canonical form for $q$ exists. Let $\frac{a}{b}$ be some fraction which represents $q$. Note that $\gcd(a,b)$ is guaranteed to exist because $b\neq 0$. Thus there are integers $m$ and $n$ for which&lt;/p&gt;
&lt;p&gt;$$\frac{a}{b} = \frac{m\cdot\gcd(a,b)}{n\cdot\gcd(a,b)}.$$&lt;/p&gt;
&lt;p&gt;We argue that $\frac{a}{b}=\frac{m}{n}$. This is easily done by remembering the above rule for determining whether two fractions represent the same rational number. From the first equality above, we have that&lt;/p&gt;
&lt;p&gt;$$a \cdot n \cdot \gcd(a,b) = b \cdot m \cdot \gcd(a,b).$$&lt;/p&gt;
&lt;p&gt;Using the left cancellation property of the integers, we may cancel $\gcd(a,b)$ from both sides to obtain&lt;/p&gt;
&lt;p&gt;$$an=bm.$$&lt;/p&gt;
&lt;p&gt;Again using the cross multiplication rule for equivalent fractions, we see that $\frac{a}{b}=\frac{m}{n}$. If $n$ is positive, this is certainly a canonical form for $q$. Otherwise, we may easily obtain a canonical form by negating both slots of the fraction: $\frac{-m}{-n}$. It is easy to show from here that $\frac{a}{b}=\frac{-m}{-n}$, so I will not bother with it.&lt;/p&gt;
&lt;p&gt;We have demonstrated that a canonical form for $q$ exists. It remains to show that it is unique. That is, we aim to show that if $\frac{m_1}{n_1}$ and $\frac{m_2}{n_2}$ are both canonical forms for $q$, then $m_1=m_2$ and $n_1=n_2$.&lt;/p&gt;
&lt;p&gt;This is not too difficult. Since both fractions are already in canonical form, we know that $\gcd(m_1,n_1)=1$ and $\gcd(m_2,n_2)=1$. Furthermore, since they both represent $q$, we also know that $\frac{m_1}{n_1} = \frac{m_2}{n_2}$ and thus $m_1n_2=n_1m_2$.&lt;/p&gt;
&lt;p&gt;Certainly this indicates that $m_1$ is a factor of $n_1m_2$. But $m_1$ and $n_1$ are coprime by hypothesis, so it must be the case that $m_1$ is a factor of $m_2$. Reversing the argument, we see that $m_2$ is a factor of $m_1$. This can only be true if $m_1=m_2$. The argument that $n_1=n_2$ is exactly analogous. It follows then that the canonical form is unique, as desired.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So now we know that every rational number can be represented in a way that is in this sense &amp;quot;most desirable.&amp;quot; It certainly aligns with the simplification of fractions that we all saw in elementary school.&lt;/p&gt;
&lt;p&gt;Now, remember that we already defined addition and multiplication of rational numbers in my previous post. Let's review those definitions here.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; The &lt;strong&gt;sum&lt;/strong&gt; of two rational numbers $\frac{a}{b}$ and $\frac{c}{d}$ is the rational number $\frac{ad+bc}{bd}$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; The &lt;strong&gt;product&lt;/strong&gt; of two rational numbers $\frac{a}{b}$ and $\frac{c}{d}$ is the rational number $\frac{ac}{bd}$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It's worth mentioning that taking the sum or product of two fractions in canonical form does not always result in a canonical form fraction.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; The fraction $\frac{1}{2}$ is certainly in canonical form. However,&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
\frac{1}{2}+\frac{1}{2} &amp;amp;= \frac{1\cdot 2 + 2\cdot 1}{2\cdot 2} \\&lt;br&gt;
&amp;amp;= \frac{4}{4}.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;This is certainly not in canonical form, since $\gcd(4,4)=4$.&lt;/p&gt;
&lt;p&gt;However, this is not really an issue since we can just rewrite it in canonical form post-computation. In this case, the canonical form for the result is $\frac{1}{1}$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id="whereiszanamewhereisz"&gt;Where is $\Z$?&lt;a name="where-is-z"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Ordinarily, when we are not being as ridiculously pedantic as we are in this post, we would consider the integers to be a subset of the rational numbers. But technically this is not the case of our construction, since our rationals are equivalence classes of pairs of integers and thus not integers themselves. It's our goal, therefore, to identify a subset of rationals that looks and behaves like the integers.&lt;/p&gt;
&lt;p&gt;The above example may have already given this away. Technically the rational number whose canonical form is $\frac{1}{1}$ is not the same thing as the integer $1$. But I mean, come on... they're pretty darn similar. This leads us to the following identification.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; The &lt;strong&gt;rational integers&lt;/strong&gt; are the set of rational numbers whose canonical form is $\frac{n}{1}$, where $n$ is an integer. We refer to $\frac{n}{1}$ as the &lt;strong&gt;rational integer corresponding to $n$&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I don't actually think &amp;quot;rational integer&amp;quot; is a phrase that anyone ever uses, but it will serve our purposes for this post to distinguish between an integer and its corresponding rational number.&lt;/p&gt;
&lt;p&gt;Rational integers behave just as we would expect under addition and multiplication. That is, their sums and products are also rational integers. Moreover, they are the &lt;em&gt;correct&lt;/em&gt; rational integers. Let's make this a bit more formal:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Proposition.&lt;/strong&gt; If $m$ and $n$ are integers, then the sum of their corresponding rational integers is the rational integer corresponding to their sum. That is,&lt;/p&gt;
&lt;p&gt;$$\frac{m}{1}+\frac{n}{1}=\frac{m+n}{1}.$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; The result actually follows immediately from our definition of rational addition, since&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
\frac{m}{1}+\frac{n}{1} &amp;amp;= \frac{m\cdot 1 + 1\cdot n}{1\cdot 1} \\&lt;br&gt;
&amp;amp;= \frac{m+n}{1}.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;We can do exactly the same sort of thing for multiplication:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Proposition.&lt;/strong&gt; If $m$ and $n$ are integers, then the product of their corresponding rational integers is the rational integer corresponding to their product. That is,&lt;/p&gt;
&lt;p&gt;$$\frac{m}{1}\cdot\frac{n}{1}=\frac{mn}{1}.$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Again, the result follows directly from our definition of rational multiplication. Note that&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
\frac{m}{1}\cdot\frac{n}{1} &amp;amp;= \frac{m\cdot n}{1\cdot 1} \\&lt;br&gt;
&amp;amp;= \frac{mn}{1}.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So these rational integers really do correspond to the integers in a one-to-one manner. Since there's no functional difference between rational integers and integers, we might as well just say they're the same thing.&lt;/p&gt;
&lt;h3 id="orderingtherationalsanameorderingtherationals"&gt;Ordering the Rationals&lt;a name="ordering-the-rationals"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;One of the requirements we imposed on our construction last post was that the rationals should be ordered in a way that's compatible with the integers. That means that if $n$ and $m$ are integers with $n &amp;lt; m$, then we definitely want it to be the case that $\frac{n}{1} &amp;lt; \frac{m}{1}$. That is, integers and rational integers should have the same order.&lt;/p&gt;
&lt;p&gt;But in addition to rational integers, all the other rational numbers should be comparable as well. This is done easily enough.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; Given two rational numbers $\frac{a}{b}$ and $\frac{c}{d}$ in canonical form, their &lt;strong&gt;order&lt;/strong&gt; is determined by saying that $\frac{a}{b} &amp;lt; \frac{c}{d}$ if and only if $ad&amp;lt;bc$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Just as a quick check that this definition of order makes any sense, let's look at a couple simple examples.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; Consider the fractions $\frac{1}{2}$ and $\frac{2}{3}$. These are already in canonical form, and we would certainly expect $\frac{1}{2}$ to be less than $\frac{2}{3}$. Let's check that this is indeed the case.&lt;/p&gt;
&lt;p&gt;According to the definition, we just need to make sure that $1 \cdot 3 &amp;lt; 2\cdot 2$. This is obviously true ($3&amp;lt;4$) and so we're done.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; Consider the fractions $\frac{0}{1}$ and $\frac{-3}{2}$. Of course we hope it should be the case that $\frac{-3}{2}$ is less than $\frac{0}{1}$.&lt;/p&gt;
&lt;p&gt;Again, plugging these straight into the definition, we see that&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
-3\cdot 1 &amp;amp;= -3 \\&lt;br&gt;
&amp;amp;&amp;lt; 0 \\&lt;br&gt;
&amp;amp;= 2\cdot 0.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;These sanity checks indicate that we're on the right track with our definition of order. But we need to guarantee that our order extends that of the integers. Let's do that now.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Proposition.&lt;/strong&gt; If $m$ and $n$ are integers with $m&amp;lt;n$ then $\frac{m}{1} &amp;lt; \frac{n}{1}$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; There's really not much to prove. Since $m&amp;lt;n$ we certainly have that $m\cdot 1 = 1\cdot n$. By the definition of order, this means that $\frac{m}{1} &amp;lt; \frac{n}{1}$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So this order is compatible with the order on the integers. Yay! Now that our rational numbers are ordered, we're allowed to put them on the number line if we so choose.&lt;/p&gt;
&lt;h3 id="fillingthegapsanamefillingthegaps"&gt;Filling the Gaps&lt;a name="filling-the-gaps"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Our motivation for inventing rational numbers was to fill the two types of gaps we identified in the previous post as being missing from the integers. Namely, we required that our rational numbers satisfy the following properties:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;If $a$ and $b$ are integers with $a\ne 0$, there exists a rational number $x$ for which $ax=b$.&lt;/li&gt;
&lt;li&gt;If $p$ and $q$ are rational numbers with $p&amp;lt;q$, there exists a rational number $x$ for which $p&amp;lt;x&amp;lt;q$.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;It's actually pretty straightforward to show that our construction guarantees these properties. Let's get straight to work!&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Proposition.&lt;/strong&gt; If $a$ and $b$ are integers with $a\ne 0$, there exists a rational number $x$ for which $ax=b$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Technically we should consider the rational integers $\frac{a}{1}$ and $\frac{b}{1}$. We need to show that there is a rational number $\frac{p}{q}$ for which $\frac{a}{1}\cdot\frac{p}{q}=\frac{b}{1}$.&lt;/p&gt;
&lt;p&gt;We argue that taking $p=b$ and $q=a$ will yield the desired result. That is, we only need to verify that $\frac{a}{1}\cdot\frac{b}{a}=\frac{b}{1}$. Notice that, from the definition of rational multiplication,&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
\frac{a}{1}\cdot\frac{b}{a} &amp;amp;= \frac{ab}{1a} \\&lt;br&gt;
&amp;amp;= \frac{ab}{a}.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;Since $\gcd(ab, a)=a$, the canonical form for the result is $\frac{b}{1}$, as desired.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Neat! We plugged one type of gap and now have solutions to lots of equations. All that's left is to check that we've filled the other type of gap.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Proposition.&lt;/strong&gt; If $p$ and $q$ are rational numbers with $p&amp;lt;q$, there exists a rational number $x$ for which $p&amp;lt;x&amp;lt;q$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Suppose $p=\frac{p_1}{p_2}$ and $q=\frac{q_1}{q_2}$ are in canonical form. We argue that taking $x=\frac{p_1q_2 + p_2q_1}{2p_2q_2}$ will suffice. To see that we did not pull this out of thin air, notice that $x$ is really just the &amp;quot;average&amp;quot; of $p$ and $q$ put into fractional form, and thus we should expect it to sit directly between them on the number line.&lt;/p&gt;
&lt;p&gt;We need to verify that $p&amp;lt;x$ and that $x&amp;lt;q$. To do so, we use the definition of order.&lt;/p&gt;
&lt;p&gt;For the first inequality, note first that since $p&amp;lt;q$, we have that $p_1q_2&amp;lt;p_2q_1$. Thus,&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
(p_1)(2p_2q_2) &amp;amp;= (p_2)(2p_1q_2) \\&lt;br&gt;
&amp;amp;&amp;lt; (p_2)(p_1q_2 + p_2q_1),&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;It follows then that $\frac{p_1}{p_2} &amp;lt; \frac{p_1q_2 + p_2q_1}{2p_2q_2}$. That is, $p&amp;lt;x$.&lt;/p&gt;
&lt;p&gt;The proof that $x&amp;lt;q$ is completely analagous to the above.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;And there we have it. Our construction of the rational numbers satisfies all the properties we wanted it to!&lt;/p&gt;
&lt;p&gt;So why did we do all this again? The short answer is because we can, and because it's kind of cool. The real answer is that we construct things in mathematics from the ground up so that&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;We know that the objects we are working with actually exist.&lt;/li&gt;
&lt;li&gt;We know exactly what properties our objects satisfy.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I don't feel comfortable working with anything I can't get a feel for in this way.&lt;/p&gt;
&lt;h3 id="fieldaxiomsanamefieldaxioms"&gt;Field Axioms&lt;a name="field-axioms"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Our rational numbers actually have a few more properties than I've mentioned. Technically, they form what is called an ordered field. I won't prove all of the field axioms here, but from what I've done already and the properties of the integers, you should be able to fill in the gaps pretty easily now. I'll just give you the axioms and then call it quits.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; A &lt;strong&gt;field&lt;/strong&gt; is a set $\mathbb{F}$ equipped with two operations, addition $+$ and multiplication $\cdot$, which satisfy the following properties:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Associativity of Addition&lt;/strong&gt;: For all $a,b,c\in\mathbb{F}$, $a+(b+c)=(a+b)+c$.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Commutativity of Addition&lt;/strong&gt;: For all $a,b\in\mathbb{F}$, $a+b=b+a$.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Additive Identity&lt;/strong&gt;: There exists $0\in\mathbb{F}$ for which $0+a=a$ for any $a\in\mathbb{F}$.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Additive Inverses&lt;/strong&gt;: For all $a\in\mathbb{F}$, there exists $-a\in\mathbb{F}$ for which $a+(-a)=0$.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Associativity of Multiplication&lt;/strong&gt;: For all $a,b,c\in\mathbb{F}$, $a\cdot (b\cdot c)=(a\cdot b)\cdot c$.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Commutativity of Multiplication&lt;/strong&gt;: For all $a,b\in\mathbb{F}$, $a\cdot b=b\cdot a$.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Multiplicative Identity&lt;/strong&gt;: There exists $1\in\mathbb{F}$ with $1\ne 0$ for which $1\cdot a=a$ for any $a\in\mathbb{F}$.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Multiplicative Inverses&lt;/strong&gt;: For all $a\in\mathbb{F}$ with $a\ne 0$, there exists $a^{-1}\in\mathbb{F}$ for which $a\cdot a^{-1}=1$.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Distributivity of Multiplication over Addition&lt;/strong&gt;: For all $a,b,c\in\mathbb{F}$, $a\cdot (b+c) = a\cdot b+a\cdot c$.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Furthermore, $\mathbb{F}$ is an &lt;strong&gt;ordered field&lt;/strong&gt; if there is an order $&amp;lt;$ on $\mathbb{F}$ which is compatible with the field structure in the following sense: If $a,b\in\mathbb{F}$ and $a,b\ge 0$, then $a+b\ge 0$ and $a\cdot b\ge 0$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;That's pretty much it. It's not too hard to show that the rationals $\Q$ form an ordered field under the definitions we gave for addition and multiplication. The additive identity is $\frac{0}{1}$, the multiplicative identity is $\frac{1}{1}$, the additive inverse of $\frac{a}{b}$ is $\frac{-a}{b}$, and the multiplicative inverse of $\frac{a}{b}$ is $\frac{b}{a}$ (provided $a\ne 0$).&lt;/p&gt;
&lt;p&gt;The integers $\Z$ do &lt;em&gt;not&lt;/em&gt; form an ordered field because they are lacking multiplicative inverses. This is precisely the first &amp;quot;gap&amp;quot; that we filled.&lt;/p&gt;
&lt;p&gt;So... yeah.&lt;/p&gt;
</content:encoded></item><item><title>Connectedness</title><description>In this post, I'm going to prove the Intermediate Value Theorem and the One-Dimensional Brouwer Fixed Point Theorem, which are two results that are undeniably and unreasonably useful. In order to prove them, however, we will need to study the notion of connectedness.</description><link>http://localhost:2368/connectedness/</link><guid isPermaLink="false">5c6e5add0ba2bb003f86050b</guid><dc:creator>Eric Shapiro</dc:creator><pubDate>Thu, 21 Feb 2019 08:02:07 GMT</pubDate><content:encoded>&lt;h3 id="contents"&gt;Contents&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#connected-spaces"&gt;Connected Spaces&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#some-cool-results"&gt;Some Cool Results&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="connectedspacesanameconnectedspaces"&gt;Connected Spaces&lt;a name="connected-spaces"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I decided to postpone the second half of my construction of the rational numbers because I needed to break up the monotony a bit.&lt;/p&gt;
&lt;p&gt;I'm finally about to show you some really cool stuff. In this post, I'm going to prove the Intermediate Value Theorem and the One-Dimensional Brouwer Fixed Point Theorem, which are two results that are undeniably and unreasonably useful. In order to prove them, however, we will need to study the notion of connectedness. I'll probably save path-connectedness for a later time, since this post will be long enough as is.&lt;/p&gt;
&lt;p&gt;Connectedness is pretty much exactly what you'd expect it to be - if something is connected then that means it is all one coherent piece. This is a very hand-wavy statement though, so let's try to come up with a real definition that makes sense in the context of topological spaces. It might be better to start by considering what it is that makes a space disconnected. Let's look at this picture of a space $X$ which we should certainly call disconnected (as a subspace of the plane $\R^2$ with the standard topology):&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2019/02/disconnectedspace1.svg" alt="disconnectedspace1"&gt;&lt;/p&gt;
&lt;p&gt;The space $X$ is very clearly comprised of two distinct components that are separated from each other. Now here is the key insight: each of these components is both open and closed in $X$. For this particular example, we can see that each component is open because it is the intersection of $X$ with an open set in $\R^2$ (remember that this is the definition of an open set in the subspace topology).&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2019/02/disconnectedspace2.svg" alt="disconnectedspace2"&gt;&lt;/p&gt;
&lt;p&gt;Similarly, each component is closed because it is the intersection of $X$ with a closed set in $\R^2$.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2019/02/disconnectedspace3.svg" alt="disconnectedspace3"&gt;&lt;/p&gt;
&lt;p&gt;So in disconnected spaces, there can be numerous sets that are both open and closed. This is something that is not true of connected spaces!&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; A space $X$ is &lt;strong&gt;connected&lt;/strong&gt; if its only subsets which are both open and closed are $\varnothing$ and $X$ itself.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; A space $X$ is &lt;strong&gt;disconnected&lt;/strong&gt; if it is not connected, i.e., there exists a nonempty proper subset $A\subset X$ which is both open and closed in $X$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;We may occasionally also wish to ask whether subsets of a topological space are connected, and there is an easy way to look at this by using definitions we already have:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; A subset $A$ of a topological space $X$ is &lt;strong&gt;connected&lt;/strong&gt; if $A$ is connected when viewed as a subspace of $X$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is just one of several equivalent and common ways that we may define connectedness. Let's take a look at two more, since they will be convenient for proofs later in this post. For the first equivalent definition, it is somewhat easier to talk about disconnectedness.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; A topological space $X$ is disconnected if and only if there exist nonempty open sets $U,V\subset X$ for which $U\cap V=\varnothing$ and $U\cup V=X$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Suppose first that $X$ is disconnected. That is, there exists a nonempty proper subset $A\subset X$ which is both open and closed in $X$. Then by definition, $X-A$ is also both open and closed, and $X-A$ is nonempty because $A\ne X$. We observe that $A\cap(X-A)=\varnothing$ and $A\cup(X-A)=X$. Thus, we have demonstrated nonempty open sets $U=A$ and $V=X-A$ for which $U\cap V=\varnothing$ and $U\cup V=X$.&lt;/p&gt;
&lt;p&gt;Suppose next that there exist nonempty open sets $U,V\subset X$ for which $U\cap V=\varnothing$ and $U\cup V=X$. Then $V=X-U$ is also closed since it is the complement of the open set $U$. Note also that $V$ is nonempty by hypothesis, and $V\ne X$ because $U$ is nonempty. It follows that $X$ is disconnected.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Just looking at this new phrasing of disconnectedness, we see that it is immediately applicable to my above example. Clearly that space $X$ is the union of two disjoint, nonempty open sets. Before I move on, let me formally state this new definition in the context of connectedness.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; If a space $X$ is disconnected, then a &lt;strong&gt;separation&lt;/strong&gt; of $X$ is a pair of nonempty open sets $U,V\subset X$ for which $U\cap V=\varnothing$ and $U\cup V=X$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Corollary.&lt;/strong&gt; A topological space $X$ is &lt;strong&gt;connected&lt;/strong&gt; if it does not have a separation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The next equivalent definition of connectedness may look a little bit strange to you right now, but it will make our lives a lot easier in two of the proofs that lie ahead. Recall that a constant function $f$ has $f(x_1)=f(x_2)$ for all $x_1,x_2$ in its domain.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; A topological space $X$ is connected if and only if every continuous function $f:X\to\{0,1\}$ is constant, where $\{0,1\}$ is equipped with the discrete topology.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; We prove each direction by contraposition. We argue first that if a continuous function $f:X\to\{0,1\}$ is not constant, then $X$ is not connected.&lt;/p&gt;
&lt;p&gt;Suppose there exists a nonconstant continuous function $f:X\to\{0,1\}$. Since $f$ is not constant, it takes on at least two values in its codomain and thus it must be the case that $f[X]=\{0,1\}$, so clearly $f$ is surjective. Define $U=f^{-1}\big[{0}\big]$ and $V=f^{-1}\big[{1}\big]$. Certainly $U\cap V=\varnothing$ and $U\cup V=X$. Also, $U$ and $V$ are nonempty because $f$ is surjective. It follows that $U$ and $V$ form a separation of $X$, and so $X$ is not connected.&lt;/p&gt;
&lt;p&gt;We argue next that if $X$ is not connected, then there exists a continuous function $f:X\to\{0,1\}$ which is not constant.&lt;/p&gt;
&lt;p&gt;Suppose $X$ is not connected. Then there exists a separation $U,V$ of $X$. Define $f:X\to\{0,1\}$ by&lt;/p&gt;
&lt;p&gt;$$f(n) =&lt;br&gt;
\begin{cases}&lt;br&gt;
0 &amp;amp; \text{if } x\in U, \\&lt;br&gt;
1 &amp;amp; \text{if } x\in V.&lt;br&gt;
\end{cases}$$&lt;/p&gt;
&lt;p&gt;This function is nonconstant because both $U$ and $V$ are nonempty. It is obvious that $f^{-1}\big[\{1\}\big]=U$ and $f^{-1}\big[\{0\}\big]=V$, which are both open in $X$. Furthermore, $f^{-1}\big[\{0,1\}\big]=X$ and $f^{-1}[\varnothing]=\varnothing$ are both open in $X$. We have demonstrated that the preimage of every open set in $\{0,1\}$ is open in $X$, and so $f$ is continuous by definition.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Let's rewrite this as yet another definition of connectedness.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; A topological space $X$ is &lt;strong&gt;connected&lt;/strong&gt; if every continuous function $f:X\to\{0,1\}$ is constant.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This definition may seem a little bit stranger than the other two, but it is perfectly natural if we recall that continuous functions map points that are close together to points that are close together. In a connected space, all points are close together and thus a continuous function cannot bridge the gap between $0$ and $1$ - it must stay constant for all values of the domain. Of course, there is nothing special about $\{0,1\}$. We could just has easily used any other discrete two-point space. I'm about to prove a useful theorem whose proof is made much easier by this new definition of connectedness, but first we will need the following lemma.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Lemma.&lt;/strong&gt; Let $X,Y$ denote topological spaces, let $A$ denote a subspace of $X$ and let $f:X\to Y$ be a continuous map. The restriction $f\mid_A:A\to Y$, defined by $f\mid_A(a)=f(a)$ for each $a\in A$, is continuous.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Choose any open set $U\subseteq Y$. Since $f$ is continuous, $f^{-1}[U]$ is open in $X$. Thus, $f\mid_A^{-1}[U]=A\cap f^{-1}[U]$ is open in $A$ by the definition of the subspace topology, and thus $f\mid_A$ is continuous.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now we have the machinery to prove the following intuitive theorem:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; Let $X$ denote a topological space and suppose $\{A_i\}_{i=1}^n$ is a collection of $n$ connected subsets of $X$. If $A_i\cap A_{i+1}$ is nonempty for each $1\leq i&amp;lt; n$, then the set $\bigcup\limits_{i=1}^n A_i$ is connected.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; We will proceed by induction on $n$, with our base case $n=1$ being too obvious to require proof.&lt;/p&gt;
&lt;p&gt;Suppose $\{A_i\}_{i=1}^{n+1}$ are connected with $A_i\cap A_{i+1}\ne\varnothing$ for every $1\le i&amp;lt; n+1$, and that $\bigcup\limits_{i=1}^n A_i$ is connected. Suppose also that $f:\bigcup\limits_{i=1}^{n+1}A_i\to\{0,1\}$ is continuous. Then $f\mid_{\bigcup\limits_{i=1}^n A_i}:\bigcup\limits_{i=1}^n A_i\to\{0,1\}$ and $f\mid_{A_{n+1}}:A_{n+1}\to\{0,1\}$ are also continuous, and they are thus constant because their domains are connected. Since $A_n\cap A_{n+1}$ is nonempty, certainly $\left(\bigcup\limits_{i=1}^n A_i\right)\cap A_{n+1}$ is nonempty, and so there exists a point $x\in\left(\bigcup\limits_{i=1}^n A_i\right)\cap A_{n+1}$. Thus, because $f$ must be well defined, $f\mid_{\bigcup\limits_{i=1}^n A_i}(x)=f\mid_{A_{n+1}}(x)$. Since $f\mid_{\bigcup\limits_{i=1}^n A_i}$ and $f\mid_{A_{n+1}}$ are both constant and they agree at one point, they must agree at every point. Thus, $f$ is constant and so $\bigcup\limits_{i=1}^{n+1} A_i$ is connected.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The proof is simple but looks a bit ugly rendered this way, for which I apologize. The theorem itself should be fairly obvious, and is in fact quite easy to think of visually. Take the following diagram, for instance:&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2019/02/connectedsequence.svg" alt="connectedsequence"&gt;&lt;/p&gt;
&lt;p&gt;This is a collection of six connected subsets of $\R^2$, each of which intersects the next in precisely one point. (They may or may not correspond to the six Bagel Bites I am about to enjoy.) From our theorem, it follows that their union is connected. Of course, we could have any number of connected subsets that intersect each other in different ways, as long as the successive pairwise intersections are nonempty. I will not prove it here, but this result also applies for any collection of connected subsets (even uncountably infinite).&lt;/p&gt;
&lt;p&gt;I mentioned a few posts back that much of the study of topology is focused on distinguishing between non-homeomorphic spaces. Connectedness offers a way of doing exactly that, because it is a topological property. What I mean by that is this: if two spaces are homeomorphic and one is connected, then so is the other.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; Let $X,Y$ denote topological spaces, let $f:X\to Y$ be a homeomorphism and suppose $X$ is connected. Then $Y$ is connected.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; We will prove the contrapositive. Suppose $Y$ is not connected, so that there exist open sets $U,V$ that separate $Y$. We argue that $f^{-1}[U]$ and $f^{-1}[V]$ form a separation of $X$.&lt;/p&gt;
&lt;p&gt;Clearly $f^{-1}[U]$ and $f^{-1}[V]$ are open because $f$ is continuous, and they are each nonempty because $f$ is surjective. In addition, because $U\cap V=\varnothing$, we have that&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
f^{-1}[U]\cap f^{-1}[V]&amp;amp;=f^{-1}[U\cap V] \\&lt;br&gt;
&amp;amp;=f^{-1}[\varnothing] \\&lt;br&gt;
&amp;amp;=\varnothing.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;Similarly, because $U\cup V=Y$, we have that&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
f^{-1}[U]\cup f^{-1}[V]&amp;amp;=f^{-1}[U\cup V] \\&lt;br&gt;
&amp;amp;=f^{-1}[Y] \\&lt;br&gt;
&amp;amp;=X.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;It follows that $f^{-1}[U]$ and $f^{-1}[V]$ form a separation of $X$, so $X$ is not connected.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Really all we used was continuity and surjectivity of $f$, so saying that $f$ was a homeomorphism actually weakened the result a little bit. It's actually true that all continuous functions preserve connectedness! I won't prove it though, because it's really just a teensy modification of the above proof.&lt;/p&gt;
&lt;p&gt;Clearly we can distinguish between topological spaces as follows: if one space is connected and another isn't, then the spaces are not homeomorphic. However, we can also use connectedness in a somewhat trickier way to distinguish between certain connected spaces!&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; A &lt;strong&gt;cutset&lt;/strong&gt; $A$ of a connected topological space $X$ is a subset of $X$ for which $X-A$ is disconnected.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; A &lt;strong&gt;cutpoint&lt;/strong&gt; $x$ of a connected topological space $X$ is a point of $X$ for which $\{x\}$ is a cutset, i.e., $X-\{x\}$ is disconnected.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; Let's look again the connected set $A=\bigcup\limits_{i=1}^6 A_i$ depicted below, and consider the points $x$ and $y$.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2019/02/cutset.svg" alt="cutset"&gt;&lt;/p&gt;
&lt;p&gt;Is $x$ a cutpoint of $A$? No, it is not because $$A-\{x\}=(A_1-\{x\})\cup\bigcup\limits_{i=2}^5 A_i\cup(A_6-\{x\}).$$ Each of the sets being unioned are connected and the intersection of each set with the next is nonempty, so $A-\{x\}$ is connected. If we permute the indices of the $A_i$, the same logic tells us that $y$ is not a cutpoint of $A$.&lt;/p&gt;
&lt;p&gt;However, $\{x,y\}$ is a cutset of $A$ (or, equivalently, $y$ is a cutpoint of $A-\{x\}$). That's because&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
U &amp;amp;= (A_1-\{x\})\cup(A_2-\{y\}) \\&lt;br&gt;
V &amp;amp;= (A_3-\{y\})\cup\bigcup\limits_{i=4}^5 A_i\cup (A_6-\{x\})&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;is a separation of $A-\{x,y\}$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;How can we use cutsets to distinguish between connected spaces? I'm glad you ask.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Theorem. Let $f:X\to Y$ be a homeomorphism between connected spaces $X$ and $Y$. If $A$ is a cutset of $X$, then $f[A]$ is a cutset of $Y$.&lt;/p&gt;
&lt;p&gt;Proof. Since $X-A$ is disconnected, there exists a separation $U,V$ of $X-A$. We argue that $f[U]$ and $f[V]$ form a separation of $Y-f[A]$. Because $f$ is a homeomorphism, $f^{-1}$ is continuous and thus $f[U]=(f^{-1})^{-1}[U]$ and $f[V]=(f^{-1})^{-1}[V]$ are open in $Y$. Since $U$ and $V$ are nonempty, certainly $f[U]$ and $f[V]$ are nonempty. Observe that, because $U\cap V=\varnothing$,&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
f[U]\cap f[V]&amp;amp;=(f^{-1})^{-1}[U]\cap(f^{-1})^{-1}[V]\\&lt;br&gt;
&amp;amp;=(f^{-1})^{-1}[U\cap V]\\&lt;br&gt;
&amp;amp;=f[U\cap V]\\&lt;br&gt;
&amp;amp;=f[\varnothing]\\&lt;br&gt;
&amp;amp;=\varnothing.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;Furthermore, because $U\cup V=X-A$ and $f$ is bijective,&lt;/p&gt;
&lt;p&gt;$$\begin{align}f[U]\cup f[V]&amp;amp;=f[U\cup V]\\&lt;br&gt;
&amp;amp;=f[X-A]\\&lt;br&gt;
&amp;amp;=f[X]-f[A]\\&lt;br&gt;
&amp;amp;=Y-f[A].&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;Thus, $f[U]$ and $f[V]$ separate $Y-f[A]$. It follows that $f[A]$ is a cutset of $Y$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To see how this can be applied, let's take a look at another example.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; The subspace $[0,2\pi)$ of $\R$ and the unit circle $S^1=\{(x,y)\in\R^2\mid x^2+y^2=1\}$ as a subspace of $\R^2$ are not homeomorphic. I have not yet shown that either of these sets is connected, but for now we will take it for granted that they both are. Any point $x\in [0,2\pi)$ with $x\ne 0$ is a cutpoint of $[0,2\pi)$ because $$[0,2\pi)-\{x\}=[0,x)\cup (x,2\pi),$$ which is already expressed as the union of its separation. On the other hand, $S^1$ has no cutpoints. For any $x\in S^1$, the space $S^1-\{x\}$ is homeomorphic to an open interval (which is connected). Any cutset of $S^1$ would therefore consist of at least two points, and so cannot be the homeomorphic image of a cutpoint for $[0,2\pi)$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I was just very hand-wavy by claiming that certain sets were connected without proving it. Let me at least prove that $\R$ is connected, from which it will immediately follow that open intervals are connected (because they are homeomorphic to $\R$). The proof will require the following fact about the real numbers, which itself needs to be prefaced with the following definitions.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; Given a subset $A$ of $\R$, a number $x\in\R$ is an &lt;strong&gt;upper bound&lt;/strong&gt; for $A$ if $x\ge a$ for every $a\in A$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; A subset $A$ of $\R$ is &lt;strong&gt;bounded above&lt;/strong&gt; if an upper bound for $A$ exists.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; Given a subset $A$ of $\R$, a number $x\in\R$ is the &lt;strong&gt;supremum&lt;/strong&gt; (or &lt;strong&gt;least upper bound&lt;/strong&gt;) of $A$ if $x$ is an upper bound for $A$ and $x\le y$ for every upper bound $y$ of $A$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Least Upper Bound Property.&lt;/strong&gt; Any nonempty subset of $\R$ which is bounded above has a supremum.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is one of the defining properties of the real numbers, and it is in fact equivalent to the fact that every Cauchy sequence in $\R$ converges (if you've taken an analysis class, this should seem familiar). We will take the least upper bound property for granted, although it can be proven from the construction of the real numbers as either Dedekind cuts or equivalence classes of rational Cauchy sequences. You don't need to understand any of this to move forward. Just smile and nod while you wait for me to shut up.&lt;/p&gt;
&lt;p&gt;Here's the proof that $\R$ is connected. It's pretty gross.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; The set $\R$ of real numbers, equipped with the standard topology, is connected.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; We proceed by contradiction, supposing that $\R$ is not connected. This means that there exist open sets $U$ and $V$ which separate $\R$. Choose $u\in U$ and $v\in V$, and assume without loss of generality that $u&amp;lt;v$. Define $U'=[u,v]-V$ and $V'=[u,v]-U$. Using De Morgan's law and the fact that $V\cap U=\varnothing$, it follows that&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
U'\cup V'&amp;amp;=\big([u,v]-V\big)\cup\big([u,v]-U\big)\\&lt;br&gt;
&amp;amp;=[u,v]-(V\cap U)\\&lt;br&gt;
&amp;amp;=[u,v]-\varnothing\\&lt;br&gt;
&amp;amp;=[u,v].&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;The set $U'$ is nonempty because $u\in U'$ and it is bounded above by $v$, and so $U'$ has a supremum, $s$. Clearly $s\in [u,v]$, so either $s\in U'$ or $s\in V'$.&lt;/p&gt;
&lt;p&gt;Suppose first that $s\in U'$. Then because $U'$ is open in $[u,v]$ and $v\notin U'$, there exists $d\in[u,v]$ for which $[s,d)\subseteq U'$. Then for every $x\in (s,d)$, we have that $x\in U'$ and $x&amp;gt;s$, which is a contradiction because $s$ is the supremum of $U'$.&lt;/p&gt;
&lt;p&gt;Suppose then that $s\in V'$. Then because $V'$ is open in $[u,v]$ and $u\notin V'$, there exists $d\in (u,s)$ for which $(d,s]\subseteq V'$. Then for every $x\in (d,s)$, we have that $x&amp;lt;s$ and $x&amp;gt;y$ for every $y\in U'$, which is again a contradiction because $s$ is the supremum of $U'$.&lt;/p&gt;
&lt;p&gt;Since $s\notin U'$ and $s\notin V'$, it must be true that $s\notin [u,v]$, which contradicts its definition.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id="somecoolresultsanamesomecoolresults"&gt;Some Cool Results&lt;a name="some-cool-results"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;It's time for some fun stuff now. Let's start with the intermediate value theorem, which you may have experienced and ignored in a calculus class.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Intermediate Value Theorem.&lt;/strong&gt; Let $X$ denote a connected space and let $f:X\to\R$ be continuous. If $x,y\in f[X]$ and $c\in [x,y]$, then $c\in f[X]$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; It suffices to consider $c\in (x,y)$, because if $x\in\{x,y\}$ there is nothing to prove. Since $X$ is connected and $f$ is continuous, $f[X]$ is connected in $\R$. We proceed by contradiction.&lt;/p&gt;
&lt;p&gt;Suppose $c\notin f[X]$ and define $U'=(-\infty,c)$ and $V'=(c,\infty)$. Clearly $U'\cap V'=\varnothing$ and $f[X]\subseteq U'\cup V'$. We argue that $U=U'\cap f[x]$ and $V=V'\cap f[X]$ form a separation of $f[X]$. Since $x\in U'$ and $y\in V'$, we have that $U$ and $V$ are nonempty. Furthermore,&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
U\cap V &amp;amp;= (U'\cap f[X])\cap(V'\cap f[X])\\&lt;br&gt;
&amp;amp;= (U'\cap V')\cap f[X]\\&lt;br&gt;
&amp;amp;= \varnothing\cap f[X]\\&lt;br&gt;
&amp;amp;= \varnothing.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;In addition, because $f[X]\subseteq U'\cup V'$, we have that&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
U\cup V &amp;amp;= (U'\cap f[X])\cup(V'\cap f[X])\\&lt;br&gt;
&amp;amp;= (U'\cup V')\cap f[X]\\&lt;br&gt;
&amp;amp;= f[X].&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;Thus, $U$ and $V$ separate $f[X]$, which is a contradiction.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This theorem has many important consequences, but I won't spend too long talking about them right now because I want to get to the Brouwer fixed point theorem. We'll see the intermediate value theorem again though, I promise.&lt;/p&gt;
&lt;p&gt;Of course, before I can talk about a fixed point theorem, it would help if I told you what fixed points were.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; Given a set $X$, a function $f:X\to X$ has a &lt;strong&gt;fixed point&lt;/strong&gt; $x\in X$ if $f(x)=x$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So fixed points are points which stay fixed after a function acts on them.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;One-Dimensional Brouwer Fixed Point Theorem.&lt;/strong&gt; Every continuous map $f:[-1,1]\to[-1,1]$ has a fixed point.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; We proceed by contradiction. Suppose $f:[-1,1]\to[-1,1]$ is continuous but has no fixed point. That is, $f(x)\ne x$ for every $x\in[-1,1]$. Define $g:[-1,1]\to\{-1,1\}$ by&lt;/p&gt;
&lt;p&gt;$$g(x) =&lt;br&gt;
\begin{cases}&lt;br&gt;
-1 &amp;amp; \text{if } f(x) &amp;gt; x, \\&lt;br&gt;
\phantom{-}1 &amp;amp; \text{if } f(x) &amp;lt; x.&lt;br&gt;
\end{cases}$$&lt;/p&gt;
&lt;p&gt;There is an alternative way of writing this: $$g(x)=\frac{f(x)-x}{\abs{f(x)-x}}.$$ Because $f(x)\ne x$ for every $x\in[-1,1]$, clearly $f(x)-x\ne 0$ and $g$ is thus a continuous function. Because $g$ is continuous and its codomain is a discrete two-point set, it must be that $g$ is constant. However, we also have that $g(-1)=1$ and $g(1)=-1$, and so $g$ is not constant - a contradiction.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This might all seem a bit abstract right now, so maybe a diagram will shed some light on why this theorem makes sense.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2019/02/brouwer1d.svg" alt="brouwer1d"&gt;&lt;/p&gt;
&lt;p&gt;Here's a graph of some continuous function $f:[-1,1]\to[-1,1]$. Clearly any such function must intersect the diagonal of the square in at least one point. Any such intersection is a fixed point of $f$.&lt;/p&gt;
&lt;p&gt;There is a more general Brouwer fixed point theorem which works for any dimension, although we cannot prove it yet. The beginning of the proof is very similar to the above proof, though, so let's get as far as we can go. (Recall the $\partial A$ denotes the boundary of a set $A$.)&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Brouwer Fixed Point Theorem.&lt;/strong&gt; Let $B^n$ denote the closed unit ball in $\R^n$. Then every continuous function $f:B^n\to B^n$ has a fixed point.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Beginning of Proof.&lt;/strong&gt; Again, we proceed by contradiction and suppose that $f$ has no fixed points, i.e., $f(x)\ne x$ for every $x\in B^n$. We define a new function $g:B^n\to\partial B^n$ by $$g(x)=\frac{f(x)-x}{d\big(f(x),x\big)},$$ where $d$ is the standard metric.&lt;/p&gt;
&lt;p&gt;We can visualize this function as follows: since every point $x$ is distinct from its image $f(x)$, there is a unique line segment in $B^n$ starting at $f(x)$ and passing through $x$ which intersects the boundary $\partial B^n$ in exactly one point, $g(x)$.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2019/02/brouwernd.svg" alt="brouwernd"&gt;&lt;/p&gt;
&lt;p&gt;Since $f(x)\ne x$ for every $x\in B^n$, $d\big(f(x),x)&amp;gt;0$ for every $x\in B^n$ and thus $g$ is continuous. Furthermore, $g(x)=x$ for every $x\in\partial B^n$ This should lead to a contradiction, but we can't show this right now.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The contradiction is that there is no continuous function which maps the ball to its boundary while keeping the boundary fixed. You can probably visualize why this is in your head - any such &amp;quot;retraction&amp;quot; would require tearing a hole in the ball. Unfortunately, we need the idea of homology in order to establish that there is no retraction to the ball's boundary, and we are a long way from that.&lt;/p&gt;
&lt;p&gt;I think there's time for one last proof. Basically, we will prove that fixed point properties are preserved by homeomorphism.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; Suppose $X$ is a topological space for which every continuous function $f:X\to X$ has a fixed point, and that $Y$ is a space homeomorphic to $X$. Then every continuous function $g:Y\to Y$ has a fixed point.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Let $h:X\to Y$ be a homeomorphism, and let $g:Y\to Y$ be continuous. By hypothesis, $h$ and $h^{-1}$ are continuous, so $h^{-1}\circ g\circ h:X\to X$ is continuous since it is the composition of continuous functions. Thus, $h^{-1}\circ g\circ h$ has a fixed point. That is, there exists some $x\in X$ for which $\big(h^{-1}\circ g\circ h\big)(x)=x$. But then $\big(g\circ h\big)(x)=h(x)$, and thus $h(x)$ is a fixed point of $g$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I'll leave you with the following interesting fact that might occasionally occur to you as you stir hot beverages: the Brouwer fixed point theorem, together with the theorem above, tells us that some particle of your drink will end up in the same place it began. This is because the space occupied by the liquid (presumably a cylinder) is homeomorphic to the three-dimensional closed unit ball.&lt;/p&gt;
</content:encoded></item><item><title>Constructing the Rational Numbers (1)</title><description>We work with number systems every day, but we just sort of take their existence for granted. However, it is possible to construct all of these number systems from scratch.</description><link>http://localhost:2368/constructing-the-rational-numbers-1/</link><guid isPermaLink="false">5c6ce0a7a4e2f60287eae2a9</guid><dc:creator>Eric Shapiro</dc:creator><pubDate>Wed, 20 Feb 2019 05:08:09 GMT</pubDate><content:encoded>&lt;h3 id="contents"&gt;Contents&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#construction"&gt;The Construction&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="introductionanameintroduction"&gt;Introduction&lt;a name="introduction"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;It's been a very long time since I've posted, so I figured I'd kick things off again with one of my favorite topics.&lt;/p&gt;
&lt;p&gt;We work with number systems every day, but we just sort of take their existence for granted. However, it is possible to construct all of these number systems from scratch.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The natural numbers are built from sets.&lt;/li&gt;
&lt;li&gt;The integers are built from natural numbers.&lt;/li&gt;
&lt;li&gt;The rational numbers are built from integers.&lt;/li&gt;
&lt;li&gt;The real numbers are built from rational numbers.&lt;/li&gt;
&lt;li&gt;The complex numbers are built from real numbers.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We could go on and on, since there are also quaternions, octonions and god knows what else.&lt;/p&gt;
&lt;p&gt;There is an obvious hierarchy here, and if I wanted to do things right I would start off at the very lowest level by constructing the natural numbers. Maybe I'll do a post on each of these constructions at some point, but for now I think I'll start in the middle.&lt;/p&gt;
&lt;p&gt;We are going to assume that we already have the set $\mathbb{Z}$ of integers and all of their properties, and we will work from there. That means we know everything about their arithmetic (addition, subtraction and multiplication), as well as their other properties such as order.&lt;/p&gt;
&lt;p&gt;The first thing to consider whenever we want to construct a new number system is what is missing from what we already have? What is not present in the set of integers that we would like to be there? What sorts of problems can we phrase in terms of integers that don't have integer solutions but should have some sort of solution?&lt;/p&gt;
&lt;p&gt;What immediately springs to mind is the following sort of equation:&lt;/p&gt;
&lt;p&gt;$$2x = 1.$$&lt;/p&gt;
&lt;p&gt;Obviously we want to scream out to the heavens that $x=\frac{1}{2}$. However, there is no such thing as a half in the set of integers. We have no concept of fractions or division, and so the above equation actually has no solution right now.&lt;/p&gt;
&lt;p&gt;So we'd like our rational numbers to be able to fill in this sort of gap and provide answers to equations of the form $ax = b$, where $a$ and $b$ are integers. But there's an even more obvious criterion we would like our new numbers to satisfy.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2019/02/integer_line.svg" alt="integer_line"&gt;&lt;/p&gt;
&lt;p&gt;Here's a traditional illustration of the &amp;quot;number line.&amp;quot; It may seem weird to even think about this since it's so ingrained in us after years of doing mathematics, but why do we draw our numbers on a line? Well the reason they can be layed out linearly to begin with is their order: $2$ comes after $1$ and before $3$, etc. But putting them on a line like this suggests something else – that there should be something &lt;em&gt;between&lt;/em&gt; them.&lt;/p&gt;
&lt;p&gt;That is, we would like our new rational numbers to have the property that between any two rational numbers there is another rational number. This is certainly something that the integers don't obey. There is no integer between $1$ and $2$.&lt;/p&gt;
&lt;p&gt;Lastly, we would like our rational numbers to &lt;em&gt;extend&lt;/em&gt; the integers in such a way that we can view the integers as sitting &amp;quot;inside&amp;quot; them, as on the number line. Furthermore, we would like the rational numbers to extend their arithmetic as well. Addition, multiplication and subtraction should all be defined and compatible when we restrict ourselves to talking about integers.&lt;/p&gt;
&lt;p&gt;Let's summarize all of that:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Desired Properties of the Rational Numbers&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;There is a subset of the rational numbers which behaves exactly like the integers.&lt;/li&gt;
&lt;li&gt;Rational numbers can be multiplied, added or subtracted in a way that extends the integers and has all the usual properties.&lt;/li&gt;
&lt;li&gt;The rational numbers can be ordered in a way that extends the integers.&lt;/li&gt;
&lt;li&gt;If $a$ and $b$ are integers with $a\ne 0$, there exists a rational number $x$ for which $ax=b$.&lt;/li&gt;
&lt;li&gt;If $p$ and $q$ are rational numbers with $p&amp;lt;q$, there exists a rational number $x$ for which $p&amp;lt;x&amp;lt;q$.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;If whatever construction we come up with has all of the above properties, we'll have been successful. With all of that in mind, let's get started.&lt;/p&gt;
&lt;h3 id="theconstructionanameconstruction"&gt;The Construction&lt;a name="construction"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;We have a significant advantage here in that we already know exactly what our rational numbers should end up looking like: they should resemble fractions $\frac{p}{q}$ where $p$ and $q$ are integers and $q\ne 0$. We even know what their arithmetic should like like in terms of these fractions. Thus, we are able to draw inspiration from our preconceived notion of what they are and how they should behave. However, we will have to build the concept of &amp;quot;fraction&amp;quot; from the ground up, since it does not exist for us currently.&lt;/p&gt;
&lt;p&gt;We might not have fractions, but we already have the next best thing – &lt;strong&gt;cartesian products&lt;/strong&gt;. Basically a fraction is just a pair of integers, right? So instead of $\frac{p}{q}$, why not just write $(p, q)$? This is actually very close to what we'll end up doing, but it doesn't quite get us where we need to be.&lt;/p&gt;
&lt;p&gt;To see why, recall that any fraction has infinite equivalent representations. For example,&lt;/p&gt;
&lt;p&gt;$$\frac{1}{2}=\frac{2}{4}=\frac{-100}{-200}=\frac{1024}{2048}=\cdots$$&lt;/p&gt;
&lt;p&gt;Unfortunately, our ordered pair idea doesn't allow for this sort of equivalent representation. Certainly $(1, 2)\ne (2, 4)$. They are completely different ordered pairs because their components are different integers! However, we are already equipped with a way to identify these ordered pairs – as a quotient set, by defining an equivalence relation on them.&lt;/p&gt;
&lt;p&gt;At this point, if you have not read my post on &lt;a href="http://localhost:2368/equivalence-relations-and-quotient-sets/"&gt;Equivalence Relations and Quotient Sets&lt;/a&gt;, I would strongly encourage you to pause here and give it a thorough read. It is the main tool we will be using in our construction and is therefore of critical importance to the rest of this post.&lt;/p&gt;
&lt;p&gt;The idea here is to define an equivalence relation $\sim$ on $\mathbb{Z}\times\mathbb{Z}^*$ (the set of ordered pairs of integers whose second component is nonzero) for which&lt;/p&gt;
&lt;p&gt;$$(1, 2) \sim (2, 4) \sim (-100, -200) \sim (1024, 2048) \sim \cdots$$&lt;/p&gt;
&lt;p&gt;and more generally, if $(p, q)\in\mathbb{Z}\times\mathbb{Z}^*$ and $n\in\mathbb{Z}$ then $(p, q) \sim (np, nq)$.&lt;/p&gt;
&lt;p&gt;Let's look back to our intuitive understanding of fractions to see how we might define this equivalence relation. If two fractions are equal, we can &amp;quot;cross multiply&amp;quot; them to obtain an expression purely in terms of integers. That is, if $\frac{a}{b}=\frac{c}{d}$ then $ad=bc$. We will use this to define the following relation:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; We define the relation $\sim_\mathbb{Q}$ on the set $\mathbb{Z}\times\mathbb{Z}^*$ as follows:&lt;/p&gt;
&lt;center&gt;$(a, b) \sim_\mathbb{Q} (c, d)$ if and only if $ad=bc$,&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where $a,b,c$ and $d$ are integers with $b,d\ne 0$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In the definition above, $\sim_\mathbb{Q}$ is just a symbol meant to distinguish this particular relation. This is not a standard notation or something you will ever need to use again outside of the construction in this post.&lt;/p&gt;
&lt;p&gt;Things are looking good so far. We've managed to rephrase equivalence of fractions solely in terms of ordered pairs of integers. Let's not get too far ahead of ourselves, though. We need to show that this is actually an equivalence relation!&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; The relation $\sim_\mathbb{Q}$ is an equivalence relation on the set $\mathbb{Z}\times\mathbb{Z}^*$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; We need to show that $\sim_\mathbb{Q}$ is symmetric, reflexive and transitive.&lt;/p&gt;
&lt;p&gt;We argue first that it is symmetric. Choose $a, b\in Z$ with $b\ne 0$. Certainly $ab=ba$ since multiplication of integers is commutative and so $(a, b) \sim_\mathbb{Q} (a, b)$ by the definition of this relation.&lt;/p&gt;
&lt;p&gt;We argue next that it is reflexive. Choose $a,b,c,d\in\mathbb{Z}$ with $b,d\ne 0$ and suppose that $(a,b) \sim_\mathbb{Q} (c,d)$. Then, by definition, we have that $ad=bc$. Again, from the commutativity of integer multiplication, we have that $cb=da$. Thus $(c,d) \sim_\mathbb{Q} (a,b)$.&lt;/p&gt;
&lt;p&gt;Lastly, we argue that it is transitive. Choose $a,b,c,d,e,f\in\mathbb{Z}$ with $b,d,f\ne 0$. Suppose that $(a,b) \sim_\mathbb{Q} (c,d)$ and that $(c,d) \sim_\mathbb{Q} (e,f)$. Then $ad=bc$ and $cf=de$ by definition. Since $cf$ and $de$ are equal, we may multiply the respective sides of the equation $ad=bc$ by these quantities without affecting the equality. That is, $adcf=bcde$. By commutativity, we then have $afdc=bedc$, and so $af=be$. Thus $(a,b) \sim_\mathbb{Q} (e,f)$, as desired.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I would be remiss if I failed to mention that in proving the transitivity of $\sim_\mathbb{Q}$ above, we used a property of the integers that might require some explaining. We cancelled the quantity $dc$ from both sides of an equation involving only integers. However, the integers don't have a concept of division! What gives?&lt;/p&gt;
&lt;p&gt;We may not be able to divide integers, but we can still cancel them as we did above. Even though I said before we would assume perfect knowledge of all properties of the integers, I think this one merits special mention since it is not mentioned often outside of a modern algebra course.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Right Cancellation Property of the Integers.&lt;/strong&gt; If $a,b$ and $c$ are integers with $c\ne 0$ and $ac=bc$, then $a=b$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Since $ac=bc$, we may subtract $bc$ from both sides to obtain the equation $ac-bc=0$. Factoring this yields $(a-b)c=0$. This can only be the case if either $a-b=0$ or $c=0$, since the integers have no zero divisors. However, $c\ne 0$ by hypothesis, and so it must be that $a-b=0$. That is, $a=b$, completing the proof.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;We used this cancellation property above to cancel the quantity $dc$. There is an analagous left cancellation property, but I think that is obvious and symmetrical enough that I do not need to go into it in detail here.&lt;/p&gt;
&lt;p&gt;Anyway, back to business! We've demonstrated that $\sim_\mathbb{Q}$ is an equivalence relation. This allows us to construct the following quotient set:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; We define the set of rational numbers to be the quotient set&lt;/p&gt;
&lt;p&gt;$$\mathbb{Q}=(\mathbb{Z}\times\mathbb{Z}^*)/\negthickspace\sim_\mathbb{Q}.$$&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is simultaneously a really beautiful idea and a really ugly expression. And if you're confused by this, let's take a step back and examine what this definition really means.&lt;/p&gt;
&lt;p&gt;Recall that the quotient set defined by an equivalence relation is the set of all of its equivalence classes. What do the equivalence classes look like in this case? Well, they are the sets of all ordered pairs which are equivalent. For instance, the following are all elements of $\mathbb{Q}$:&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
[(1,2)] &amp;amp;= \{(1,2),(-2,4),(3,-6),\ldots\}, \\&lt;br&gt;
[(-3,4)] &amp;amp;= \{(-3,4),(3,-4),(-30,40),\ldots\}, \\&lt;br&gt;
[(5,1)] &amp;amp;= \{(5,1),(15,3),(45,9),\ldots\}, \\&lt;br&gt;
[(0,1)] &amp;amp;= \{(0,1),(0,2),(0,-4),\ldots\}.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;And that's because&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
(1,2) &amp;amp; \sim_\mathbb{Q} (-2,4) \sim_\mathbb{Q} (3,-6) \sim_\mathbb{Q} \cdots, \\&lt;br&gt;
(-3,4) &amp;amp; \sim_\mathbb{Q} (3,-4) \sim_\mathbb{Q} (-30,40) \sim_\mathbb{Q} \cdots, \\&lt;br&gt;
(5,1) &amp;amp; \sim_\mathbb{Q} (15,4) \sim_\mathbb{Q} (45,9) \sim_\mathbb{Q} \cdots, \\&lt;br&gt;
(0,1) &amp;amp; \sim_\mathbb{Q} (0, 2) \sim_\mathbb{Q} (0, -4) \sim_\mathbb{Q} \cdots.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;Essentially all we've done is taken, for instance, all of the pairs which we think should correspond to $\frac{1}{2}$ and we've collapsed them down into a single equivalence class called $[(1,2)]$. In this manner, every rational number is an equivalence class of these ordered pairs of integers.&lt;/p&gt;
&lt;p&gt;Now that we have our rational numbers, we still need to define their arithmetic. We could technically do this however we wanted, but obviously we would like their arithmetic to coincide with our preconceived ideas of fractional arithmetic.&lt;/p&gt;
&lt;p&gt;For example, we could try to define addition as follows:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Incorrect Definition.&lt;/strong&gt; Given two rational numbers $[(a,b)]$ and $[(c,d)]$, we &lt;em&gt;incorrectly&lt;/em&gt; define their &lt;strong&gt;sum&lt;/strong&gt; to be $$[(a,b)] + [(c,d)] = [(a+c,b+d)].$$&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;There are two reasons why this is a bad definition. First, because in the language of fractions this would translate to $\frac{a}{b}+\frac{c}{d}=\frac{a+b}{c+d}$, which our elementary school teachers drilled into our heads was &lt;em&gt;WRONG&lt;/em&gt;. (Maybe the phrase &amp;quot;common denominator&amp;quot; is echoing around your head right now.) This definition simply does not correspond to our physical intuition of what should happen when we add fractions.&lt;/p&gt;
&lt;p&gt;But there is an even more fundamental reason why this definition cannot be correct. And it's a little bit subtle, so I'll try to break it down the best that I can.&lt;/p&gt;
&lt;p&gt;To see why this &amp;quot;addition&amp;quot; doesn't even work, let's try to add the rational numbers $[(1,2)]$ and $[(1,4)]$. According to the above definition,&lt;/p&gt;
&lt;p&gt;$$[(1,2)] + [(1,3)] = [(1+1, 2+3)] = [(2,5)].$$&lt;/p&gt;
&lt;p&gt;However, we know that $[(1,2)]=[(2,4)]$. But the above definition gives us&lt;/p&gt;
&lt;p&gt;$$[(2,4)] + [(1,3)] = [(2+1, 4+3)] = [(3,7)].$$&lt;/p&gt;
&lt;p&gt;Obviously $[(2,5)] \ne [(3,7)]$ since $(2,5)\not\sim_\mathbb{Q} (3,7)$, and so we have a serious problem here. The issue is that this notion of addition is not &lt;strong&gt;well defined&lt;/strong&gt;. That is, the result of our addition is different depending on which representative ordered pairs we choose for our equivalence classes. This is unacceptable, because it leads to nonsensical results.&lt;/p&gt;
&lt;p&gt;With that in mind, let's work toward the correct definition. In terms of fractions, we would expect $\frac{a}{b}+\frac{c}{d}=\frac{ad+bc}{bd}$. And in fact, this is exactly how we shall proceed.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; Given two rational numbers $[(a,b)]$ and $[(c,d)]$, we define their &lt;strong&gt;sum&lt;/strong&gt; to be $$[(a,b)] + [(c,d)] = [(ad+bc,bd)].$$&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In light of the disaster that was the previous attempt at a definition, we need to verify that this notion of addition is well defined. That is, the result does not depend on our choice of representatives.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Proposition.&lt;/strong&gt; Addition of rational numbers is well defined.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Suppose that $[(a_1,b_1)]=[(a_2,b_2)]$ and $[(c_1,d_1)]=[(c_2,d_2)]$. We need to show that $[(a_1,b_1)]+[(c_1,d_1)]=[(a_2,b_2)]+[(c_2,d_2)]$.&lt;/p&gt;
&lt;p&gt;Since $(a_1,b_1)\sim_\mathbb{Q}(a_2,b_2)$, we have that $a_1b_2=a_2b_1$. Similarly, since $(c_1,d_1)\sim_\mathbb{Q}(c_2,d_2)$, we have that $c_1d_2=c_2d_1$. We note that&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
(a_1d_1+b_1c_1)b_2d_2 &amp;amp;= a_1b_2d_1d_2 + b_1b_2c_1d_2 \\&lt;br&gt;
&amp;amp;= a_2b_1d_1d_2 + b_1b_2c_2d_1 \\&lt;br&gt;
&amp;amp;= b_1d_1(a_2d_2+b_2c_2).&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;But by definition this means that $(a_1d_1+b_1c_2, b_1d_1) \sim_\mathbb{Q} (a_2d_2+b_2c_2, b_2d_2)$. That is, $[(a_1,b_1)]+[(c_1,d_1)]=[(a_2,b_2)]+[(c_2,d_2)]$, as desired.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Thank goodness! This definition of addition is both mathematically legal and matches what we would intuitively expect. So let's move on.&lt;/p&gt;
&lt;p&gt;Logically, the next thing to do is work toward defining multiplication of rational numbers. This is very similar to defining addition. Given what we know about fractions, we expect $\frac{a}{b}\cdot\frac{c}{d}=\frac{ac}{bd}$. By now, hopefully you can guess what the definition will look like.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; Given two rational numbers $[(a,b)]$ and $[(c,d)]$, we define their &lt;strong&gt;product&lt;/strong&gt; to be $$[(a,b)] \cdot [(c,d)] = [(ac,bd)].$$&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Just like we did for addition, we need to show that multiplication is well defined.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Proposition.&lt;/strong&gt; Multiplication of rational numbers is well defined.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Suppose that $[(a_1,b_1)]=[(a_2,b_2)]$ and $[(c_1,d_1)]=[(c_2,d_2)]$. We need to show that $[(a_1,b_1)] \cdot [(c_1,d_1)] = [(a_2,b_2)] \cdot [(c_2,d_2)]$.&lt;/p&gt;
&lt;p&gt;Since $(a_1,b_1)\sim_\mathbb{Q}(a_2,b_2)$, we have that $a_1b_2=a_2b_1$. Similarly, since $(c_1,d_1)\sim_\mathbb{Q}(c_2,d_2)$, we have that $c_1d_2=c_2d_1$. We note that&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
a_1c_1b_2d_2 &amp;amp;= (a_1b_2)(c_1d_2) \\&lt;br&gt;
&amp;amp;= (a_2b_1)(c_2d_1) \\&lt;br&gt;
&amp;amp;= b_1d_1a_2c_2.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;But by definition this means that $(a_1c_1, b_1d_1) \sim_\mathbb{Q} (a_2c_2, b_2d_2)$. That is, $[(a_1,b_1)]\cdot[(c_1,d_1)]=[(a_2,b_2)]\cdot[(c_2,d_2)]$, as desired.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This post is getting long, so I'm going to leave it here for now and continue the construction in a later post, along with the verification of our desired properties of the rational numbers. Until next time! :)&lt;/p&gt;
</content:encoded></item><item><title>Sequences, Hausdorff Spaces and Nets</title><description>I'm now going to talk about sequences and nets, which often provide an alternative way of describing topological phenomena. I'll also talk about Hausdorff spaces, which have all sorts of nice properties.</description><link>http://localhost:2368/sequences-hausdorff-spaces-and-nets/</link><guid isPermaLink="false">5c6c6452a4e2f60287eae222</guid><dc:creator>Eric Shapiro</dc:creator><pubDate>Thu, 20 Apr 2017 21:11:25 GMT</pubDate><content:encoded>&lt;h3 id="contents"&gt;Contents&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#sequences"&gt;Sequences&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#hausdorff-spaces"&gt;Hausdorff Spaces&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#nets"&gt;Nets&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I'm now going to talk about sequences and nets, which often provide an alternative way of describing topological phenomena. I'll also talk about Hausdorff spaces, which have all sorts of nice properties. I was originally planning to include filters in this discussion as well, but I think if I did that this post might become long enough to break the internet.&lt;/p&gt;
&lt;h3 id="sequencesanamesequences"&gt;Sequences&lt;a name="sequences"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;If you've taken a calculus class (or maybe even if you haven't) then you probably already have some notion of what sequences are. They're basically just lists of elements that go on forever. For instance,&lt;/p&gt;
&lt;p&gt;$$\begin{gather}&lt;br&gt;
\begin{aligned}&lt;br&gt;
(0,1,2,3,4,5,6,7,\dotsc)\\&lt;br&gt;
(1,1,2,3,5,8,13,\dotsc)\\&lt;br&gt;
(\text{cat},\text{cat},\text{cat},\text{cat},\dotsc)&lt;br&gt;
\end{aligned}&lt;br&gt;
\end{gather}$$&lt;/p&gt;
&lt;p&gt;are all sequences. The first two have entries in $\mathbb{N}$ and the third takes values in some set of animals.&lt;/p&gt;
&lt;p&gt;Notice that there is always one entry for each natural number. That is, there is a zeroth entry, a first entry, a second entry, and so on. The order in which these entries appear does matter, so put them in parentheses rather than set brackets to distinguish them from sets. Sequences have two main differences from countable infinite sets: they are ordered, and the same point can appear more than once. This important point leads us to the following rigorous definition of a sequence:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; A &lt;strong&gt;sequence&lt;/strong&gt; in a topological space $X$ is a function $x:\mathbb{N}\to X$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It is perhaps a bit confusing to actually think of sequences as functions. The definition above is simply meant to give the &amp;quot;ordered list of points&amp;quot; idea some rigorous footing. We generally write $x_n$, rather than $x(n)$, to denote the $n$th term in a sequence. This means we can write a sequence as $(x_0,x_1,x_2,\dotsc)$. This is sometimes shortened to either $(x_n)_{n=0}^\infty$ or $(x_n)_{n\in\mathbb{N}}$.&lt;/p&gt;
&lt;p&gt;Next, let's talk about convergence. This can be a tricky business, and it is the bane of many Calculus II students' existence. The concept of convergence is not itself terribly complicated — it is the process of figuring out whether a specific sequence converges which can sometimes be unreasonably challenging. To start, let's look at convergence in metric spaces so that we can make use of the familiar notion of distance.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; A sequence $(x_n)_{n\in\mathbb{N}}$ in a metric space $X$ converges to a point $x\in X$ if for every real number $\epsilon&amp;gt;0$ there is some natural number $N$ for which $d(x,x_n)&amp;lt; \epsilon$ whenever $n&amp;gt;N$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; If a sequence $(x_n)_{n\in\mathbb{N}}$ converges to a point $x$, we say that $x$ is the &lt;strong&gt;limit&lt;/strong&gt; of that sequence and we write $\lim\limits_{n\to\infty}x_n=x$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;That's a bit of a mouthful, so let's spend a little bit of time making sure we know what we're getting ourselves into. Essentially what I mean when I say that a sequences converges to a point $x$ is that eventually everything in the sequence becomes as close to $x$ as I want. More precisely, given $\epsilon &amp;gt; 0$, I want everything beyond the $N$th entry in the sequence to be within the open ball $B(x,\epsilon)$, where I get to choose $N$. If I can find such an $N$ for every $\epsilon$, then the sequence converges. Generally, $N$ will need to be very large when $\epsilon$ is very close to zero.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; Consider the sequence $(x_n)_{n=1}^\infty$ in $\mathbb{R}$ where each $x_n=\frac{1}{n}$. We can visualize this sequence in the following manner:&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/1-over-n.svg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Notice that the points in the sequence all lie on the graph of the function $f:\mathbb{R}^+\to\mathbb{R}$ defined by $f(x)=\frac{1}{x}$. This is not surprising, considering we originally defined sequences as functions themselves. That is, this sequence is really the restriction of $f$ to the positive integers, $f\negmedspace\mid_{\mathbb{Z}^+}:\mathbb{Z}^+\to\mathbb{R}$. If you have any experience with this function, you'll believe me when I say that it becomes extremely close to zero and always grows closer to it. It makes sense then that our sequence does the same, so we might guess that it converges to zero. Let's prove this!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; The sequence $(x_n)_{n=1}^\infty$ given by $x_n=\frac{1}{n}$ converges to $0$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Choose $\epsilon&amp;gt;0$ and let $N&amp;gt;\frac{1}{\epsilon}$. If $n&amp;gt;N$, then certainly $n&amp;gt;\frac{1}{\epsilon}$. Thus,&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}&lt;br&gt;
d(x_n, 0) &amp;amp;= \vert x_n - 0\vert \\&lt;br&gt;
&amp;amp;= \tfrac{1}{n} \\&lt;br&gt;
&amp;amp;&amp;lt; \epsilon.&lt;br&gt;
\end{aligned}$$&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;You don't really need to remember the proof of this fact, although it's incredibly easy to reproduce — the candidate for $N$ in this case is more obvious than usual. Just remember that $\lim\limits_{n\to\infty}\frac{1}{n}=0$, which should hopefully make a lot of sense to you anyway. This is an important sequence which we will occasional use in the future.&lt;/p&gt;
&lt;p&gt;Also, notice that the sequence we just looked at doesn't actually &lt;em&gt;quite&lt;/em&gt; fit the definition I gave for sequences. That is, it doesn't have an entry for every natural number (in particular, there is no $x_0$). We could easily remedy that by rewriting each term as $\frac{1}{n+1}$ and shifting each entry's index down by one. I chose to write it the way I did because it looks a bit nicer. It is somewhat common to allow sequences to start at any index we like, as we can always translate it into starting at zero using a similar substitution.&lt;/p&gt;
&lt;p&gt;Now, in a calculus or analysis class you would study lots of properties and characteristics of sequences in $\mathbb{R}$ and learn a bunch of tricks to help you show that certain types of sequences in $\mathbb{R}$ converge. However, all of that stuff bores me and I want to talk generally about convergent sequences in topological spaces, not just about $\mathbb{R}$ with the standard topology. This will require a slight reworking of the definition of convergence to eliminate the concept of distance that we have in metric spaces.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; A sequence $(x_n)_{n\in\mathbb{N}}$ in a topological space $X$ converges to a point $x\in X$ if for every neighborhood $U$ of $x$, there is a natural number $N$ for which $x_n\in U$ whenever $n&amp;gt;N$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This definition basically replaces open balls with neighborhoods, and shouldn't require too much explanation other than that. It should be clear that this definition, when $X$ is a metric space, is equivalent to the old one because open sets are just unions of open balls.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; If a sequence $(x_n)_{n\in\mathbb{N}}$ in a topological space converges to a point $x$, we say that $x$ is a &lt;strong&gt;limit&lt;/strong&gt; of that sequence and we write $\lim\limits_{n\to\infty}x_n=x$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Notice that I've said &amp;quot;a limit,&amp;quot; rather than &amp;quot;the limit&amp;quot; like I did for metric spaces. That's because a convergent sequence in a topological space might actually converge to multiple points. &lt;center&gt;&lt;h1&gt;😱&lt;/h1&gt;&lt;/center&gt; The simplest example of this phenomenon that I can think of is as follows:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; Let $X$ be any nonempty set equipped with the trivial topology.&lt;sup class="footnote-ref"&gt;&lt;a href="#fn1" id="fnref1"&gt;[1]&lt;/a&gt;&lt;/sup&gt; Then for any point $x\in X$, the only neighborhood of $x$ is $X$ itself. Certainly for any sequence $(x_n)_{n\in\mathbb{N}}$ in $X$, all terms of the sequence are in $X$. If follows that every sequence in $X$ converges to every point of $X$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This might strike you as a bit odd, and I'd agree with you. At the very least, this business of every sequence converging to every point is not very desirable behavior for a topological space. After all, we'd like limits of sequences to be unique. Luckily for us, there is a specific type of space for which this behavior is guaranteed!&lt;/p&gt;
&lt;h3 id="hausdorffspacesanamehausdorffspaces"&gt;Hausdorff Spaces&lt;a name="hausdorff-spaces"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; A topological space $X$ is &lt;strong&gt;Hausdorff&lt;/strong&gt;&lt;sup class="footnote-ref"&gt;&lt;a href="#fn2" id="fnref2"&gt;[2]&lt;/a&gt;&lt;/sup&gt; if for every pair of points $x,y\in X$ with $x\ne y$, there exists a neighborhood $U$ of $x$ and a neighborhood $V$ of $y$ such that $U\cap V=\varnothing$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So in a Hausdorff space, distinct points have disjoint neighborhoods. This is clearly not true for spaces with two or more points under the trivial topology, so we're off to a good start. Before I show how this property guarantees uniqueness of limits, I will prove that every metric space is Hausdorff.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; Let $X$ denote a metric space with metric $d:X\times X\to\mathbb{R}$. Then $X$ is Hausdorff when equipped with the topology induced by the metric $d$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Choose $x,y\in X$ with $x\ne y$. By the definition of a metric, $d(x,y)&amp;gt;0$. Let $r=\frac{d(x,y)}{2}$ and define $U=B(x,r)$ and $V=B(y,r)$. It suffices to show that $U$ and $V$ are disjoint, which we will argue by contradiction.&lt;/p&gt;
&lt;p&gt;Suppose $U\cap V\ne\varnothing$. Then there exists some point $p\in U\cap V$, so $d(x,p)&amp;lt; r$ and $d(y,p)&amp;lt; r$ by the definitions of these open balls. Thus,&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}&lt;br&gt;
d(x,p)+d(y,p) &amp;amp;&amp;lt; 2r \\&lt;br&gt;
&amp;amp;= d(x,y),&lt;br&gt;
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;which violates the triangle inequality. We have reached a contradiction, so the proof is complete.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This tells us right away that things like $\mathbb{R}$ in the standard topology are Hausdorff. Now if we can just show that convergent sequences in Hausdorff spaces have unique limits, then I will definitely have been justified earlier in claiming that metric spaces have unique limits. Let's prove this right now.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; Let $X$ be a nonempty Hausdorff space and let $(x_n)_{n\in\mathbb{N}}$ be a convergent sequences in $X$. Then $(x_n)_{n\in\mathbb{N}}$ has exactly one limit.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Since $(x_n)_{n\in\mathbb{N}}$ is convergent, we know that it has at least one limit. Thus, it suffices to show that it also has at most one limit. We proceed by contradiction.&lt;/p&gt;
&lt;p&gt;Suppose $(x_n)_{n\in\mathbb{N}}$ converges to both $p_1$ and $p_2$, where $p_1\ne p_2$. Since $X$ is Hausdorff, there exist disjoint neighborhoods $U_1$ of $p_1$ and $U_2$ of $p_2$. From the definition of convergence, we have that $x_n\in U_1$ whenever $n&amp;gt;N_1$ and $x_n\in U_2$ whenever $n&amp;gt;N_2$ for some natural numbers $N_1$ and $N_2$ Let $N=\max\{N_1,N_2\}$. Then clearly $x_n\in U_1\cap U_2$ whenever $n&amp;gt;N$. This is a contradiction, since $U_1$ and $U_2$ are disjoint.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So Hausdorff spaces are desirable in that if a sequence converges, it does so as we'd generally expect it to. I won't go into this in too much detail right now, but all of the thinks we actually think of as &amp;quot;space&amp;quot; are Hausdorff. In fact, the definition of a manifold explicitly requires this property, which we shall see if I ever manage to get that far.&lt;/p&gt;
&lt;p&gt;There are a few more properties of Hausdorff spaces which I'd like to prove before moving on, just because they're interesting. The first is the fact that singleton sets in Hausdorff spaces are closed. Its proof is quite straightforward.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; Let $X$ be a nonempty Hausdorff space. Then for every point $x\in X$, the set $\{x\}$ is closed.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Since $X$ is Hausdorff, for every $y\in X$ with $y\ne x$ there exist disjoint neighborhoods $U_y$ of $x$ and $V_y$ of $y$. It follows from the union lemma that&lt;/p&gt;
&lt;p&gt;$$\bigcup\limits_{y\ne x}V_y = X-\{x\},$$&lt;/p&gt;
&lt;p&gt;and this set is open because it is the union of open sets. Thus, $\{x\}$ is closed because its complement is open.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The next property is a little bit more interesting&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; Let $X$ and $Y$ denote topological spaces and suppose $Y$ is Hausdorff. Then the graph of any continuous function $f:X\to Y$, given by&lt;/p&gt;
&lt;p&gt;$$G=\left\{\big(x,f(x)\big)\mid x\in X\right\}$$&lt;/p&gt;
&lt;p&gt;is closed in the product space $X\times Y$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; It suffices to show that $(X\times Y)-G$ is open in $X\times Y$. Choose $(x,y)\in (X\times Y)-G$. Clearly $y\ne f(x)$, so because $Y$ is Hausdorff there exist disjoint neighborhoods $U$ of $y$ and $V$ of $f(x)$. Furthermore, because $f$ is continuous we have that $f^{-1}[V]$ is open in $X$. Notice that $x\in f^{-1}[V]$ by definition.&lt;/p&gt;
&lt;p&gt;Next, choose any point $\big(g,f(g)\big)\in G$, and let us consider separately the cases where $g\in f^{-1}[V]$ and $g\notin f^{-1}[V]$. If $g\in f^{-1}[V]$ then by definition $f(g)\in V$. Thus, $f(g)\notin U$ because $U$ and $V$ are disjoint. It follows that $\big(g,f(g)\big)\notin f^{-1}[V]\times U$. If, on the other hand, $g\notin f^{-1}[V]$ then it follows immediately that $\big(g,f(g)\big)\notin f^{-1}[V]\times U$ from the definition of the Cartesian product.&lt;/p&gt;
&lt;p&gt;Either way, $\big(g,f(g)\big)\notin f^{-1}[V]\times U$ and so we have that $(f^{-1}[V]\times U)\cap G=\varnothing$. Clearly $f^{-1}\times U$ is open as it is the product of open sets. Thus every point $(x,y)\in (X\times Y)-G$ is contained in the open set $f^{-1}[V]\times U$, which is itself contained in $(X\times Y)-G$. It follows that $(X\times Y)-G$ is open in $X\times Y$, so $G$ is closed.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is a pretty nice result, although it isn't too useful to us right now. At the very least, it tells us that continuous real-valued functions have closed graphs because $\mathbb{R}$ is Hausdorff. The next two theorems should immediately seem useful to you.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; Any subspace of a Hausdorff space is Hausdorff.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Let $A$ be a subspace of a Hausdorff space $X$ and choose points $x,y\in A$. Then there exist disjoint neighborhoods in $X$, $U$ of $x$ and $V$ of $y$. It follows that $A\cap U$ is a neighborhood of $x$ in $A$ and $A\cap V$ is a neighborhood of $y$ in $A$. Furthermore,&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}&lt;br&gt;
(A\cap U)\cap (A\cap V) &amp;amp;= A\cap (U\cap V) \\&lt;br&gt;
&amp;amp;= A\cap\varnothing \\&lt;br&gt;
&amp;amp;= \varnothing,&lt;br&gt;
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;so $A$ is Hausdorff.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; The product of two Hausdorff spaces is Hausdorff.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Let $X$ and $Y$ denote Hausdorff spaces and choose distinct points $(x_1,y_1)$ and $(x_2,y_2)$ in $X\times Y$. Without loss of generality (the other case is so similar) suppose $x_1\ne x_2$. Then because $X$ is Hausdorff, there exist disjoint neighborhoods $U_1$ of $x_1$ and $U_2$ of $x_2$ in $X$. Note that $U_1\times Y$ and $U_2\times Y$ are both open in $X\times Y$, and that $(x_1,y_1)\in U_1\times Y$ while $(x_2,y_2)\in U_2\times Y$. Furthermore,&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}&lt;br&gt;
(U_1\times Y)\cap (U_2\times Y) &amp;amp;= (U_1\cap U_2)\times Y \\&lt;br&gt;
&amp;amp;= \varnothing\times Y \\&lt;br&gt;
&amp;amp;= \varnothing,&lt;br&gt;
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;so $X\times Y$ is Hausdorff.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It can be shown by induction that the product of any finite number of Hausdorff spaces is Hausdorff. It is also possible to show, in fact, that the product of &lt;em&gt;any&lt;/em&gt; collection of Hausdorff spaces is Hausdorff, but I try to avoid talking about infinite Cartesian products unless I have no other choice.&lt;/p&gt;
&lt;p&gt;Given that products and subspaces of Hausdorff spaces inherit Hausdorffness from their parents, you might be tempted to guess that quotients of Hausdorff spaces are Hausdorff. This is wrong in general, although I won't provide a counterexample because this post is already very long and I haven't even started discussing nets yet.&lt;/p&gt;
&lt;p&gt;Unfortunately, before I get to nets I have a few more things about sequences that I would like to talk about. In particular, it would be a shame for me not to prove the following beautiful theorem for you.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; Let $X$ and $Y$ denote topological spaces and let $(x_n)_{n\in\mathbb{N}}$ be a sequence which converges to the point $x\in X$. Then for any continuous function $f:X\to Y$, the sequence $\big(f(x_n)\big)_{n\in\mathbb{N}}$ converges to the point $f(x)\in Y$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Choose any neighborhood $U\subseteq Y$ of $f(x)$. Since $f$ is continuous, $f^{-1}[U]\subseteq X$ is open and clearly $x\in f^{-1}[U]$, so $f^{-1}[U]$ is a neighborhood of $x$. Since $(x_n)_{n\in\mathbb{N}}$ converges to $x$, there exists $N\in\mathbb{N}$ for which $x_n\in f^{-1}[U]$ whenever $n&amp;gt;N$. It follows that $f(x_n)\in U$ whenever $n&amp;gt;N$. Thus, $\big(f(x_n)\big)_{n\in\mathbb{N}}$ converges to $f(x)$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This theorem is great because it tells us that continuous functions preserve convergent sequences! It would be even better if the converse was true, because that would give us yet another alternative characterization of continuous functions. Unfortunately, this is not the case without additionally assuming that both spaces are first-countable (a property that I haven't mentioned yet, but that every metric space has). For general spaces, it is also possible for function which aren't continuous to preserve convergent sequences.&lt;/p&gt;
&lt;p&gt;This hints that sequences might not be exactly the right tool to study continuity. The problem is that they are too specific a concept. Let's next look at a generalization of sequences that will solve all of our problems.&lt;/p&gt;
&lt;h3 id="netsanamenets"&gt;Nets&lt;a name="nets"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Before I start trying to explain nets to you, let me state the main theorem we eventually want to prove about them.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; Let $X$ and $Y$ denote topological spaces. A function $f:X\to Y$ is continuous if and only if for every net $(x_a)_{a\in A}$ that converges to $x$, the net $\big(f(x_a)\big)_{a\in A}$ converges to $f(x)$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In stating this theorem of things to come, I've already given away a fair amount of information about the nature of nets. Namely, the fact that nets look almost exactly like sequences, except perhaps that their entries are indexed over sets other than $\mathbb{N}$. However, nets aren't indexed over just any kind of set — after all, we would still like the entries of a net to progress in some order. Thus, we will define them over sets with a specific type of relation:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; A &lt;strong&gt;preorder&lt;/strong&gt; on a set $X$ is a reflexive and transitive relation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;That is, a preorder on $X$ is a relation $\le$ such that $x\le x$ for every $x\in X$, and $x\le z$ whenever $x\le y$ and $y\le z$.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; A &lt;strong&gt;directed set&lt;/strong&gt; is a nonempty set $X$ together with a preorder $\le$ which satisfies the additional property that for any $x,y\in X$, there exists $z\in X$ such that $x\le z$ and $y\le z$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A shorter way of describing this final property of directed sets might be to say that every pair of elements has an upper bound. This ensures that, although some pairs of elements may not be related to each other, they are at least related to some third element. In turn, this guarantees that strange behavior, as in the following example, does not occur.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; Just to make sure there's no confusion, this will be an example of a set with a preorder that is &lt;em&gt;not&lt;/em&gt; a directed set, because pairs of elements will not necessarily have upper bounds.&lt;/p&gt;
&lt;p&gt;We will define preorders $\le_1$ on the set $\mathbb{N}\times\{1\}$ and $\le_2$ on the set $\mathbb{N}\times\{2\}$ that act similarly to the standard &amp;quot;less than or equal to&amp;quot; relation on $\mathbb{N}$. Recall that we previously defined $\le$ on $\mathbb{N}$ so that $n\le m$ if and only if $m=n+k$ for some $k\in\mathbb{N}$.&lt;/p&gt;
&lt;p&gt;Notice that every element of $\mathbb{N}\times\{1\}$ is of the form $(n,1)$ for some $n\in\mathbb{N}$. Thus it makes sense to define $\le_1$ using the rule that $(n,1)\le_1 (m,1)$ if and only if $n\le m$. Similarly, we define $\le_2$ using the rule that $(n,2)\le_2 (m,2)$ if and only if $n\le m$.&lt;/p&gt;
&lt;p&gt;It is obvious that both $\le_1$ and $\le_2$ are preorders on their respective sets because they both inherit their reflexivity and transitivity from $\le$.&lt;/p&gt;
&lt;p&gt;Let's use these to define a preorder on $(\mathbb{N}\times\{1\})\cup(\mathbb{N}\times\{2\})$. We can define $\le_3$ on this union using the rule that $n\le_3 m$ if and only if either $n\le_1 m$ or $n\le_2 m$. Using the rigorous set-theoretic definition of relations, we could alternatively define this by $\le_3=\le_1\cup\le_2$. Again, it's easy to see that $\le_3$ is a preorder because it inherits its reflexivity and transitivity from $\le_1$ and $\le_2$.&lt;/p&gt;
&lt;p&gt;Basically what we have is two disjoint copies of things that act identically to $\mathbb{N}$, which have been glued together, but are related to each other in absolutely no way. In particular, if we choose $n_1\in\mathbb{N}\times\{1\}$ and $n_2\in\mathbb{N}\times\{2\}$, there is certainly no element of $(\mathbb{N}\times\{1\})\cup (\mathbb{N}\times\{2\})$ which serves as an upper bound for both $n_1$ and $n_2$. Thus, this example does not constitute a directed set.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; On the other hand, the set $\mathbb{N}$ of natural numbers equipped with $\le$, the standard &amp;quot;less than or equal to&amp;quot; relation, is a directed set. I proved in my post on quotient sets that this relation is reflexive and transitive, so it is certainly a preorder. The fact that all pairs of natural numbers have an upper bound is easy to show. For any $x,y\in\mathbb{N}$, choose $x=\max\{x,y\}$. Then clearly $x\le z$ and $y\le z$. This is a particularly easy example because every natural number is either less than or greater than every other natural number.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; Another interesting directed set can be formed as follows. Let $X$ denote any nonempty topological space and pick a point $x\in X$. The set $N_x$ of all neighborhoods of $x$ forms a directed set when equipped with the preorder $\le$ defined by $U\le V$ is and only if $V\subseteq U$.&lt;/p&gt;
&lt;p&gt;This relation is reflexive because for any neighborhood $U$ of $x$, it is clear that $U\subseteq U$ and so $U\le U$.&lt;/p&gt;
&lt;p&gt;It is only a tad more difficult to see that $\le$ is transitive. Suppose we have neighborhoods $U, V$ and $W$ of $x$ for which $U\le V$ and $V\le W$. Then $W\subseteq V\subseteq U$, so certainly $W\subseteq U$. Thus, $U\le Q$.&lt;/p&gt;
&lt;p&gt;Lastly, we need to show that any pair of neighborhoods of $x$ has an upper bound, which in this case simply means they both contain a common neighborhood of $x$. Again, this is easy to show. Choose any two neighborhoods $U$ and $V$ of $x$. Clearly $x\in U\cap V$, and by the definition of a topology $U\cap V$ is open. Thus it is a neighborhood of $x$. It is obvious that $U\cap V\subseteq U$ and $U\cap V\subseteq V$, so $U\le U\cap V$ and $V\le U\cap V$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now that we have some examples of directed sets in our arsenal, it's finally time to define nets. You've likely already guessed how we'll proceed.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; A &lt;strong&gt;net&lt;/strong&gt; in a topological space $X$ is a function $x:A\to X$, where $A$ is any directed set.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Again, we generally write $x_a$ rather than $x(a)$, and we denote a net itself by $(x_a)_{x\in A}$. Since we've already established that $\mathbb{N}$ is a directed set, it should be clear that sequences are a special type of net.&lt;/p&gt;
&lt;p&gt;Convergence of nets is extremely similar to convergence of sequences.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; A net $(x_a)_{x\in A}$ in a topological space $X$ &lt;strong&gt;converges&lt;/strong&gt; to a point $x\in X$ if for every neighborhood $U$ of $x$, there exists $b\in A$ for which $x_a\in U$ whenever $a\ge b$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; If a net $(x_a)_{x\in A}$ in a topological space converges to a point $x$, we say that $x$ is a &lt;strong&gt;limit&lt;/strong&gt; of that net and we write $\lim x_a=x$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It's fairly easy to come up with a convergent net that is not a sequence, using an example I've already given.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; Given a topological space $X$ and a point $x\in X$, let $N_x$ denote the directed set of neighborhoods of $x$ as detailed above. We can construct a net $(x_U)_{U\in N_x}$ by choosing a point $x_U\in U$ for each neighborhood $U$ of $x$. (Notice that this action requires the Axiom of Choice). Intuition tells us that this net should converge to $x$ because the neighborhoods of $x$ get &amp;quot;smaller&amp;quot; the further out we go in our directed set $N_x$. This claim is super easy to verify, so let's just do it.&lt;/p&gt;
&lt;p&gt;Choose any neighborhood $U$ of $x$. From our construction of the net $(x_U)_{U\in N_x}$, it is clear that $x_U\in U$. Furthermore, for any neighborhood $V$ of $x$ with $V\ge U$, we have that $V\subseteq U$ and thus $x_V\in X\subseteq U$. It follows that $(x_U)_{U\in N_x}$ converges to $x$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This post is already so ridiculously long that I'm just going to prove the theorem that I promised you and then be done. Unfortunately, the proof is a little bit on the longer side.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; Let $X$ and $Y$ denote topological spaces. Then a function $f:X\to Y$ is continuous if and only if for every net $(x_a)_{a\in A}$ that converges to $x$, the net $\big(f(x_a)\big)_{a\in A}$ converges to $f(x)$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; The forward direction is practically identical for the analogous result for series. Suppose $f$ is continuous and that the net $(x_a)_{a\in A}$ converges to the point $x\in X$. Choose any neighborhood $U$ of $f(x)$. Since $f$ is continuous, $f^{-1}[U]\subseteq X$ is open and clearly $x\in f^{-1}[U]$, so $f^{-1}[U]$ is a neighborhood of $x$. Thus, there exists $b\in A$ for which $x_a\in f^{-1}[U]$ whenever $a\ge b$. It follows that $f(x_a)\in U$ whenever $a\ge b$, so the net $\big(f(x_a)\big)_{a\in A}$ converges to $f(x)$.&lt;/p&gt;
&lt;p&gt;I will prove the reverse direction by contradiction. Suppose that for every net $(p_a)_{a\in A}$ that converges to $p$, the net $\big(f(p_a)\big)_{a\in A}$ converges to $f(p)$, but that $f$ is not continuous. Then there exists a point $x\in X$ and a neighborhood $V$ of $f(x)$ for which $f^{-1}[V]$ is not a neighborhood of $x$. Thus, we can construct a net $(x_U)_{U\in N_x}$ for which each $x_U\notin f^{-1}[V]$. Clearly each $f(x_U)\notin V$. Choose any neighborhood $W$ of $x$. Then for any neighborhood $T\ge W$, i.e., $T\subseteq W$, and so $x_T\in W$. It follows that $(x_U)_{U\in N_x}$ converges to $x$, and thus $\big(f(x_U)\big)_{U\in N_x}$ converges to $f(x)$. However, the interior of $V$ is a neighborhood of $f(x)$ and thus $f(x_U)$ is eventually in this interior and therefore also in $V$, but this is a contradiction.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So continuity is equivalent to the preservation of convergent nets, which is pretty cool. It's also true that being Hausdorff is equivalent to the existence of unique limits for nets, but I'm going to end this post here because it's really just getting ridiculous at this point.&lt;/p&gt;
&lt;hr class="footnotes-sep"&gt;
&lt;section class="footnotes"&gt;
&lt;ol class="footnotes-list"&gt;
&lt;li id="fn1" class="footnote-item"&gt;&lt;p&gt;Recall that in the trivial topology the only open sets are $\varnothing$ and $X$. &lt;a href="#fnref1" class="footnote-backref"&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn2" class="footnote-item"&gt;&lt;p&gt;Or &lt;strong&gt;separated&lt;/strong&gt;, or $\mathbf{T}_2$. &lt;a href="#fnref2" class="footnote-backref"&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</content:encoded></item><item><title>Quotient Spaces</title><description>The notion of a quotient space will effectively allow us to glue pieces of topological spaces together. This corresponds to the collapsing of equivalent subsets to points which occurs in quotient sets, as I mentioned in my last post.</description><link>http://localhost:2368/quotient-spaces/</link><guid isPermaLink="false">5c6c6452a4e2f60287eae221</guid><dc:creator>Eric Shapiro</dc:creator><pubDate>Sun, 09 Apr 2017 14:16:40 GMT</pubDate><content:encoded>&lt;p&gt;Now that we've defined quotient sets, let's talk about quotient sets of topological spaces. The notion of a quotient space will effectively allow us to glue pieces of topological spaces together. This corresponds to the collapsing of equivalent subsets to points which occurs in quotient sets, as I mentioned in my last post. These are useful tools, so I'm going to jump right into it. It may be a bit difficult to see where I'm going with this at first, but bear with me and hopefully it'll become clear.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; Let $X$ denote a topological space, let $A$ be a set and let $f:X\to A$ be a surjective function. The &lt;strong&gt;quotient topology&lt;/strong&gt; induced by $f$ has as its open sets all sets $U$ such that $f^{-1}[U]$ is open in $X$. We call $f$ a &lt;strong&gt;quotient map&lt;/strong&gt; and $A$ a &lt;strong&gt;quotient space&lt;/strong&gt; when equipped with this topology.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Supposing the quotient topology is truly a topology, we get for free that quotient maps are always continuous, simple from the way they're defined.  However, we still need to verify that quotient topologies satisfy the requirements of a topology. We need to show that $\varnothing$ and $A$ are open, and that unions and finite intersections of open sets are open.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; Let $X$ denote a topological space, let $A$ be a set and let $f:X\to A$ be a surjective function. Then the quotient topology defined above is a topology on $A$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; It is clear that $f^{-1}[\varnothing]=\varnothing$ and so the empty set is open in $A$. Furthermore, since $f$ is surjective, we know that $f^{-1}[A]=X$ is open in $X$ and so $A$ is also open in $A$.&lt;/p&gt;
&lt;p&gt;Next, suppose that $I$ is an indexing set and $U_i\subseteq A$ are such that $f^{-1}[U_i]$ is open in $X$ for each $i\in I$. Then certainly&lt;/p&gt;
&lt;p&gt;$$f^{-1}\left[\bigcup\limits_{i\in I}U_i\right]=\bigcup\limits_{i\in I}f^{-1}[U_i]$$&lt;/p&gt;
&lt;p&gt;is open in $X$ since it is the union of open sets. Thus, $\bigcup\limits_{i\in I}U_i$ is open in A.&lt;/p&gt;
&lt;p&gt;Finally, suppose that $n\in\mathbb{Z}^+$ and that $U_i\subseteq A$ are such that $f^{-1}[U_i]$ is open in $X$ for each $1\le i\le n$. Then&lt;/p&gt;
&lt;p&gt;$$f^{-1}\left[\bigcap\limits_{i=1}^n U_i\right]=\bigcap\limits_{i=1}^n f^{-1}[U_i]$$&lt;/p&gt;
&lt;p&gt;is open in $X$ since it is the intersection of a finite number of open sets. Thus, $\bigcap\limits_{i=1}^n U_i$ is open in $A$, completing the proof.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;There is also an equivalent, more intuitive way to define quotient spaces which will probably look more familiar to you after our discussion on quotient sets last post.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; Let $X$ denote a topological space and let $\sim$ be an equivalence relation on $X$. The &lt;strong&gt;quotient space&lt;/strong&gt; $X/\negthickspace\sim$ is this quotient set where the open sets are sets of equivalence classes whose unions are open in $X$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;We've established that quotient maps induce a topology in this way, so let's take a look at what they can do for us.&lt;/p&gt;
&lt;p&gt;While it's true that any set $A$ can be turned into a quotient space by defining a suitable surjection as our quotient map, we generally restrict our interest to partitions of $A$. Let's first visualize the construction of a simple quotient space, which you may have seen before. We will then figure out how to formally document this process.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; Consider the square $[0,1]^2$ in the standard topology. We can first create a cylinder from the square by gluing two opposite edges together.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/square_to_cylinder.svg" alt="square to cylinder"&gt;&lt;/p&gt;
&lt;p&gt;Next, we can glue the two open circular ends of the cylinder together to form a torus.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/cylinder_to_torus.svg" alt="cylinder to torus"&gt;&lt;/p&gt;
&lt;p&gt;What we've really done here is glue the opposite edges of the square together, one pair at a time. A much more concise diagram representing this act simply identifies opposite edges of the square with each other, and the gluing is implied.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/square_to_torus.svg" alt="square to torus"&gt;&lt;/p&gt;
&lt;p&gt;In such diagrams, it is understood that the two edges with one arrow get glued to each other and the two edges with two arrows get glued to each other. In this case everything is symmetrical so it doesn't matter which pair gets glued first, but there are probably cases in which it does matter. It is conventional to first glue together sides with one arrow, then two arrows and so on.&lt;/p&gt;
&lt;p&gt;It is this last diagram which provides us with something we can really use. This &lt;em&gt;identification&lt;/em&gt; of sides is crucial to defining the torus as a quotient space of the square. What we are really doing here is partitioning the square in such a way that certain pairs of points on the boundary get grouped into the same equivalence class. More precisely, we partition the square into many sets, namely every point in the interior of the square and each pair of opposite points on the square's boundary:&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
B_{x,y} &amp;amp;= \{(x,y)\}\text{ for } (x,y)\in (0,1)^2, \\&lt;br&gt;
C_x     &amp;amp;= \{(x,0),(x,1)\}\text{ for } x\in (0,1), \\&lt;br&gt;
D_y     &amp;amp;= \{(0,y),(1,y)\}\text{ for } y\in (0,1), \\&lt;br&gt;
E        &amp;amp;= \{(0,0),(0,1),(1,0),(1,1)\}.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;Allow me to explain these choices a little bit. We have defined one set $B_{x,y}$ in the partition for every point $(x,y)$ in the interior of the square. This is because in our quotient space, we do not want the interior of the square to collapse at all, and so every point should be in its own equivalence class. There is one set $C_x$ for every pair of points along the bottom and top of the square, and one set $C_y$ for every pair along the left and right edges. Putting these pairs into the same equivalence classes ensures that they will become one thing, i.e. 'glued together,' in the quotient space. Lastly, $E$ includes the corners of the square separately to avoid double-counting them.&lt;sup class="footnote-ref"&gt;&lt;a href="#fn1" id="fnref1"&gt;[1]&lt;/a&gt;&lt;/sup&gt; This also ensures explicitly that the four corners of the square will all end up being glued together.&lt;/p&gt;
&lt;p&gt;Going back to our original definitions for quotient maps and spaces, we define the set $A$ as the collection of all sets in this partition and the quotient map $f$ as the surjective function mapping each point in the square to the set in $A$ which contains it. Then it is easy to show that the resulting quotient space is (homeomorphic to) the torus $S^1\times S^1$, so we have accomplished what we set out to.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Many, many more examples of quotient spaces can be generated easily in much the same manner. We can define the sphere as a quotient space of pretty much any polygon, for instance. However, it is tedious and difficult to draw diagrams and they can be found all over the internet anyway. This post is also nice and short for a change, so I'm going to stop here. The good news is that I've now introduced most of the common methods for constructing new topological spaces!&lt;/p&gt;
&lt;hr class="footnotes-sep"&gt;
&lt;section class="footnotes"&gt;
&lt;ol class="footnotes-list"&gt;
&lt;li id="fn1" class="footnote-item"&gt;&lt;p&gt;Remember that the sets in a partition must be pairwise disjoint. &lt;a href="#fnref1" class="footnote-backref"&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</content:encoded></item><item><title>Equivalence Relations and Quotient Sets</title><description>Quotient sets of $A$ are comprised not of elements of $A$, but of the equivalence classes they fall into. This gives us a powerful method to collapse a set into a smaller set that is in some way still representative of the original set.</description><link>http://localhost:2368/equivalence-relations-and-quotient-sets/</link><guid isPermaLink="false">5c6c6452a4e2f60287eae220</guid><dc:creator>Eric Shapiro</dc:creator><pubDate>Sun, 09 Apr 2017 00:41:51 GMT</pubDate><content:encoded>&lt;p&gt;The next topological construction I'm going to talk about is the quotient space, for which we will certainly need the notion of quotient sets. However, equivalence relations and quotient sets show up all over the place in mathematics and are worth studying on their own because of their tremendous importance and ubiquitousness.&lt;/p&gt;
&lt;p&gt;The first concept I should introduce is that of a relation. A special type of relation, called an equivalence relation, will be vital to all of the content in this post.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; A &lt;strong&gt;relation&lt;/strong&gt; on a set $A$ is a subset of the Cartesian product $A\times A$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So technically any subset of $A\times A$ is a relation on $A$, but most of them are usually boring and have little meaning. Relations are generally used to compare two elements in some way. That is, we use them to determine whether two elements are 'related' in the manner specified. We should take a look at some characteristics that relations may possess which make them more interesting, but first I'd like to give some examples of familiar relations.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; Take $A=\mathbb{N}$, the set of natural numbers. The &amp;quot;less than or equal to&amp;quot; relation on $\mathbb{N}$, usually written $\le$, is defined so that $(a,b)\in\le$ if and only if $b=a+x$ for some $x\in\mathbb{N}$. Clearly&lt;/p&gt;
&lt;p&gt;$$\le \; := \{(a,b)\in\mathbb{N}^2\mid b=a+x\text{ for some }x\in\mathbb{N}\}$$&lt;/p&gt;
&lt;p&gt;fits our definition of a relation because it is a subset of $\mathbb{N}\times\mathbb{N}$. However, no one ever writes things this way. Normal people use infix notation. That is, they write $a\le b$ rather than $(a,b)\in\le$. I will pretty much use infix notation for the rest of time since it tends to simplify things a great deal, and it is probably what you're used to seeing.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; Take $A=\mathbb{Z}$, the set of integers, and choose some $n\in\mathbb{Z}$. We can define a relation $=_n$ on $\mathbb{Z}$ so that for any $a,b\in\mathbb{Z}$, we have that $a=_n b$ if and only if $b-a=kn$ for some $k\in\mathbb{Z}$. We can write this more formally as&lt;/p&gt;
&lt;p&gt;$$=_n \; := \{(a,b)\in\mathbb{Z}^2\mid b-a=kn\text{ for some }k\in\mathbb{Z}\}$$&lt;/p&gt;
&lt;p&gt;but there isn't usually any benefit in doing things that way, and I think it's even a little bit confusing to look at. By the way, this relation is called &lt;strong&gt;congruence modulo $n$&lt;/strong&gt; and it is of tremendous importance to many fields of mathematics. You can bet we'll be seeing this again at some point soon.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; For any set $A$, both $\varnothing$ and $A\times A$ are relations on $A$. The $\varnothing$ relation doesn't relate elements of $A$ to anything, not even themselves. On the other hand, the relation $A\times A$ relates every element to every element of $A$. These are two extreme sorts of relations, but neither is particularly interesting or important.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now that I've given you a few examples, hopefully the definition of a relation has had time to sink in and begun to make a bit of sense. As promised I'll now discuss some important qualities that a relation may or may not have.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; A relation $\sim$ on a set $A$ is &lt;strong&gt;reflexive&lt;/strong&gt; if $a\sim a$ for every $a\in A$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; The relation $\le$ on $\mathbb{N}$ is reflexive because every natural number is less than or equal to itself, i.e. $n\le n$ for every $n\in\mathbb{N}$&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; Another example of a reflexive relation is that of congruence modulo $n$. This is because $a-a=0n$ for every $a\in\mathbb{Z}$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The reflexive property holds for many important relations, and is in general quite easy to verify. This is because in most relations of interest to mathematicians, elements tend to be related to themselves. In fact, the only relation we discussed above that is not reflexive is the empty relation.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; A relation $\sim$ on a set $A$ is &lt;strong&gt;symmetric&lt;/strong&gt; if $b\sim a$ whenever $a\sim b$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; The relation $=_n$ on $\mathbb{Z}$ of congruence modulo some $n\in\mathbb{Z}$ is symmetric. To see this, suppose $a=_n b$ for some $a,b\in\mathbb{Z}$. Then by definition, $b-a=kn$ for some integer $k$. Negating each side, we see that $a-b=-kn$ and since $-k$ is also an integer it follows that $b=_n a$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; The relation $\le$ on $\mathbb{N}$, on the other hand, is not symmetric. We can see this by examining a single counterexample. Clearly $3\le 5$ but it is not true that $5\le 3$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The final property I'm going to talk about is generally the most difficult to demonstrate holds for a particular relation. It sort of resembles the triangle inequality.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; A relation $\sim$ on a set $A$ is &lt;strong&gt;transitive&lt;/strong&gt; if $a\sim c$ whenever both $a\sim b$ and $b\sim c$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; It's not too hard to show that the relation $\le$ on $\mathbb{N}$ is transitive. Consider $a,b,c\in\mathbb{N}$ such that $a\le b$ and $b\le c$. Then by definition, $b=a+x$ and $c=b+y$ for some $x,y\in\mathbb{N}$. Substituting the first equation into the second, we see that $c=a+x+y$. And since $x+y\in\mathbb{N}$, it follows that $a\le c$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; Next, consider again the relation $=_n$ on $\mathbb{Z}$ of congruence modulo some integer $n$. Suppose $a=_n b$ and $b=_n c$. Then $b-a=k_1 n$ and $c-b=k_2 n$ for some integers $k_1$ and $k_2$. Thus,&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
c-a &amp;amp;= (c-b) + (b-a) \\&lt;br&gt;
&amp;amp;= k_2 n - k_1 n \\&lt;br&gt;
&amp;amp;= (k_2-k_1)n.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;Since $k_2-k_1\in\mathbb{Z}$, it follows that $a=_n c$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now that we have established these three types of relation, it is a piece of cake to define an equivalence relation:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; An &lt;strong&gt;equivalence relation&lt;/strong&gt; is a relation which is reflexive, symmetric and transitive.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; We've established above that congruence modulo $n$ satisfies each of these properties, which automatically makes it an equivalence relation on the integers.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; The relation &amp;quot;is the same age as&amp;quot; on the set of all people is an equivalence relation. Every person is the same age as him/herself. If person $A$ is the same age as person $B$, then certainly person $B$ is the same age as person $A$. And transitivity also holds, but I'm too lazy to type that one out right now.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; The relation &amp;quot;has shaken hands with&amp;quot; on the set of all people is &lt;em&gt;not&lt;/em&gt; an equivalence relation because it is not transitive. For instance, it is entirely possible that Bob has shaken Fred's hand and Fred has shaken hands with the president, yet this does not necessarily mean that Bob has shaken the president's hand.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;As you will learn, equivalence relations pop up constantly in every area of mathematics. This is because they give sets a very nice kind of structure. To explain this further, we first need the following concepts:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; Given an equivalence relation $\sim$ on a set $A$ and an element $a\in A$, the &lt;strong&gt;equivalence class&lt;/strong&gt; of $A$ is the set $[a]=\{x\in A\mid a\sim x\}$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; Given an equivalence relation $\sim$ on a set $A$, the set of equivalence classes corresponding to $\sim$ is called a &lt;strong&gt;quotient set&lt;/strong&gt;&lt;sup class="footnote-ref"&gt;&lt;a href="#fn1" id="fnref1"&gt;[1]&lt;/a&gt;&lt;/sup&gt; and is written $A/\negthickspace\sim$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So quotient sets of $A$ are comprised not of elements of $A$, but of the equivalence classes they fall into. This gives us a powerful method to collapse a set into a smaller set that is in some way still representative of the original set. Hopefully the following example will help make some sense of this.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; Let's take another look at the set $\mathbb{Z}$ and the relation $=_3$ of congruence modulo $3$.&lt;sup class="footnote-ref"&gt;&lt;a href="#fn2" id="fnref2"&gt;[2]&lt;/a&gt;&lt;/sup&gt; Under this relation, two integers $a$ and $b$ are related if $b-a=3k$ for some integer $k$. Put more plainly, two integers are congruent if their difference is a multiple of $3$.&lt;/p&gt;
&lt;p&gt;How many equivalence classes does this relation create? It isn't too tough to see that there are three: $[0], [1]$ and $[2]$. This is because all multiples of three, i.e. elements of the form $3k$ for some integer $k$, are congruent. Similarly, all elements of the form $3k+1$ are congruent and all elements of the form $3k+2$ are congruent. And these are all the possible options, really. I have chosen $0, 1$ and $2$ as the &lt;strong&gt;representatives&lt;/strong&gt; of these equivalence classes, but this choice was arbitrary (albeit standard). I could just as easily have named them $[3000], [16]$ and $[-1]$.&lt;/p&gt;
&lt;p&gt;Lastly, we see that the quotient set $\mathbb{Z}/\negthickspace=_3$ is just the set $\big\{[0],[1],[2]\big\}$. That is, all congruent elements are essentially collapsed to a single point in the quotient set.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;There is one final topic I need to talk about here, which is the fact that equivalence classes form partitions of sets. This is called the Fundamental Theorem of Equivalence Relations, but I'm getting ahead of myself. Before I prove it, I need to tell you what a partition is.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; A &lt;strong&gt;partition&lt;/strong&gt; $\cal P$ of a set $A$ is a collection of subsets of $A$ which satisfies the following properties:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The empty set is not in $\cal P$.&lt;/li&gt;
&lt;li&gt;For any two sets $X,Y$ in $\cal P$, either $X$ and $Y$ are disjoint or $X=Y$.&lt;/li&gt;
&lt;li&gt;The union $\bigcup\limits_{X\in\cal P}X$ of all subsets in the partition is equal to $A$ itself.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is all basically a fancy way of saying that a partition is a method of breaking a set into non-overlapping subsets. Now it's time to prove that Fundamental Theorem thingy I mentioned a moment ago.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Fundamental Theorem of Equivalence Relations.&lt;/strong&gt; Let $\sim$ be an equivalence relation on a set $A$. Then the quotient set $A/\negthickspace\sim$ is a partition of $A$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; All we need to do is show that the three properties of partitions hold. Clearly the empty set $\varnothing$ is not in the quotient set $A/\negthickspace\sim$ because the reflexive property of equivalence relations tells us that $x\sim x$, and thus $x\in [x]$ for every $x\in A$.&lt;/p&gt;
&lt;p&gt;Next, suppose that $[x]$ and $[y]$ are equivalences classes in $A/\negthickspace\sim$ and that they are disjoint, i.e. $[x]\cap [y]\ne\varnothing$. Then there exists some $a\in A$ such that $a\in [x]\cap [y]$. That is, $a\in [x]$ and $a\in [y]$, so $a\sim x$ and $a\sim y$. By the symmetric property of equivalence relations, $x\sim a$. And by the transitive property, $x\sim y$. Thus, it follows that $[x]=[y]$.&lt;/p&gt;
&lt;p&gt;Finally, it is clear from the union lemma that the union of all equivalence classes, $\bigcup\limits_{[x]\in A/\sim}[x]$, is the entire set $A$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Notice that we used all three properties of equivalence relations (reflexivity, symmetry and transitivity) to prove this result. This indicates that equivalence relations are the only relations which partition sets in this manner. It turns out that this is true, and it's very easy to prove. I won't do that here because this post is already longer than I intended, but I will at least state the theorem.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; Let $\cal P$ be a partition of a set $A$ and define a relation $\sim$ by $x\sim y$ if and only if $x,y\in X$ for some $X\in\cal P$. Then $\sim$ is an equivalence relation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;What this theorem really tells us is that every partition is the quotient set of some equivalence relation, and that's a really cool idea.&lt;/p&gt;
&lt;hr class="footnotes-sep"&gt;
&lt;section class="footnotes"&gt;
&lt;ol class="footnotes-list"&gt;
&lt;li id="fn1" class="footnote-item"&gt;&lt;p&gt;More formally, it is called the &lt;strong&gt;quotient set of $A$ modulo $\sim$.&lt;/strong&gt; &lt;a href="#fnref1" class="footnote-backref"&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn2" class="footnote-item"&gt;&lt;p&gt;It's easy to extend this example to integers other than $3$, but I feel like a more concrete example is useful here. &lt;a href="#fnref2" class="footnote-backref"&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</content:encoded></item><item><title>Product Spaces</title><description>Next let's talk about an intuitive way to combine topological spaces to create new spaces which inherit certain characteristics from their parents. We've talked about Cartesian products before in the context of set theory, but what happens if we take the Cartesian product of topological spaces?</description><link>http://localhost:2368/product-spaces/</link><guid isPermaLink="false">5c6c6452a4e2f60287eae21f</guid><dc:creator>Eric Shapiro</dc:creator><pubDate>Sat, 08 Apr 2017 20:54:38 GMT</pubDate><content:encoded>&lt;h3 id="contents"&gt;Contents&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#definition"&gt;Definition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#examples"&gt;Examples&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="definitionanamedefinition"&gt;Definition&lt;a name="definition"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Next let's talk about an intuitive way to combine topological spaces to create new spaces which inherit certain characteristics from their parents. We've talked about Cartesian products before in the context of set theory, but what happens if we take the Cartesian product of topological spaces? What should the topology look like?&lt;/p&gt;
&lt;p&gt;Obviously there are many options (to name a few, the discrete or trivial topologies can be defined on any set), but we would like to choose a topology that is as natural as possible and inherits its properties from the spaces from which it is built. This decision actually has its roots in category theory, but I hope that the choice will make some sense to you nonetheless.&lt;/p&gt;
&lt;p&gt;Let's say we are given topological spaces $X$ and $Y$ and we want to construct a &amp;quot;natural&amp;quot; topology on $X\times Y$. Our first instinct might be to choose as the open sets all products $U\times V$ where $U$ is open in $X$ and $V$ is open in $Y$. But even in $\mathbb{R}\times\mathbb{R}$ we can see that this doesn't result in a topology, since the union of products of open sets isn't necessarily itself a product of open sets, as illustrated below.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/nonono.svg" alt="no no no"&gt;&lt;/p&gt;
&lt;p&gt;So clearly the products of open sets aren't going to form a topology by themselves, since they are not closed under unions. We don't throw out this idea entirely, though. It just so happens that the products of open sets do form a &lt;em&gt;basis&lt;/em&gt; for a topology on $X\times Y$.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; Let $(X,{\cal T}_X)$ and $(Y,{\cal T}_Y)$ denote topological spaces. Then ${\cal B} = \{U\times V\mid U\in {\cal T}_X, V\in {\cal T}_V\}$ is a basis for a topology on $X\times Y$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; We argue first that for every $(x,y)\in X\times Y$ there exists a basis element $B\in {\cal B}$ with $(x,y)\in B$. Take $B=X\times Y$. Since $x\in X$ and $y\in Y$, clearly $(x,y)\in B$.&lt;/p&gt;
&lt;p&gt;Next, suppose we are given basis elements $B_1, B_2\in{\cal B}$ for which $B_1\cap B_2\ne\varnothing$. Then by definition $B_1=U_1\times V_1$ and $B_2=U_2\times V_2$ for some open sets $U_1, U_2\in{\cal T}_X$ and $V_1, V_2\in{\cal T}_Y$. Note that $U=U_1\cap U_2\in{\cal T}_X$ and $V=V_1\cap V_2\in{\cal T}_Y$. Thus,&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
B_1\cap B_2 &amp;amp;= (U_1\times V_1)\cap (U_2\times V_2) \\&lt;br&gt;
&amp;amp;= (U_1\cap U_2)\times (V_1\cap V_2) \\&lt;br&gt;
&amp;amp;= U\times V \\&lt;br&gt;
&amp;amp;\in {\cal B}.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;It follows that $B_1\cap B_2$ is a basis element contained in itself, completing the proof.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now that we have a natural basis for a topology on the product of two spaces, defining the product topology is a piece of cake.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; Let Let $(X,{\cal T}_X)$ and $(Y,{\cal T}_Y)$ denote topological spaces. The &lt;strong&gt;product topology&lt;/strong&gt; on $X\times Y$ is the topology generated by the basis ${\cal B} = \{U\times V\mid U\in {\cal T}_X, V\in {\cal T}_V\}$. We call $X\times Y$ a &lt;strong&gt;product space&lt;/strong&gt; when equipped with this topology.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Just to refresh your memory, the open sets in the topology generated by a basis are the empty set and all unions of basis elements. This also guarantees that the entire space is open as a result of the union lemma, as we saw several posts ago.&lt;/p&gt;
&lt;p&gt;The product topology can easily be extended in the obvious way to the Cartesian product of a finite numbers of sets. This basis even generates a topology for an infinite number of sets, but in that case it is actually not the topology we generally use. For an infinite number of sets, the product topology has a few extra restrictions. The basis we just gave extends to what is called the &lt;strong&gt;box topology&lt;/strong&gt; for an infinite product, and it has some undesirable properties. However, I'm fairly confident that I will never need to talk about infinite products on this blog, so I'm going to leave the discussion at that for now.&lt;/p&gt;
&lt;h3 id="examplesanameexamples"&gt;Examples&lt;a name="examples"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; For our first example, consider $\mathbb{R}$ with the standard topology. What is the product topology on $\mathbb{R}\times\mathbb{R}=\mathbb{R}^2$? Well we know that a basis for this topology is all products of open intervals. If $(a,b)$ and $(c,d)$ are open intervals in $\mathbb{R}$ then $(a,b)\times(c,d)$ can be viewed as an open rectangle in $\mathbb{R}^2$. But open rectangles, just like open balls, generate the standard topology on $\mathbb{R}^2$. So the product topology on $\mathbb{R}^2$ is actually the standard topology, and the same holds for any finite product of $\mathbb{R}$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; For our next example, consider the closed interval $[0,1]$ as a subspace of $\mathbb{R}$. The product $[0,1]\times[0,1]$ is just the unit square in $\mathbb{R}^2$. Open sets in the square are unions of products of open sets in $[0,1]$. That is, they are unions of open rectangles.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; Consider the unit circle $S^1=\{(x,y)\in\mathbb{R}^2\mid x^2+y^2=1\}$ as a subspace of $\mathbb{R}^2$. Let's begin by visualizing $S^1\times S^1$. Recalling the definition of the Cartesian product, we can think loosely of each point on the first circle $S^1$ as corresponding to an entire circle. We thus obtain the &lt;strong&gt;torus&lt;/strong&gt;, which is a donut-shaped subset of $\mathbb{R}^3$.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/torus-1.svg" alt="torus"&gt;&lt;/p&gt;
&lt;p&gt;Notice that the torus is hollow. If we wanted a solid torus, we would take $S^1\times D^2$, where $D^2=\{(x,y)\in\mathbb{R}^2\mid x^2+y^2\le 1\}$ is the closed unit ball.&lt;/p&gt;
&lt;p&gt;Before we can think about the topology on the torus $S^1\times S^1$, we should first consider the topology on the circle $S^1$. Since it's a subspace of $\mathbb{R}^2$, open sets in the circle are intersections of $S^1$ with open sets in $\mathbb{R}^2$. These open sets basically look like unions of &amp;quot;open intervals&amp;quot; wrapped around the circle. In fact, they are all homeomorphic to open intervals, except for $S^1$ itself (which I will prove when I talk about connectedness).&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/circle_open_sets.svg" alt="circle open sets"&gt;&lt;/p&gt;
&lt;p&gt;Products of these open sets somewhat resemble open rectangles wrapped around the surface of the torus. We'll call them open patches, and the unions of these open patches form the open sets on the torus.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/torus_open_sets.svg" alt="torus open sets"&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Since $S^1\times S^1$ can also be viewed as a subspace of $\mathbb{R}^3$, we could also view the open sets on the torus as intersections of open sets in $\mathbb{R}^3$ with $S^1\times S^1$. This statement may seen obvious, but I haven't proved it yet.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; Let $X$ and $Y$ denote topological spaces with $A\subseteq X$ and $B\subseteq Y$. The topology on $A\times B$ as a subspace of $X\times Y$ is the same as the product topology where $A$ is a subspace of $X$ and $B$ is a subspace of $Y$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; We argue that any open set in either topology is also open in the other. Choose an open set $U$ in the subspace topology on $A\times B$. By definition, there exists some open set $V$ in $X\times Y$ such that $U=(A\times B)\cap B$. Since it is open in the product topology on $X\times Y$, we have that $V$ must be a union of products of open sets. That is,&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
V &amp;amp;= \bigcup\limits_{i\in I}(S_i\times T_i) \\&lt;br&gt;
&amp;amp;= \bigcup\limits_{i\in I}S_i\times\bigcup\limits_{i\in I}T_i,&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;where $I$ is an indexing set such that $S_i$ is open in $X$ and $T_i$ is open in $Y$ for every $i\in I$. But this means that $U$ is open in the product topology on $A\times B$.&lt;/p&gt;
&lt;p&gt;The proof of the reverse direction is completely symmetrical.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So any open set on the torus can also be expressed as the intersection of open balls in $\mathbb{R}^3$ with $S^1\times S^1$. This may or may not be a simpler way of viewing the topology on the torus, depending on the application.&lt;/p&gt;
&lt;p&gt;I would like to conclude with the proof I promised you in my last post, which greatly simplified the task of showing that the $x$-axis as a subspace of $\mathbb{R}^2$ is homeomorphic to $\mathbb{R}$. This proof closely mimics the corresponding proof in my last post, although I have defined the homeomorphism in the opposite direction just to spice things up a bit. Notice first that the $x$-axis may be written as $\mathbb{R}\times\{0\}$.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; Let $A$ and $B$ denote topological spaces with $b\in B$ and consider $A\times\{b\}$ as a subspace of $A\times B$ with the product topology. Then $A$ is homeomorphic to $A\times\{b\}$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; We will argue that $f:A\to A\times\{b\}$ defined by $f(a)=(a,b)$ is a homeomorphism. Certainly $f$ is bijective and its inverse function $f^{-1}:A\times\{b\}\to A$ is given by $f^{-1}\big((a,b)\big)=a$.&lt;/p&gt;
&lt;p&gt;First we'll show that $f$ is continuous. Let $U$ denote an open set in $A\times\{b\}$. We can write $U$ as the intersection of $A\times\{b\}$ with some union of basis elements of $A\times B$, which are themselves products of open sets. That is, for some indexing set $I$,&lt;/p&gt;
&lt;p&gt;$$U=(A\times B)\cap\bigcup\limits_{i\in I}(A_i\times B_i),$$&lt;/p&gt;
&lt;p&gt;where $A_i\subseteq A$ and $B_i\subseteq B$ are open for every $i\in I$. Thus,&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
f^{-1}[U] &amp;amp;= f^{-1}\left[(A\times B)\cap\bigcup_{i\in I}(A_i\times B_i)\right]\\&lt;br&gt;
&amp;amp;= f^{-1}[A\times B]\cap f^{-1}\left[\bigcup_{i\in I}(A_i\times B_i)\right]\\&lt;br&gt;
&amp;amp;= f^{-1}[A\times B]\cap \bigcup_{i\in I}f^{-1}[A_i\times B_i]\\&lt;br&gt;
&amp;amp;= A\cap\bigcup_{i\in I}A_i\\&lt;br&gt;
&amp;amp;= \bigcup_{i\in I}A_i,&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;which is certainly open in $A$ since it is the union of open sets.&lt;/p&gt;
&lt;p&gt;It is easier to show that $f^{-1}$ is continuous. Let $V$ denote an open set in $A$. Note that $V\times B$ is a basis element for $A\times B$ and is thus open in $A\times B$. Therefore,&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
(f^{-1})^{-1}[V] &amp;amp;= f[V] \\&lt;br&gt;
&amp;amp;= V\times\{b\} \\&lt;br&gt;
&amp;amp;= (A\times\{b\})\cap(V\times B).&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;This is open in $A\times\{b\}$ because it is the intersection of $A\times\{b\}$ with an open set in $A\times B$, completing the proof.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Using this result, we can immediately construct homeomorphisms&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
\mathbb{R}&amp;amp;\to\mathbb{R}\times\{b\}\subset\mathbb{R}^2 \\&lt;br&gt;
\mathbb{R}^2&amp;amp;\to\mathbb{R}^2\times\{b\}\subset\mathbb{R}^3 \\&lt;br&gt;
\mathbb{R}^3&amp;amp;\to\mathbb{R}^3\times\{b\}\subset\mathbb{R}^4 \\&lt;br&gt;
&amp;amp;\;\; \vdots \\&lt;br&gt;
\mathbb{R}^n&amp;amp;\to\mathbb{R}^n\times\{b\}\subset\mathbb{R}^{n+1} \\&lt;br&gt;
&amp;amp;\;\; \vdots&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;between $\mathbb{R}^i$ and 'horizontal' hyperplanes in $\mathbb{R}^{i+1}$. It is also possible to show that arbitrary hyperplanes (formally $n$-dimensional subspaces in the linear algebraic sense) of $\mathbb{R}^{i+1}$ are homeomorphic to $\mathbb{R}^i$, but the proof would require a change of basis and that isn't something we have the machinery to get into right now.&lt;/p&gt;
&lt;p&gt;Anyway, that's all the time I have right now and I think I've done enough to introduce product spaces. May this knowledge aid you in your quest and be your savior in many battles.&lt;/p&gt;
</content:encoded></item><item><title>Subspaces</title><description>A topological space is, at its core, just a set with some additional structure. So what if we want to keep the structure, but change the underlying set? There's an easy and somewhat obvious way to do this.</description><link>http://localhost:2368/subspaces/</link><guid isPermaLink="false">5c6c6452a4e2f60287eae21e</guid><dc:creator>Eric Shapiro</dc:creator><pubDate>Sat, 08 Apr 2017 16:47:05 GMT</pubDate><content:encoded>&lt;h3 id="contents"&gt;Contents&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#definition"&gt;Definition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#examples"&gt;Examples&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="definitionanamedefinition"&gt;Definition&lt;a name="definition"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;In this post I'm going to introduce a classic method which allows us to construct new topological spaces from existing ones in a natural way.&lt;/p&gt;
&lt;p&gt;A topological space is, at its core, just a set with some additional structure. So what if we want to keep the structure, but change the underlying set? There's an easy and somewhat obvious way to do this.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; Let $X$ denote a topological space with topology $\cal T$ and suppose $A\subseteq X$. Then ${\cal T}_A=\{A\cap U\mid U\in{\cal T}\}$ is called the &lt;strong&gt;subspace topology&lt;/strong&gt; on $A$. Equipped with this topology, we call $A$ a &lt;strong&gt;subspace&lt;/strong&gt; of $X$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In standard English, this says that in the subspace topology on $A$, a set is open if it is the intersection of $A$ with some open set in $X$.&lt;/p&gt;
&lt;p&gt;Now we have to prove that we are justified in calling this thing a topology. We need to show that the empty set and the subspace itself are open, that unions of opens sets are open, and that finite intersections of open sets are open.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; Let $X$ denote a topological space with topology $\cal T$ and suppose $A\subseteq X$. Then ${\cal T}_A=\{A\cap U\mid U\in{\cal T}\}$ is a topology on $A$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Notice first that $\varnothing, X\in\cal T$ by the definition a topology. Certainly $\varnothing=A\cap\varnothing\in{\cal T}_A$, so the empty set is open in the subspace. Similarly, $A=A\cap X\in{\cal T}_A$ because $A\subseteq X$, so $A$ itself is open in the subspace.&lt;/p&gt;
&lt;p&gt;Next, suppose that $I$ is an indexing set such that $V_i\in{\cal T}_A$ is open in the subspace for each $i\in I$. Then for every $i\in I$ we have that $V_i=A\cap U_i$ for some open set $U_i\in{\cal T}$, by the definition of the subspace topology. Since $\bigcup\limits_{i\in I}U_i\in\cal T$ it is clear that&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
\bigcup\limits_{i\in I}V_i &amp;amp;= \bigcup\limits_{i\in I}(A\cap U_i) \\&lt;br&gt;
&amp;amp;= A\cap \bigcup\limits_{i\in I}U_i \\&lt;br&gt;
&amp;amp;\in{\cal T}_A,&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;so we have shown that the union of any collection of open sets in the subspace is also open in the subspace.&lt;/p&gt;
&lt;p&gt;Finally, suppose that $V_i\in{\cal T}_A$ is open in the subspace for $1\leq i\leq n$ for some $n\in\mathbb{Z}^+$. Then for $1\leq i\leq n$, we again have that $V_i=A\cap U_i$ for some open set $U_i\in{\cal T}$, by the definition of the subspace topology. Since $\bigcap\limits_{i=1}^n U_i\in\cal T$, it is clear that&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
\bigcap\limits_{i=1}^n V_i &amp;amp;= \bigcap\limits_{i=1}^n (A\cap U_i) \\&lt;br&gt;
&amp;amp;= A\cap \bigcap\limits_{i=1}^n U_i \\&lt;br&gt;
&amp;amp;\in {\cal T}_A,&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;so we have shown that the intersection of a finite collection of open sets in the subspace is also open in the subspace. It follows that the subspace topology on $A$ is a topology, as desired.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I have noticed that people often find the following observation confusing: If $A$ is a subset of a topological space $X$, then the set $A$ is both open and closed in the subspace topology on $A$. This is automatically true because of the definition of a topology. However, this says nothing at all about whether $A$ is open or closed as a &lt;em&gt;subset&lt;/em&gt; of $X$. Similarly, there are plenty of sets that may be open or closed in the subspace topology that may not have been that way in the original topology. Make sure you pay attention to the distinction between subspaces and subsets!&lt;/p&gt;
&lt;p&gt;Next, there's a way to figure out what sets in a subspace are closed which is sometimes more direct than trying to make sure that their complements are open.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; Let $A$ be a subspace of a topological space $X$. Then $U\subseteq A$ is closed in $A$ if and only if $U=A\cap V$ for some closed set $V\subseteq X$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; First, suppose that $U$ is closed in $A$. Then $A-U$ is open by definition, so $A-U=A\cap W$ for some open set $W$ in $X$. Certainly $V=X-W$ is closed in $X$, so&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
U &amp;amp;= A-(A-U) \\&lt;br&gt;
&amp;amp;= A-(A\cap W) \\&lt;br&gt;
&amp;amp;= A-W \\&lt;br&gt;
&amp;amp;= A\cap (X-W) \\&lt;br&gt;
&amp;amp;= A\cap V.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;Conversely, suppose that $U=A\cap V$ for some closed set $V$ in $X$. Then $X-V$ is open in $X$, so&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
A-U &amp;amp;= A-(A\cap V) \\&lt;br&gt;
&amp;amp;= A\cap (X-V)&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;is open in $A$. Thus, $U$ is closed in $A$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I may not have explicitly proved all those set equalities in the past, but if they aren't immediately obvious to you then this might be a good time to go back and get some more practice with set-theoretic proofs.&lt;/p&gt;
&lt;h3 id="examplesanameexamples"&gt;Examples&lt;a name="examples"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Let's look at a few examples of subspaces of topological spaces we are already familiar with.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; Consider $\mathbb{R}$ with the standard topology. Obviously the half-open interval $[0,1)$ is a subset of $\mathbb{R}$. So what is the subspace topology on $[0,1)$?&lt;/p&gt;
&lt;p&gt;Well, we already know it. The open sets are just intersections of $[0,1)$ with any open set in $\mathbb{R}$. Of course, the subspace $[0,1)$ is itself both open and closed.&lt;/p&gt;
&lt;p&gt;Is $(0,1)$ open in the subspace topology? Of course it is. Certainly $(0,1)$ is open in $\mathbb{R}$, and $(0,1)=[0,1)\cap (0,1)$, so it is open in the subspace as well.&lt;/p&gt;
&lt;p&gt;Play around with this a little bit more and you'll notice that the open sets in $[0,1)$ actually look a lot like the open sets in $\mathbb{R}$ which happen to be subsets of $[0,1)$. This is just a testament to the fact that the subspace topology is a very natural object. In fact, whenever I talk about an interval, I'll generally be assuming that it is equipped with the subspace topology induced by the standard topology on $\mathbb{R}$. Even though I won't always explicitly mention this, it will be especially important to remember when I talk about paths and homotopy in the future.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Let's look at another example, shall we?&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;. Consider $\mathbb{R}^2$ in the standard topology, and the set $A=\{(x,0)\in\mathbb{R}^2\mid x\in\mathbb{R}\}$.&lt;sup class="footnote-ref"&gt;&lt;a href="#fn1" id="fnref1"&gt;[1]&lt;/a&gt;&lt;/sup&gt; The open sets in the subspace topology on $A$ are, of course, any sets which can be expressed as the intersection of $A$ with unions of open balls in $\mathbb{R}^2$.&lt;/p&gt;
&lt;p&gt;This looks an awful lot like the standard topology on $\mathbb{R}$, but technically it isn't because $A\ne\mathbb{R}$. In reality, $A$ is just the $x$-axis in the two-dimensional Euclidean plane. So it's basically $\mathbb{R}$, and behaves exactly like it. What we have, then, is that $A$ is homeomorphic to $\mathbb{R}$ with the standard topology.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Let's prove the assertion I just made. It's going to be a bit of work, but I think it's worth proving things just for fun once in a while. The homeomorphism we will choose in our proof is the obvious choice, but there are actually others that could work just as well.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Proposition.&lt;/strong&gt; Consider $\mathbb{R}$ with the standard topology and $A=\{(x,0)\in\mathbb{R}^2\mid x\in\mathbb{R}\}$ as a subspace of $\mathbb{R}^2$ with the standard topology. The spaces $\mathbb{R}$ and $A$ are homeomorphic.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; We argue that the function $f:A\to\mathbb{R}$ defined by $f\big((x,0)\big)=x$ is a homeomorphism. It is trivial to check that $f$ is bijective and that its inverse function $f^{-1}:\mathbb{R}\to A$ is given by $f^{-1}(x)=(x,0)$.&lt;/p&gt;
&lt;p&gt;We will show first that $f^{-1}$ is continuous. Choose an open set $U$ in $A$. By definition, we can write $U$ as the intersection of $A$ with some union of open balls in $\mathbb{R}^2$. That is,&lt;/p&gt;
&lt;p&gt;$$U=A\cap\bigcup\limits_{i\in I} B\big((x_i,y_i),r_i\big)$$&lt;/p&gt;
&lt;p&gt;for some indexing set $I$, where $(x_i,y_i)\in\mathbb{R}^2$ and $r_i\in\mathbb{R}^+$ for each $i\in I$. It follows that&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
(f^{-1})^{-1}[U] &amp;amp;= f[U] \\&lt;br&gt;
&amp;amp;= f\left[A\cap\bigcup\limits_{i\in I}B\big((x_i,y_i),r_i\big)\right] \\&lt;br&gt;
&amp;amp;= f\left[\bigcup\limits_{i\in I}A\cap B\big((x_i,y_i),r_i\big)\right] \\&lt;br&gt;
&amp;amp;= \bigcup\limits_{i\in I}f\Big[A\cap B\big((x_i,y_i),r_i\big)\Big].&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;A small amount of geometry and the Pythagorean Theorem gets us that for each $i\in I$, the set $f\Big[A\cap B\big((x_i,y_i),r_i\big)\Big]$ is equal to the open interval&lt;/p&gt;
&lt;p&gt;$$\left(x_i-\sqrt{r_i^2-y_i^2}, x_i+\sqrt{r_i^2-y_i^2}\right)$$&lt;/p&gt;
&lt;p&gt;if $r_i&amp;gt;y_i$, and it is empty if $r_i\leq y_i$. The union of open intervals is open in $\mathbb{R}$, so $(f^{-1})^{-1}[U]$ is open in $\mathbb{R}$ and thus $f^{-1}$ is continuous.&lt;/p&gt;
&lt;p&gt;Next, we will show that $f$ is continuous. Choose an open set $U$ in $\mathbb{R}$. By definition, $U$ is a union of open intervals in $\mathbb{R}$ (possibly $\mathbb{R}$ itself, in which case $f^{-1}[U]=f^{-1}[\mathbb{R}]=A$ is certainly open). More precisely, we can write&lt;/p&gt;
&lt;p&gt;$$U=\bigcup\limits_{i\in I}(x_i-r_i,x_i+r_i),$$&lt;/p&gt;
&lt;p&gt;where $I$ is some indexing set such that $x_i\in\mathbb{R}$ and $r_i\in\mathbb{R}^+$ for every $i\in I$. It follows that&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
f^{-1}[U] &amp;amp;= f^{-1}\left[\bigcup\limits_{i\in I}(x_i-r_i,x_i+r_i)\right] \\&lt;br&gt;
&amp;amp;= f^{-1}\left[\bigcup\limits_{i\in I}\left\{x\in\mathbb{R}\bigg\vert \vert x-x_i\vert&amp;lt; r_i\right\}\right] \\&lt;br&gt;
&amp;amp;= \bigcup\limits_{i\in I}f^{-1}\left[\left\{x\in\mathbb{R}\bigg\vert \vert x-x_i\vert&amp;lt; r_i\right\}\right] \\&lt;br&gt;
&amp;amp;= \bigcup\limits_{i\in I}\left\{(x,0)\in\mathbb{R}^2\bigg\vert\vert x-x_i\vert&amp;lt; r_i\right\} \\&lt;br&gt;
&amp;amp;= \bigcup\limits_{i\in I}\bigg(A\cap B\big((x_i,0),r_i\big)\bigg) \\&lt;br&gt;
&amp;amp;= A\cap \bigcup\limits_{i\in I}B\big((x_i,0),r_i\big).&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;The union of open balls is open, so $f^{-1}[U]$ is the intersection of $A$ with an open set in $\mathbb{R}$ and is thus open in $A$. It follows that $f$ is continuous, completing the proof.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It ended up being a bit long, but not too difficult. And I think this example really gets the point across that even though homeomorphic spaces may not be identical, they behave in essentially the same way. Most people aren't as careful as I just was, and frequently write that $\mathbb{R}$ is a subspace of $\mathbb{R}^2$. This isn't strictly true, but at least you now know how to interpret it.&lt;/p&gt;
&lt;p&gt;Just so you know, we will see another proof of the above proposition when I talk about product spaces. I just really wanted to prove it this way once to give you some geometric intuition behind why it's true.&lt;/p&gt;
&lt;p&gt;The last thing I'm going to do in this post is show that an open interval in $\mathbb{R}$ is homeomorphic to $\mathbb{R}$ itself. This will reinforce the notion that stretching a space does not alter its topological properties.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Proposition.&lt;/strong&gt; Let $a,b\in\mathbb{R}$ with $a&amp;lt; b$. Then $\mathbb{R}$ and the interval $(a,b)$ are homeomorphic.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&amp;quot;Proof.&amp;quot;&lt;/strong&gt; Define $f:(a,b)\to\mathbb{R}$ by&lt;/p&gt;
&lt;p&gt;$$f(x)=\frac{1}{x-a}+\frac{1}{x-b}.$$&lt;/p&gt;
&lt;p&gt;We will argue that $f$ is a homeomorphism. I am not going to check that $f$ is a bijection, although it is obvious just from looking at its graph. This could be done using the quadratic formula to find an explicit inverse function, being careful to restrict $f^{-1}$ so that it is surjective. It could also be done using calculus to show that this function is injective because it is monotonically decreasing and surjective by the intermediate value theorem because it approaches negative infinity at its left endpoint and positive infinity at its right endpoint.&lt;/p&gt;
&lt;p&gt;The function $f$ is clearly continuous because it is a rational function whose denominator is nonzero for every $x\in(a,b)$. Its inverse, $f^{-1}$ is also continuous for the same reason, but since I haven't explicitly computed it I will not show that this is the case.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Okay, so that really wasn't a proof at all. But again, a quick glance at the graph of $f$ should really be enough to convince you that it's a homeomorphism. I could be more precise in giving an argument that any two open intervals are homeomorphic, but I think this post has gone on long enough already, and hopefully this fact is obvious to you. On the other hand, closed intervals are &lt;em&gt;not&lt;/em&gt; homeomorphic to open intervals. We don't have enough tools to prove that at this point, but it will become trivial when I talk about compactness in a later post.&lt;/p&gt;
&lt;hr class="footnotes-sep"&gt;
&lt;section class="footnotes"&gt;
&lt;ol class="footnotes-list"&gt;
&lt;li id="fn1" class="footnote-item"&gt;&lt;p&gt;$(x,0)$ is not an open interval here, but a point in $\mathbb{R}^2$. That is, it's an ordered pair of real numbers. The fact that open intervals and ordered pairs have the same notation is unfortunate, but if we are careful it should always be clear which we are talking about. &lt;a href="#fnref1" class="footnote-backref"&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</content:encoded></item><item><title>Continuity and Homeomorphisms</title><description>The concept of continuity is central to the study of topology. So much so, in fact, that whenever anyone talks about a map between topological spaces, they generally expect you to know that they're talking about a continuous map.</description><link>http://localhost:2368/continuity-and-homeomorphisms/</link><guid isPermaLink="false">5c6c6452a4e2f60287eae21d</guid><dc:creator>Eric Shapiro</dc:creator><pubDate>Sat, 08 Apr 2017 03:08:10 GMT</pubDate><content:encoded>&lt;h3 id="contents"&gt;Contents&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#continuity"&gt;Continuity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#homeomorphisms"&gt;Homeomorphisms&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="continuityanamecontinuity"&gt;Continuity&lt;a name="continuity"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The concept of continuity is central to the study of topology. So much so, in fact, that whenever anyone talks about a map between topological spaces, they generally expect you to know that they're talking about a continuous map.&lt;sup class="footnote-ref"&gt;&lt;a href="#fn1" id="fnref1"&gt;[1]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;I've heard it said that a function is continuous if you can draw its graph without lifting your pencil. This is an awful, imprecise definition, but it does give us a hint of intuition regarding the nature of continuity.&lt;/p&gt;
&lt;p&gt;So then what is continuity? Let's take a look at pieces of two functions, $f,g:\mathbb{R}\to\mathbb{R}$.&lt;sup class="footnote-ref"&gt;&lt;a href="#fn2" id="fnref2"&gt;[2]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/i_can_haz_continuous.svg" alt="I can haz continuous?"&gt;&lt;/p&gt;
&lt;p&gt;Your gut instinct should tell you that $f$ is continuous on the interval depicted but $g$ is not. So what does your gut know that you don't? Here's a (very) rough description:&lt;/p&gt;
&lt;p&gt;If you zoom in far enough on any point in the graph of $f$, the whole graph behaves similarly in that region. On the other hand, there are pieces of the graph of $g$ which look nothing like nearby pieces.&lt;/p&gt;
&lt;p&gt;This is just an informal way of saying that if a function is continuous, points that are close together get mapped to points that are close together. This phrasing is not only much more revealing, it also allows us to extend the definition of continuity away from real-valued functions.&lt;/p&gt;
&lt;p&gt;Let's make this notion more precise, in the context of metric spaces. I'll give you the definition first, and then try to make sense of it for you.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; Let $X$ and $Y$ denote metric spaces. A function $f:X\to Y$ is &lt;strong&gt;continuous at the point&lt;/strong&gt; $x\in X$ if for every real number $\epsilon&amp;gt;0$, there exists a real number $\delta&amp;gt;0$ such that $f\big[B(x,\delta)\big]\subseteq B\big(f(x),\epsilon\big)$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; A function $f:X\to Y$ is &lt;strong&gt;continuous&lt;/strong&gt; if it is continuous at every point $x\in X$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;All the definition really says is that if a function is continuous at $x$, no matter how closely you look at $f(x)$ there will always be points around $x$ which get mapped within that distance of $f(x)$. So like I said earlier, points that are close together get mapped to points that are close together.&lt;/p&gt;
&lt;p&gt;If that makes perfect sense to you, skip the next few paragraphs. Otherwise, I'm going to explain this definition to you very slowly through a story.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Think of the person you loathe the most in this world. I'll refer to this person as &amp;quot;the enemy&amp;quot; and use the pronoun &amp;quot;it.&amp;quot;&lt;/p&gt;
&lt;p&gt;Say you have two metric spaces $X$ and $Y$, and a continuous map $f:X\to Y$ between them:&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/some_spaces.svg" alt="some spaces"&gt;&lt;/p&gt;
&lt;p&gt;You are omnipotent, as in real life, and you know everything there is to know about $X,Y$ and $f$. However, the enemy, being a foolish fool, mistakenly thinks that $f$ is not continuous. And so it tries to trick you. It plots a point $x\in X$ and its image $f(x)\in Y$. Then it draws an open ball $B$ of radius $\epsilon$ around $f(x)$.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/turn_1.svg" alt="turn 1"&gt;&lt;/p&gt;
&lt;p&gt;The enemy challenges you to find an open ball $B'$ around $x$ whose image is contained in $B$. So you think for a while and you use your information about $f$ and you quickly come up with such an open ball, with radius $\delta$.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/turn_2.svg" alt="turn 2"&gt;&lt;/p&gt;
&lt;p&gt;The enemy is angry. It chooses a new smaller ball $B$ and you draw a new, smaller $B'$ to compensate. You do it faster this time, because you've noticed a pattern. No matter what radius $\epsilon$ it chooses to make $B$, you've come up with a method to calculate the radius $\delta$ that $B'$ needs to be so that $f[B']$ will fit inside $B$.&lt;/p&gt;
&lt;p&gt;You tell the enemy your method, and it has no choice but to conclude that $f$ is continuous at $x$. Next, you demonstrate how to do this for any point $x\in X$, and reason that $f$ is continuous. The enemy's head promptly explodes.&lt;/p&gt;
&lt;p&gt;Let's look at a specific example. Let $X$ be a metric space and consider the identity function $i:X\to X$ defined by $i(x)=x$ for every $x\in X$. The enemy first chooses a point $x_0\in X$ and draws a ball of radius $\epsilon$ around $x_0=i(x_0)$. You realize immediately that&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
i\big[B(x_0,\epsilon)\big] &amp;amp;= B(x_0,\epsilon) \\&lt;br&gt;
&amp;amp;= B\big(i(x_0),\epsilon\big)&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;because $i$ is the identity function. So no matter what point $x_0$ or radius $\epsilon$ the enemy chooses, picking $\delta=\epsilon$ will always work. This argument shows that the identity function on any metric space is continuous!&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Hopefully the definition of continuity makes sense to you now, because I'm about move on to an equivalent and simpler definition.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; Let $X$ and $Y$ denote metric spaces with $f: X\to Y$. Then $f$ is continuous if and only if the preimage $f^{-1}[U]$ of any open set $U\subseteq Y$ is open in $X$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Suppose first that $f:X\to Y$ is continuous. If $f^{-1}[U]=\varnothing$ then we are done because this is open in $X$. Suppose then that $f^{-1}[U]\ne\varnothing$. Choose $x\in f^{-1}[U]$, so that $f(x)\in U$. Since $U$ is open, there exists a real number $\epsilon&amp;gt;0$ such that $B\big(f(x),\epsilon\big)\subseteq U$. Since $f$ is continuous, there exists a real number $\delta&amp;gt;0$ such that $f\big[B(x,\delta)\big]\subseteq B\big(f(x),\epsilon\big)$. That is, $B(x,\delta)\subseteq f^{-1}\big[B\big(f(x),\epsilon\big)\big]\subseteq f^{-1}[U]$. Thus, there is an open ball centered at $x$ which is contained in $f^{-1}[U]$, so clearly $f^{-1}[U]$ is open in $X$.&lt;/p&gt;
&lt;p&gt;Suppose conversely that $f^{-1}[U]$ is open in $X$ whenever $U$ is open in $Y$. Choose $x\in X$ and a real number $\epsilon&amp;gt;0$. Since $B\big(f(x),\epsilon\big)$ is open in $Y$, we have that $f^{-1}\big[B\big(f(x),\epsilon\big)\big]$ is open in $X$. Since $x\in f^{-1}\big[B\big(f(x),\epsilon\big)\big]$, there exists a real number $\delta&amp;gt;0$ such that $B(x,\delta)\subseteq f^{-1}\big[B\big(f(x),\epsilon\big)\big]$. Thus, $f$ is continuous.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is most excellent. We've arrived at a &amp;quot;distance-free&amp;quot; definition of continuity, phrased entirely in terms of open sets. You know what that means! We're going to adopt this as the definition of continuity in a general topological setting.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; Let $X$ and $Y$ denote topological spaces. A function $f:X\to Y$ is &lt;strong&gt;continuous&lt;/strong&gt; if $f^{-1}[U]$ is open in $X$ whenever $U$ is open in $Y$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;There is also a corresponding definition for continuity at a point, but we will never need it.&lt;/p&gt;
&lt;p&gt;As is oft desired, we would like a way to determine whether a function between topological spaces is continuous, given only a basis for each space. This is done easily and naturally.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; Let $X$ and $Y$ denote topological spaces, let ${\cal B}_X$ be a basis for the topology on $X$ and ${\cal B}_Y$ a basis for the topology on $Y$. A function $f:X\to Y$ is continuous if and only if $f^{-1}[B]$ is open in $X$ whenever $B\in{\cal B}_Y$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Suppose first that $f$ is continuous. Since $B$ is a basis element, it is open in $Y$. It follows immediately that $f^{-1}[B]$ is open in $X$.&lt;/p&gt;
&lt;p&gt;Suppose next that the preimage of any basis element in $Y$ is open in $X$. It has been established that for any open set  $U\subseteq Y$, there exists an indexing set $I$ and basis elements $B_i\in{\cal{B}}_Y$ such that  $U=\bigcup\limits_{i\in I}B_i$. Thus,&lt;/p&gt;
&lt;p&gt;$$f^{-1}[U]=f^{-1}\left[\bigcup\limits_{i\in I}B_i\right]=\bigcup\limits_{i\in I}f^{-1}[B_i],$$&lt;/p&gt;
&lt;p&gt;which is open since it is the union of open sets.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Yay! Now let's use our beautiful definition of continuity to prove an elementary property of continuous maps: that the composition of two continuous functions&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; Let $X,Y$ and $Z$ denote topological spaces with continuous functions $f:X\to Y$ and $g:Y\to Z$. Then their composition $(g\circ f):X\to Z$, defined by $(g\circ f)(x)=g\big(f(x)\big)$ for every $x\in X$, is continuous.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Suppose $U\subseteq Z$ is open. Then $g^{-1}[U]\subseteq Y$ is open, so $f^{-1}\big[g^{-1}[U]\big]\subseteq X$ is open. Thus, it suffices to show that $f^{-1}\big[g^{-1}[U]\big]=(g\circ f)^{-1}[U]$.&lt;/p&gt;
&lt;p&gt;Suppose $x\in f^{-1}\big[g^{-1}[U]\big]$. Then $f(x)\in g^{-1}[U]$, so $g\big(f(x)\big)=(g\circ f)(x)\in U$. Thus, $x\in (g\circ f)^{-1}[U]$.&lt;/p&gt;
&lt;p&gt;Suppose next that $x\in (g\circ f)^{-1}[U]$. Then $(g\circ f)(x)=g\big(f(x)\big)\in U$, so $f(x)\in g^{-1}[U]$ and thus $x\in f^{-1}\big[g^{-1}[U]\big]$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id="homeomorphismsanamehomeomorphisms"&gt;Homeomorphisms&lt;a name="homeomorphisms"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Ages ago, when I first started talking about topological spaces, I mentioned the idea of topological equivalence. I believe I said something like &amp;quot;two spaces are topologically equivalent if they can be continuously deformed into each other,&amp;quot; and that &amp;quot;continuous deformations are ways we can bend, stretch and move spaces without tearing, cutting or gluing them.&amp;quot; We now have the machinery to formally define this notion.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; Let $X$ and $Y$ denote topological spaces. A bijective function $f:X\to Y$ is a &lt;strong&gt;homeomorphism&lt;/strong&gt; if both $f$ and $f^{-1}:X\to Y$ are continuous. We say that the spaces are &lt;strong&gt;homeomorphic&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It is particularly important that $f$ is bijective, since otherwise $f^{-1}$ would not be well defined.&lt;/p&gt;
&lt;p&gt;There is no consistent symbol for &amp;quot;is homeomorphic to,&amp;quot; although I've seen several used by different authors. For instance, $X\simeq Y$, $Y\approx Y$ or $X\sim Y$ could all be used. And I've seen them all used. I won't use any such notation, however, because I find it terribly confusing.&lt;/p&gt;
&lt;p&gt;It should go without saying that if a function is a homeomorphism then so is its inverse. The next result is perhaps a tad less obvious, although its proof is almost trivial.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; Let $X, Y$ and $Z$ denote topological spaces with homeomorphisms $f:X\to Y$ and $g:Y\to Z$. Then $X$ is homeomorphic to $Z$ via $(g\circ f):X\to Z$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Since $f,g$ are bijective and continuous, $g\circ f$ is bijective and continuous. Furthermore, since $f^{-1},g^{-1}$ are bijective and continuous, $(g\circ f)^{-1}=f^{-1}\circ g^{-1}$ is bijective and continuous. Thus $g\circ f$ is a homeomorphism.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Unfortunately, it is difficult to give simple examples of homeomorphic spaces without first discussing the constructions of new spaces, so more examples of homeomorphisms won't come for a few posts. We can, however, talk about what homeomorphism really means.&lt;/p&gt;
&lt;p&gt;Given a homeomorphism $f$, we know that $f$ and its inverse $f^{-1}$ are continuous. This means that open sets get mapped to open sets in both directions. So essentially, homeomorphisms preserve open sets. Why is this nice? &lt;strong&gt;Because topological spaces are defined in terms of open sets.&lt;/strong&gt; This indicates that homeomorphic spaces are really the same, just with their open sets renamed in some way.&lt;/p&gt;
&lt;p&gt;There is a lot more to say about homeomorphisms. In fact, much of what topologists do is in an attempt to identify which spaces are homeomorphic.&lt;sup class="footnote-ref"&gt;&lt;a href="#fn3" id="fnref3"&gt;[3]&lt;/a&gt;&lt;/sup&gt; And it isn't always obvious directly from the definition. All the tools I bring up from now on will be useful on this quest.&lt;/p&gt;
&lt;p&gt;We will mainly be interested in things called &lt;strong&gt;topological invariants&lt;/strong&gt;, which are characteristics of spaces that are preserved under homeomorphisms. If two spaces have different invariants, this tells us that these spaces are &lt;em&gt;not&lt;/em&gt; homeomorphic. As we shall see, connectedness, compactness, countability, separation conditions, homology and homotopy groups are all topological invariants. These are all properties of the open sets of spaces, so this makes sense. Properties like boundedness and completeness, on the other hand, which rely on the notion of distance, are not topological invariants.&lt;/p&gt;
&lt;hr class="footnotes-sep"&gt;
&lt;section class="footnotes"&gt;
&lt;ol class="footnotes-list"&gt;
&lt;li id="fn1" class="footnote-item"&gt;&lt;p&gt;If I haven't mentioned this before, &amp;quot;map&amp;quot; is just another word for &amp;quot;function&amp;quot; and the two are often used interchangeably. &lt;a href="#fnref1" class="footnote-backref"&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn2" class="footnote-item"&gt;&lt;p&gt;I'm not sure why the arrows in my diagram are on sideways, but I'm too lazy to fix it. &lt;a href="#fnref2" class="footnote-backref"&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn3" class="footnote-item"&gt;&lt;p&gt;Although we are often willing to settle for homotopy equivalence. &lt;a href="#fnref3" class="footnote-backref"&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</content:encoded></item><item><title>Limit Points, Closure, Boundary and Interior</title><description>It's fairly common to think of open sets as sets which do not contain their boundary, and closed sets as sets which do contain their boundary. The trouble here lies in defining the word 'boundary.'</description><link>http://localhost:2368/limit-points-closure-boundary-and-interior/</link><guid isPermaLink="false">5c6c6452a4e2f60287eae21c</guid><dc:creator>Eric Shapiro</dc:creator><pubDate>Sat, 08 Apr 2017 00:34:07 GMT</pubDate><content:encoded>&lt;h3 id="contents"&gt;Contents&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#limit-points"&gt;Limit Points&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#closure"&gt;Closure&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#boundary"&gt;Boundary&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#interior"&gt;Interior&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;We are nearly ready to begin making some distinctions between different topological spaces. Distinguishing between fundamentally different spaces lies at the heart of the subject of topology, and it will occupy much of our time. However, before we can really dig in, we're going to need some additional tools.&lt;/p&gt;
&lt;p&gt;On a different note, and I've been meaning to mention this, I'd be willing to bet that you probably had a different sense of what open and closed sets were before learning any topology. It's fairly common to think of open sets as sets which do not contain their boundary, and closed sets as sets which do contain their boundary. The trouble here lies in defining the word 'boundary.' This is finally about to be addressed, first in the context of metric spaces because it is easier to see why the definitions are natural there. As in prior posts, these concepts generalize easily to topological space.&lt;/p&gt;
&lt;h3 id="limitpointsanamelimitpoints"&gt;Limit Points&lt;a name="limit-points"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;If you've had any calculus, you've probably had some experience with limits. Whether or not the formal $\epsilon$-$\delta$ definition of a limit is familiar to you is of no real consequence. Even though this definition is extremely insightful, it isn't really necessary for our purposes. In fact, if we aren't working in a metric space then this definition doesn't even apply. The good news it that many definitions in topology have a sort of &lt;em&gt;too-good-to-be-true&lt;/em&gt; feel to them, since they're often deceptively simple.&lt;/p&gt;
&lt;p&gt;Limit points are not the same type of limit that you encounter in a calculus or analysis class, but the underlying idea is similar. Informally, a point in a metric space is a limit point of some subset if it is arbitrarily close to other points in that subset. What exactly does this mean? It means that no matter how closely we zoom in on a limit point, there will always be another point in its immediate vicinity which belongs to the subset in question. Thus, we can in some sense approximate limit points to arbitrary accuracy using other points in the subset. This might be a little confusing or overwhelming, so I'll give you the definition now and you'll see that it isn't too bad. Its simplicity may even be a bit misleading.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; Let $A$ denote a subset of a metric space $X$. A point $p\in X$ is a &lt;strong&gt;limit point&lt;/strong&gt; of $A$ if every open ball centered at $p$ contains a point $x\in A$ with $x\neq p$. We write $L(A)$ to denote the set of limit points of $A$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The first thing that I will emphasize is that a limit point of a set does not need to belong to that set! All that is necessary is that there are points in the set &lt;em&gt;as close as we like&lt;/em&gt; to the limit point. This can be made more obvious by rephrasing the definition slightly. By &amp;quot;every open ball,&amp;quot; what we mean is that for every real number $\epsilon&amp;gt;0$ there exists some point $x\in A$ distinct from $p$ such that $x\in B(p,\epsilon)$. Take a moment to appreciate and understand that this definition ensures what I claim it does.&lt;/p&gt;
&lt;p&gt;There's a sort of dual notion as well, which is called an isolated point. The following definition makes it clear that any point in a subset of a metric space is either a limit point or an isolated point.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; Let $A$ denote a subset of a metric space $X$. A point $p\in X$ is an &lt;strong&gt;isolated point&lt;/strong&gt; of $A$ if there exists an open ball centered at $p$ which contains no other points of $A$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Let's look at an example, to make sure we're fully on board with these concepts before we press onward. I'm going to cordon off the entire example so that we don't accidentally make sweeping generalizations about every metric space based on this one scenario.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; Take $X=\mathbb{R}^2$ equipped, of course, with the standard metric $d:X\times X\to\mathbb{R}$. Let $A=B\big((0,0),1\big)$, the open unit ball centered at the origin. Consider the following points in $X$:&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
x &amp;amp;= (0,0), \\&lt;br&gt;
y &amp;amp;= (1,0), \\&lt;br&gt;
z &amp;amp;= (1,1). \\&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;I'll even throw in a diagram to make things crystal clear:&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/limit_point_example.svg" alt="limit point example"&gt;&lt;/p&gt;
&lt;p&gt;Clearly $x\in A$ because $d(x,x)=0&amp;lt; r$. However, $y,z\notin A$ because $d(x,y)=r$ and $d(x,z)=\sqrt{2}&amp;gt;r$. Which, if any, of the points $x,y,z$ are limit points of $A$?&lt;/p&gt;
&lt;p&gt;Let's consider $x$ first. Does every open ball centered at $x$ contain a point in $A$ distinct from $x$? The simple answer is &amp;quot;well DUH,&amp;quot; but let's be a tad more rigorous.&lt;/p&gt;
&lt;p&gt;Choose a real number $\epsilon&amp;gt;0$. We consider separately the cases where $\epsilon\geq 1$ and $0&amp;lt;\epsilon&amp;lt;1$. If $\epsilon\geq 1$ then $A\subseteq B(x,\epsilon)$ and we are done because there are certainly points in $A$ distinct from $x$. If $0&amp;lt;\epsilon&amp;lt;1$, it is clear that the point $x_0=(0,\epsilon/2)\in B(x,\epsilon)$. Furthermore, $x_0\neq x$ because $d(x,x_0)&amp;gt;0$.&lt;/p&gt;
&lt;p&gt;So $x$ is a limit point of $A$, which was sort of obvious from the start. A similar argument could be made that any point $a\in A$ is a limit point of $A$ by adding a few more technical details to the above argument, but I won't bother because it feels like overkill.&lt;/p&gt;
&lt;p&gt;Next, let's take a look at $y$. You should have a sense that $y$ is a limit point of $A$, because even though it is not in $A$ it is &lt;em&gt;superextraclose&lt;/em&gt; to lots and lots of points in $A$. Let's show that our intuition is correct.&lt;/p&gt;
&lt;p&gt;Again, choose a real number $\epsilon&amp;gt;0$ and consider the open ball $B(y,\epsilon)$. The point $y_0=(0,1-\epsilon/2)$ is clearly in $B(y,\epsilon)$ because $d(y,y_0)=\epsilon/2&amp;lt;\epsilon$ and thus it is also distinct from $y$. Furthermore, $y_0\in A$ since $d(x,y_0)=1-\epsilon/2&amp;lt;1$.&lt;/p&gt;
&lt;p&gt;We've shown then that $y$ is a limit point of $A$, which is somewhat more interesting. A similar argument would show that any point $a\in X$ with $d(a,x)=1$ is a limit point of $A$. Sooo... even though we haven't defined the concept of &amp;quot;boundary&amp;quot; yet, it's looking like any point on what we intuitively perceive to be the boundary of $A$ is a limit point of $A$. This is an important realization.&lt;/p&gt;
&lt;p&gt;Finally, let's show that $z$ is not a limit point of $A$. To show that the necessary property is not true for every open ball centered at $z$, all we need to do is demonstrate a single open ball centered at $z$ which contains no points of $A$. This is easy! Just take as the radius any positive $\epsilon&amp;lt;\sqrt{2}-1$ and that's essentially all there is to it.&lt;/p&gt;
&lt;p&gt;More formally, choose $\epsilon&amp;lt;\sqrt{2}-1$ and consider $z_0\in B(z,\epsilon)$. By the definition of this open ball $d(z,z_0)&amp;lt;\epsilon$. By the triangle inequality,&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
d(x,z) &amp;amp;= \sqrt{2} \\&lt;br&gt;
&amp;amp;\leq d(x,z_0) + d(z_0,z) \\&lt;br&gt;
&amp;amp;&amp;lt; d(x,z_0) + \epsilon \\&lt;br&gt;
&amp;amp;&amp;lt; d(x,z_0)+\sqrt{2}-1.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;Rearranging the above inequality, we have that $d(x,z_0)&amp;gt;1$ and so $z_0\notin A$. Thus, $z$ is not a limit point of $A$. Once again, a similar argument would show that, in general, any point $p\in X$ with $d(p,x)&amp;gt;1$ is not a limit point of $A$.&lt;/p&gt;
&lt;p&gt;What can we conclude about this particular set $A$? The limit points of $A$ are every point in $A$ as well as every point on the unit circle $S^1$. That is, $L(A)=A\cup S^1=\overline{B}(x,r)$. This is the closed ball with the same center and radius as $A$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;We shall see soon enough that this is no accident. For any subset $A$ of a metric space $X$, it happens that the set of limit points $L(A)$ is closed. Let's prove something even better.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; A subset of a metric space is closed if and only if it contains all of its limit points.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; We argue first that if $L(A)\subseteq A$ then $A$ is closed. It suffices to show that $X-A$ is open. Choose a point $x\in X-A$. Clearly $x$ is not a limit point of $A$ since $x\notin A$ and thus $x\notin L(A)\subseteq A$. Thus there exists some open ball $B$ centered at $x$ which does not contain any points in $A$. It follows that $B\subseteq X-A$ and so $X-A$ is open.&lt;/p&gt;
&lt;p&gt;We argue next that if $A$ is closed then $L(A)\subseteq A$. Since $A$ is closed, we know that $X-A$ is open. Thus for any $x\in X-A$ there exists some open ball centered at $x$ which is strictly contained in $X-A$ and therefore contains no points of $A$. It follows that $x$ is not a limit point of $A$, so any limit points of $A$ are contained in $A$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Hooray! We now have an alternative, and often easier to use, definition of a closed set in a metric space! What's awesome is that nothing we've done (other than our example) depends on the metric, so we can immediately abstract everything to the setting of topological spaces!&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; Let $A$ denote a subset of a topological space $X$. A point $p\in X$ is a &lt;strong&gt;limit point&lt;/strong&gt; of $A$ if every neighborhood of $p$ contains a point $x\in A$ with $x\neq p$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The theorem we just proved translates as well, if we simply replace open balls with neighborhoods each time the appear in the proof.&lt;/p&gt;
&lt;p&gt;As always, there's nothing contradictory about the fact that the empty set is closed. Certainly the empty set contains all of its limit points, since it contains no points at all.&lt;/p&gt;
&lt;h3 id="closureanameclosure"&gt;Closure&lt;a name="closure"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;We will now define the closure of a subset of a topological space. We will see later that taking the closure of a set is equivalent to include the set's boundary.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; Let $A$ denote a subset of a topological space $X$. The &lt;strong&gt;closure&lt;/strong&gt; of $A$ is the intersection of all closed set in $X$ which contain $A$. We denote the closure of a $A$ by $\overline A$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The closure of a set is always closed, because it is the intersection of closed sets. Furthermore, it is obvious that any closed set must equal its own closure. Intuitively, $\overline A$ is the smallest closed set which contains $A$. This is because, by definition, any closed set containing $A$ must also contain $\overline A$. Even more intuitively, the closure of $A$ is the union of $A$ with all of its limit points. Let's prove that this is true.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; If $A$ is a subset of a topological space, then $\overline A=A\cup L(A)$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; We argue first that $A\cup L(A)\subseteq\overline A$. Clearly $A\subseteq\overline A$ since $\overline A$ is the intersection of all closed sets containing $A$, and thus itself contains $A$. It remains to show then that $L(A)\subseteq\overline A$, which we do by contraposition. Suppose $x\notin\overline A$ so that $x\in X-\overline A$. Since $\overline A$ is closed, $X-\overline A$ is open and is thus a neighborhood of $x$ which contains no points in $A$. Thus $x\notin L(A)$.&lt;/p&gt;
&lt;p&gt;We argue next that $\overline A\subseteq A\cup L(A)$. If $x\in A$ then the proof is immediate. If $x\in\overline A -A$, then by definition $x$ is in every closed set containing $A$. It follows that for any open set $U\subseteq X-A$, we have $x\notin U$. Thus any neighborhood of $x$ intersects $A$ in some point $p$. Since $x\notin A$, clearly $x\neq p$ and thus $x$ is a limit point of $A$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It's a somewhat gross proof, but a nice and useful result, and one that we will use often.&lt;/p&gt;
&lt;h3 id="boundaryanameboundary"&gt;Boundary&lt;a name="boundary"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Next let's formalize the concept of boundary. It's easy and intuitive to think about the boundary of a ball, so let's start there. Let's say we have an open and closed ball of the same center and radius in some metric space. They obviously have the same boundary — the circle with the same radius as these balls. Even though these points don't belong to the open ball, they are &lt;em&gt;just&lt;/em&gt; touching its outer edge.&lt;/p&gt;
&lt;p&gt;Now what about this set, as a subset of $\mathbb{R}^2$ in the standard metric?&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/vomitous_mass.svg" alt="vomitous mass"&gt;&lt;/p&gt;
&lt;p&gt;Trying to calculate the boundary of this set is a bit more difficult than just drawing a circle. Does that loop at the top right count as boundary? What about the points sitting by themselves? Do those inner circles count as well, or does the boundary have to enclose the set? It turns out that, the way we define boundary, the answer to all of these questions is yes.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; Let $A$ be a subset of a metric space $X$. A point $p\in X$ is a &lt;strong&gt;boundary point&lt;/strong&gt; of $A$ if every open ball centered at $p$ contains at least one point in $A$ and one point in $X-A$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; The &lt;strong&gt;boundary&lt;/strong&gt; of $A$ is the set of all boundary points of $A$. We denote it by $\partial A$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This makes a lot of sense! No matter how tiny an open ball we choose around a boundary point, it will always intersect both $A$ and its complement. That is, it will always contain points that are in $A$ and points that are not in $A$.&lt;/p&gt;
&lt;p&gt;These definitions are identical in a topological space if we again replace open balls with neighborhoods. I won't even bother restating them.&lt;/p&gt;
&lt;p&gt;It turns out we could already have defined the boundary of a set without the notion of boundary points!&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; If $A$ is a subset of a topological space $X$, then $\partial A=\overline A\cap\overline{X-A}$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Choose $x\in\partial A$. By definition, every neighborhood of $x$ contains a point in $A$ and a point in $X-A$, so $x\in\overline A$ and $x\in\overline{X-A}$. Thus $x\in\overline A\cap\overline{X-A}$ and so $\partial A\subseteq \overline A\cap\overline{X-A}$.&lt;/p&gt;
&lt;p&gt;The proof that $\overline A\cap\overline{X-A}\subseteq\partial A$ is precisely the same as above, with the steps reversed.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This means that the boundary of $A$ is the intersection of the smallest closed set containing $A$ and the smallest closed set containing its complement, which hopefully seems reasonable to you.&lt;/p&gt;
&lt;h3 id="interioranameinterior"&gt;Interior&lt;a name="interior"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I'm not going to bother with metric spaces for this part, since I think you get the idea. You can easily translate all the results about topological spaces back into metric spaces if you'd like. Intuitively, we can think of the interior of a set as everything in the set which does not belong to its boundary. This is actually not the definition we'll initially give, although we shall soon see that they are equivalent.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; Let $A$ denote a subset of a topological space $X$. The &lt;strong&gt;interior&lt;/strong&gt; of $A$ is the union of all open subsets of $A$. We write $\mathring A$ to denote the interior of $A$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Clearly the interior of a set is always open because it is the union of open sets. We can think of the interior of a set as the largest open set contained in that set. Clearly every point in $\mathring A$ has a neighborhood contained in $A$. We call each such point an &lt;strong&gt;interior point&lt;/strong&gt; of $A$.&lt;/p&gt;
&lt;p&gt;Now that we have defined the interior and closure of any set $A$, we have a sort of set sandwich $\mathring A\subseteq A\subseteq\overline A$. Here, $\mathring A$ contains none of its boundary points, $\overline A$ contains them all, and $A$ can contain some, all or none.&lt;/p&gt;
&lt;p&gt;Let's finish up with the proof I promised you a minute ago.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; If $A$ is a subset of a topological space $X$, then $\mathring A=\overline A-\partial A$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Choose $x\in\mathring A$. Clearly $x\in\overline A$ because $\mathring A\subseteq\overline A$. Since $x$ is an interior point of $A$, there exists some neighborhood of $x$ which is contained in $A$. Thus $x$ is not a boundary point of $A$ and so $x\in\overline A-\partial A$.&lt;/p&gt;
&lt;p&gt;Next, choose $x\in\overline A-\partial A$. Then $x\in A$ or $x$ is a limit point of $A$, but $x$ is not a boundary point of $A$. Thus any neighborhood of $x$ contains a point in $A$ but no points in $X-A$, so $x\in\mathring A$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I'm probably boring you. I'm boring myself, actually, because I don't find any of this particularly interest. It's kind of necessary though, so I'm glad I went through it. I'm going to end the post here, and next time I'll finally talk about continuity, which is actually interesting and incredibly important.&lt;/p&gt;
</content:encoded></item><item><title>Groups and their Basic Properties</title><description>Essentially, a group is a set endowed with a very basic structure. This structure is enforced by an operation which governs how the elements in the group interact with each other.</description><link>http://localhost:2368/groups-and-their-basic-properties/</link><guid isPermaLink="false">5c6c6452a4e2f60287eae21b</guid><dc:creator>Eric Shapiro</dc:creator><pubDate>Fri, 07 Apr 2017 23:05:25 GMT</pubDate><content:encoded>&lt;h3 id="contents"&gt;Contents&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#the-definition"&gt;The Definition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#examples"&gt;Examples&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#basic-properties"&gt;Basic Properties&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#subgroups"&gt;Subgroups&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="introductionanameintroduction"&gt;Introduction&lt;a name="introduction"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I think it's probably time I wrote a post about something other than topology, so today I'm going to break way into the field of algebra.&lt;sup class="footnote-ref"&gt;&lt;a href="#fn1" id="fnref1"&gt;[1]&lt;/a&gt;&lt;/sup&gt; It's difficult to explain exactly what algebra is until you've been exposed to some of it, but I like to think of algebra as the study of structure. Using algebraic techniques, seemingly different objects can be shown to be not so different after all, and many difficult problems can be solved relatively easy using such observations.&lt;/p&gt;
&lt;p&gt;The first algebraic object I'd like to introduce, as you may have guessed, is a group. This will not be my only post on groups, since there is a lot to say about them. Essentially, a group is a set endowed with a very basic structure. This structure is enforced by an operation which governs how the elements in the group interact with each other. Before I define a group, I need to talk a little bit about binary operations.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; A &lt;strong&gt;binary operation&lt;/strong&gt; $\circ$ on a set $X$ is a function $\circ:X\times X\to X$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The definition nicely captures several important ideas. First, it guarantees that if $a,b\in X$ then $\circ(a,b)\in X$ as well. This is called &lt;strong&gt;closure&lt;/strong&gt; under the binary operation — when we combine two elements in $X$, we always get back something which is also in $X$. Next, because we have defined $\circ$ as a function, it is guaranteed that every pair of elements in $X$ can be combined to yield a new element.&lt;/p&gt;
&lt;p&gt;You're probably more used to &lt;strong&gt;infix notation&lt;/strong&gt; $a\circ b$, rather than the equivalent function notation $\circ(a,b)$, when it comes to denoting binary operations. That's good, since infix notation is more convenient and we will use it more often.&lt;/p&gt;
&lt;p&gt;As an example, the usual operations of addition and multiplication on $\mathbb{N},\mathbb{Z},\mathbb{Q},\mathbb{R}$ and $\mathbb{C}$ are binary operations on each of these sets. Let $X$ denote any of the aforementioned sets. That addition and multiplication on $X$ actually constitute binary operations is shown easily by noting that for any two elements $a,b\in X$, their sum $a+b$ and their product $a\cdot b$ are well defined and are also in $X$.&lt;/p&gt;
&lt;h3 id="thedefinitionanamethedefinition"&gt;The Definition&lt;a name="the-definition"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I'll jump straight into it, shall I?&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; A &lt;strong&gt;group&lt;/strong&gt; is a set $G$ together with a binary operation $\circ:G\times G\to G$ with the following properties:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Associativity.&lt;/strong&gt; For any $a,b,c\in G$, we have that $(a\circ b)\circ c=a\circ (b\circ c)$.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Identity.&lt;/strong&gt; There exists $e\in G$ such that $e\circ x=x\circ e=x$.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Inverses.&lt;/strong&gt; For every $x\in G$ there exists $y\in G$ such that $x\circ y=e$.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;Stated in plain English, groups must have an identity element and inverses for every element, and the group operation must be associative. These all seem like reasonable requirements.&lt;/p&gt;
&lt;p&gt;In the future, we will occasionally be even more lax and denote $a\circ b$ as simply $ab$, when a group's binary operation is implicitly understood and no confusion can arise. When an element is 'multiplied' by itself numerous times, we will use exponential notation. For instance, $aa=a^2$ and $aaa=a^3$. It is consistent and convenient in this notation to denote the identity element $e=a^0$ for any element $a$ in a group.&lt;/p&gt;
&lt;p&gt;Furthermore, I will frequently refer to $G$ itself as a group, as this very rarely results in any confusion. Just remember that whenever I mention a group, there is always some binary operation lurking behind the curtain.&lt;/p&gt;
&lt;h3 id="examplesanameexamples"&gt;Examples&lt;a name="examples"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Now that groups have been defined, I'd like to walk you through a few simple examples of groups.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; The &lt;strong&gt;trivial group&lt;/strong&gt; is the group containing only one element.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Technically there are infinitely many 'trivial groups' since that one element could be anything, but all trivial groups are really the same. Let's call the element $e$. To see that the trivial group is in fact a group, first note that $e$ must be the group's identity element. Thus, $(ee)e=ee=e(ee)$ and so we have associativity. Furthermore, since $ee=ee=e$, clearly $e$ is its own inverse.&lt;/p&gt;
&lt;p&gt;The set of integers under addition also forms a group. Associativity is a property of addition itself, and you probably use it every day without even thinking about it. The identity element is zero, since $x+0=0+x=x$ for any $x\in\mathbb{Z}$. Lastly, the inverse of any integer $x$ is $-x$, since $x+(-x)=0$.&lt;/p&gt;
&lt;p&gt;Similarly, the set $\mathbb{R}^+$ of positive real numbers under multiplication forms a group. Again, associativity is obvious.&lt;sup class="footnote-ref"&gt;&lt;a href="#fn2" id="fnref2"&gt;[2]&lt;/a&gt;&lt;/sup&gt; The identity element is $1$ since $1\cdot x=x\cdot 1=x$ for any $x\in\mathbb{R}^+$. Lastly, the inverse of any $x\in\mathbb{R}^+$ is $\frac{1}{x}$. Notice that the set of all real numbers does not form a group under multiplication because zero has no multiplicative inverse!&lt;/p&gt;
&lt;p&gt;The last example I'd like to talk about is considerably more abstract, and probably not something you would ever have considered might be a group. It is called the &lt;strong&gt;dihedral group&lt;/strong&gt; (or &lt;strong&gt;group of symmetries&lt;/strong&gt;) of a regular polygon. We write $D_n$ to denote the dihedral group of the $n$-sided regular polygon. How is $D_n$ defined? I'm not quite ready to do it rigorously, since we haven't talked about permutations yet, but I'll explain it intuitively.&lt;/p&gt;
&lt;p&gt;Basically, $D_n$ is the set of all rotations and reflections which preserve the locations of the vertices. The group operation is composition of these rotations and reflections, which essentially amounts to performing them one after the other. For instance, consider the equilateral triangle (the $3$-sided regular polygon)&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/equilateral-triangle-1.svg" alt="equilateral triangle"&gt;&lt;/p&gt;
&lt;p&gt;where I've numbered the vertices to avoid the tremendous confusion that would otherwise ensue. Here's one of the vertex location preserving rotations we can perform, $r_1$:&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/r_1.svg" alt="r_1"&gt;&lt;/p&gt;
&lt;p&gt;Here's another one, $r_2$:&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/r_2-1.svg" alt="r_2"&gt;&lt;/p&gt;
&lt;p&gt;It's not too difficult to see that $r_2$ is really just $r_1$ applied twice! That is, $r_2=r_1\circ r_1$. Remember that this is the notation of function composition, so the first rotation applied is written on the right.&lt;/p&gt;
&lt;p&gt;Now that we have a better grasp of what's going on, let's think about the identity element of $D_3$. It should hopefully make sense that the identity element is the rotation by zero degrees. That is, the identity element is the act of doing nothing to the triangle. Call this element $e$. It should be clear that $e\circ r_1=r_1\circ e=r_1$ and likewise for $r_2$, so things are looking good so far.&lt;/p&gt;
&lt;p&gt;What are the inverses of $r_1$ and $r_2$? We just need to figure out how to get the vertices back to their original positions. It looks like $r_1\circ r_2=r_2\circ r_1=e$, so $r_1$ and $r_2$ are actually inverses!&lt;/p&gt;
&lt;p&gt;We've exhausted all the rotations, so now we need to look at the reflections. There are three of them, and each preserves the location of one vertex while swapping the other two. Let's call them $f_1, f_2$ and $f_3$, where the subscript denotes the vertex preserved under each. For instance, here's $f_1$:&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/f_1.svg" alt="f_1"&gt;&lt;/p&gt;
&lt;p&gt;What is the inverse of each reflection? If you reflect something twice along the same axis, it goes back to its original position. That is, $f_1, f_2$ and $f_3$ are each their own inverse.&lt;/p&gt;
&lt;p&gt;It's important to remember that the elements of the group are these reflections and rotations, rather than the triangles they act upon. I'll make all this more precise later when I talk about permutations, but for now I think this visual explanation should suffice.&lt;/p&gt;
&lt;p&gt;Next, $D_4$ is the dihedral group of the square, with four distinct rotations (where I have counted the identity among the rotations) and four reflections.&lt;/p&gt;
&lt;p&gt;Likewise, $D_5$ is the dihedral group of the regular pentagon, with five rotations and five reflections. In general, $D_n$ consists of $n$ rotations and $n$ reflections, totaling $2n$ elements.&lt;/p&gt;
&lt;p&gt;I'll talk about dihedral groups again in the future, but for now let me conclude by noting that the rotations in $D_n$ form a group of their own, since they cannot be composed in such a way as to produce anything other than a rotation. The reflections are a different story, though. They do not form a group since, for example, in $D_3$ we have that $f_2\circ f_1=r_2$. That is, the composition of two reflections can be a rotation.&lt;/p&gt;
&lt;h3 id="basicpropertiesanamebasicproperties"&gt;Basic Properties&lt;a name="basic-properties"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Now that I've gotten a few examples of groups out of the way, I'd like to talk about some immediate consequences of the group axioms. Let's begin by showing that we are allowed to cancel terms from equations, as we are so used to doing in the familiar number systems.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Left Cancellation Law.&lt;/strong&gt; Let $G$ denote a group with $a,b,x\in G$. If $xa=xb$, then $a=b$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Since $x\in G$, there must exist an inverse $y\in G$ for $x$ and an identity element $e\in G$ such that $yx=e$. Thus,&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
a &amp;amp;= e a &amp;amp; \scriptstyle\textit{identity}\\&lt;br&gt;
&amp;amp;=(y x) a &amp;amp; \scriptstyle\textit{inverses}\\&lt;br&gt;
&amp;amp;=y(x a) &amp;amp; \scriptstyle\textit{associativity}\\&lt;br&gt;
&amp;amp;=y(x b) &amp;amp;\scriptstyle{x a=x b}\\&lt;br&gt;
&amp;amp;=(y x) b &amp;amp;\scriptstyle\textit{associativity}\\&lt;br&gt;
&amp;amp;=e b &amp;amp;\scriptstyle\textit{inverses}\\&lt;br&gt;
&amp;amp;=b. &amp;amp;\scriptstyle{\textit{identity}}&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;This completes the proof.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I have included my reasoning for each step to the right, because such proofs can be difficult to parse when you first encounter them. Do not expect me to continue being this nice in the future. The &lt;strong&gt;right cancellation law&lt;/strong&gt; and its proof are completely symmetric, so I will not even bother to state them. Now that these cancellation laws have been established, we will be using them frequently. For instance, let's use one to prove the following proposition about inverses.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; Each element in a group has a unique inverse.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Let $G$ denote a group with $x\in G$ and suppose that $y_1, y_2\in G$ are both inverses for $x$. Then $y_1x=y_2x=e$ by the definition of inverses, so by the right cancellation law it follows that $y_1=y_2$, completing the proof.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;How does this proof establish that each element's inverse is unique? We are guaranteed the existence of at least one inverse by the group axioms. Furthermore, we just demonstrated that if an element has two inverses, then they must really be the same element!&lt;/p&gt;
&lt;p&gt;Next, let's prove a similar statement that there is only one identity element in any group. This is probably the simplest proof ever, but it's rather informative.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; The identity element in a group is unique.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Let $G$ denote a group and suppose that $e_1, e_2\in G$ are both identity elements. Then $e_1=e_1e_2=e_2$ by the definition of the identity, completing the proof.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I've already been saying 'the inverse' of an element and 'the identity' a lot prior to this, but now I'm actually justified in doing so. Furthermore, since each element $x$ only has one inverse, we can denote it unambiguously as $x^{-1}$. This plays well with the exponential notation I introduced earlier, i.e. $(x^{-1})^n=x^{-n}$ and $x^mx^{-m}=e$.&lt;/p&gt;
&lt;p&gt;Before moving on I'd like to mention a very nice property that certain groups may exhibit, but they do not necessarily have to.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; A group $G$ is &lt;strong&gt;abelian&lt;/strong&gt; (or &lt;strong&gt;commutative&lt;/strong&gt;) if $xy=yx$ for every $x,y\in G$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Examples of abelian groups that we've already seen are the integers under addition and the positive real numbers under multiplication. On the other hand, the dihedral groups of order three and above are nonabelian.&lt;/p&gt;
&lt;h3 id="subgroupsanamesubgroups"&gt;Subgroups&lt;a name="subgroups"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I'm almost done now, and I know this has been a pretty long post. I just need to introduce one more important concept and then I promise I'll stop.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; A &lt;strong&gt;subgroup&lt;/strong&gt; $H$ of a group $G$ is a subset of $G$ which is itself a group under the group operation on $G$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;If $H$ is a subgroup of $G$, I will sometimes write $H\leq G$. This cannot really be confused with the &amp;quot;less than or equal to&amp;quot; relation because groups are not numbers and thus have no such concept.&lt;/p&gt;
&lt;p&gt;As an example, the even integers (denoted $2\mathbb{Z}$) are a subgroup of $\mathbb{Z}$ under addition. This is because the sum of two even integers is always even. However, the odd integers do not form a subgroup of $\mathbb{Z}$ under addition because the sum of two odd integers is not odd.&lt;sup class="footnote-ref"&gt;&lt;a href="#fn3" id="fnref3"&gt;[3]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;I pointed out earlier that the rotations in $D_3$ themselves formed a group under function composition, and this means that they are a subgroup of $D_3$.&lt;/p&gt;
&lt;p&gt;In general, a group does not necessarily have any subgroups other than itself and the trivial group. We shall see later that if a subgroup (of a finite group) is to exist, it must contain a very predictable number of elements.&lt;/p&gt;
&lt;hr class="footnotes-sep"&gt;
&lt;section class="footnotes"&gt;
&lt;ol class="footnotes-list"&gt;
&lt;li id="fn1" class="footnote-item"&gt;&lt;p&gt;Although my true motivation is perhaps more sinister than you could possibly imagine. 😈 &lt;a href="#fnref1" class="footnote-backref"&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn2" class="footnote-item"&gt;&lt;p&gt;It's really not. When I inevitably define the real numbers from scratch as equivalence classes of Cauchy sequences of rational numbers in a future post, showing associativity will actually be something of a chore. As will everything else. &lt;a href="#fnref2" class="footnote-backref"&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn3" class="footnote-item"&gt;&lt;p&gt;The odd integers form what is called a coset, $2\mathbb{Z}+1$ of the subgroup $2\mathbb{Z}$, but I will talk about this in a later post. &lt;a href="#fnref3" class="footnote-backref"&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</content:encoded></item><item><title>Bases for Topologies</title><description>Essentially, a basis is a 'small' collection of open sets from which every open set can be easily generated. It is often useful to talk about the topology generated by a specific basis, since many facts about a topology can be gleaned by studying one of its bases.</description><link>http://localhost:2368/bases-for-topologies/</link><guid isPermaLink="false">5c6c6452a4e2f60287eae21a</guid><dc:creator>Eric Shapiro</dc:creator><pubDate>Mon, 03 Apr 2017 04:07:41 GMT</pubDate><content:encoded>&lt;h3 id="contents"&gt;Contents&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#recap"&gt;Recap&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#bases"&gt;Bases&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="recapanamerecap"&gt;Recap&lt;a name="recap"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;It occurred to me after I finished my last post on topological spaces that there is actually quite a lot I can already tell you about them. First I'm going to show a sort of stronger correspondence between the ideas of open sets in metric and topological spaces. Then I'm going to talk about bases for topologies. I believe I've mentioned these before, but now I'm finally ready to define them.&lt;/p&gt;
&lt;p&gt;Recall that in a metric space, a set $U$ is open if every point $x\in U$ is at the center of some open ball which is itself a subset of $U$.&lt;/p&gt;
&lt;p&gt;Recall also that in a topological space, the open sets are required to include the empty set and the space itself, the union of any number of open sets, and the intersection of any finite number of open sets.&lt;/p&gt;
&lt;p&gt;Let's see if we can get the definition of open sets in topological spaces to look a little bit more like the definition in metric spaces. First, we'll need the following lemma. It's a bit obvious, but useful enough to have a name.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Union Lemma.&lt;/strong&gt; Suppose $X$ is a set and $\cal T$ is a collection of subsets of $X$. If every $x\in X$ is contained in some set $U_x\in\cal T$ then $X=\bigcup\limits_{x\in X}U_x$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; To show that these two sets are equal, it suffices to show that each is a subset of the other.&lt;/p&gt;
&lt;p&gt;Since every set $U_x$ is a subset of $X$, it must be that their union, $\bigcup\limits_{x\in X}U_x$ is a subset of $X$.&lt;/p&gt;
&lt;p&gt;Next, suppose $y\in X$. Then by hypothesis there exists $U_y\in\cal T$ for which $y\in U_y$. Thus, $y\in U_y\subseteq\bigcup\limits_{x\in X}U_x$. It follows that $X$ is a subset of $\bigcup\limits_{x\in X}U_x$, completing the proof.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Just from the letters I chose to represent the sets in the statement of this lemma, it should be somewhat obvious where I'm going with this. Think of $X$ as a topological space, $\cal T$ as a topology on $X$, and each $U_x\in\cal T$ as a neighborhood of each point $x\in X$. (Recall that a neighborhood of a point is any open set containing that point, and that I've likened them to open balls in the past.)&lt;/p&gt;
&lt;p&gt;Now let's do what I promised earlier&lt;sup class="footnote-ref"&gt;&lt;a href="#fn1" id="fnref1"&gt;[1]&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; A subset $V$ of a topological space $X$ is open if and only if every point $x\in V$ has a neighborhood $U_x$ such that $U_x\subseteq V$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Suppose first that $V$ is open. Then the set $V$ itself is a neighborhood of every $x\in V$, so choosing each $U_x=V$ will suffice.&lt;/p&gt;
&lt;p&gt;Suppose next that every point $x\in V$ has a neighborhood $U_x$ such that $U_x\subseteq V$. Then by the union lemma, $v=\bigcup\limits_{x\in V}U_x$, which is open because it is the union of open sets.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;That looks a lot like the definition of openness in a metric space, doesn't it? This analogous definition of open sets in topological spaces says that a set $V$ is open if every point in the set is contained in an open set which is itself a subset of $V$.&lt;/p&gt;
&lt;p&gt;Since metric spaces &lt;em&gt;are&lt;/em&gt; topological spaces (when equipped with the proper topology, of course (the one that's induced by the metric (I wonder how many nested parenthetical statements I can get away with?))) we can use this new concept of openness in metric spaces too! That means we are no longer restricted to open balls centered at a point.&lt;/p&gt;
&lt;h3 id="basesanamebases"&gt;Bases&lt;a name="bases"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Now I'm going to talk about the idea of a basis for a topological space. Essentially, a basis is a 'small' collection of open sets from which every open set can be easily generated. It is often useful to talk about the topology generated by a specific basis, since many facts about a topology can be gleaned by studying one of its bases.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; A &lt;strong&gt;basis&lt;/strong&gt; $\cal B$ for a topology on a set $X$ is a collection of open sets (called &lt;strong&gt;basis elements&lt;/strong&gt; with the following two properties:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Every point in $X$ is contained in some basis element $B\in\cal B$.&lt;/li&gt;
&lt;li&gt;If two basis elements $B_1, B_2\in\cal B$ are not disjoint, then for each $x\in B_1\cap B_2$ there is another basis element $B_x\subseteq B_1\cap B_2$ for which $x\in B_x$.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;The first condition is self-evident. The second condition just means that if two basis elements intersect, then for every point in their intersection there is another basis element containing that point which is itself contained in their intersection.&lt;/p&gt;
&lt;p&gt;It isn't too hard to see how such a collection generates a topology:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; The &lt;strong&gt;topology generated by the basis&lt;/strong&gt; $\cal B$ is defined as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The empty set is, of course, open.&lt;/li&gt;
&lt;li&gt;The union of any collection of sets in $\cal B$ is open.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;We need to verify that the topology generated by a basis is, in fact, a topology. Otherwise we'd be in a world of trouble, and we'd have some nerve calling it that. To do so, we're going to need another lemma:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Basis Intersection Lemma.&lt;/strong&gt; Let $\cal B$ be a basis for a topology on $X$, let $B_1, B_2, \dotsc, B_n\in\cal B$ and suppose that $x\in\bigcap\limits_{i=1}^n B_i$. Then there also exists $B_x\in\cal B$ such that $x\in B_x\subseteq\bigcap\limits_{i=1}^n B_i$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; We proceed by induction on $n$. The base case, $n=2$, holds by the definition of a basis.&lt;/p&gt;
&lt;p&gt;Suppose then that the lemma holds for $n-1$, where $n&amp;gt;2$. That is, if $B_1, B_2, \dotsc, B_n\in\cal B$ then there exists $B_x\in\cal B$ such that $x\in B_x\subseteq\bigcap\limits_{i=1}^{n-1}B_i$. Suppose that $x\in\bigcap\limits_{i=1}^n=\bigcap\limits_{i=1}^{n-1}\cap B_n$. Then $x\in B_x$ and $x\in B_n$, so from the definition of a basis it it follows that there exists $B'_x\in\cal B$ for which $x\in B'_x\subseteq\bigcap\limits_{i=1}^n$, as desired. This completes the proof.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;We now have all the tools we need to prove that a basis actually generates a topology!&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; Given a set $X$, the topology generated by a basis $\cal B$ is a topology on $X$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; First notice that the empty set is open by definition, and the set $X$ is open by the union lemma since every point in $X$ is required to be in some basis element.&lt;/p&gt;
&lt;p&gt;Next, let $I$ be an indexing set such that $A_i\subseteq X$ is open for each $i\in I$. Define $U=\bigcup\limits_{i\in I}A_i$. Each set $A_i$ is either empty or the union of some collection of basis elements, so it is open. Thus, $U$ is open since it is the union of open sets.&lt;/p&gt;
&lt;p&gt;Finally, let $A_1, A_2, \dotsc, A_n$ be open sets for some $n\in\mathbb{N}$ and define $I=\bigcap\limits_{i=1}^n A_i$. If any $A_i$ is empty then so is $I$, and thus it is open. Suppose then that $I$ is nonempty, and let $x\in I$ so that $x\in A_i$ for each $i$. Since each $A_i$ is the union of basis elements, there exists $B_i\in\cal B$ such that $x\in B_i\subseteq A_i$ for each $i$. Thus, $x\in\bigcap\limits_{i=1}^n B_i$, so by the basis intersection lemma there exists $B_x\in\cal B$ such that $x\in B_x\subseteq\bigcap\limits_{i=1}^n B_i\subseteq V$. By the union lemma, $V=\bigcup\limits_{x\in I} B_x$. This is open since it is the union of basis elements, completing the proof.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Woah. That proof was long and boring. What was even the point of all that again? Well, now we can be verify that a collection of subsets is a basis for a topology and immediately talk about the topology it generates without having to prove that it really is a topology each and every time. Looking at a space in terms of a basis for that space can also simplify our talk of open sets quite a bit, as in the following theorem.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; Let $X$ denote a topological space generated by a basis $\cal B$. A set $U\subseteq X$ is open if and only if for each $x\in U$ there is some basis element $B_x\in\cal B$ for which $x\in B_x\subseteq U$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Suppose first that $U\subseteq X$ is open. Then $U$ is the union of some collection of basis elements, so for each $x\in U$ there exists at least one $B_x\in\cal B$ for which $x\in B_x\subseteq U$.&lt;/p&gt;
&lt;p&gt;Suppose next that for each $x\in U$ there is some $B_x\in\cal B$ for which $x\in B_x\subseteq U$. Then by the union lemma we have that $U=\bigcup\limits_{x\in U} B_x$, which is open since it is the union of basis elements.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is the ultimate relationship between open sets in metric and topological spaces. In fact, if we take open balls in the metric as the basis elements of a topology, we have precisely the same definition for each. Let's actually make sure that the open balls in a metric space form a basis.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; In a metric space $X$ with metric $d:X\times X\to\mathbb{R}$, the set of open balls $\{B(x,r)\subseteq X\mid x\in X,r&amp;gt;0\}$ is a basis for a topology on $X$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; The first condition for a basis is clearly satisfied, since for any $x\in X$ we have that $x\in B(x,r)$ for any $r&amp;gt;0$. For the next part, here's a diagram to help you visualize my argument, because I know how much you love my diagrams:&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/basis-intersection-balls-1.svg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;I've practically already proved that second condition already in my first post on metric spaces. Suppose that $a,b\in X$ and $B(a,r_a)\cap B(b,r_b)\neq\varnothing$ for some real numbers $r_a, r_b &amp;gt;0$. If $x\in B(a,r_a)\cap B(b,r_b)$ then $x\in B(a,r_a)$ and $x\in B(b,r_b)$ by the definition of set intersection. We already know that there exist real numbers $r_1, r_2&amp;gt;0$ for which $B(x,r_1)\subseteq B(a,r_a)$ and $B(x,r_2)\subseteq B(b,r_b)$ Simply choosing the smaller of these open balls, $B(x,r)$ with $r=\min\{r_1,r_2\}$, yields a basis element containing $x$ which is contained entirely in the intersection.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It's important to realize that this is a proof that the open balls in &lt;em&gt;any&lt;/em&gt; metric space are the basis for a topology on that space. We call this topology the &lt;strong&gt;topology induced by a metric&lt;/strong&gt;. It is clear that this topology on $\mathbb{R}^n$ is the standard topology, and any open set in $\mathbb{R}^n$ is thus the union of some collection of open balls. I talked about this a few posts ago, but now I'm actually justified in claiming it.&lt;/p&gt;
&lt;p&gt;Can you show that in $\mathbb{R}^2$, the set of open rectangles of the form&lt;/p&gt;
&lt;p&gt;$$\{(x,y)\in\mathbb{R}^2\mid x\in (a,b), y\in (c,d)\},$$&lt;/p&gt;
&lt;p&gt;where $a,b,c,d\in\mathbb{R}$, is the basis for a topology on $\mathbb{R}^2$? It's really not terribly difficult, and drawing a picture of the situation is practically a proof in itself. It can be shown that this basis also generates the standard topology on $\mathbb{R}^2$, although this is a bit more work.&lt;/p&gt;
&lt;p&gt;In closing, several metrics can induce the same topology on a space. However, not every topology is induced by some metric! We say that a topology on $X$ is &lt;strong&gt;metrizable&lt;/strong&gt; if there exists a metric on $X$ which induces that topology. I may talk about this in the future, but I don't personally find this topic too interesting.&lt;/p&gt;
&lt;p&gt;In my next post, I'm going to do what I promised to do in my last post. That is, I'll introduce some more important definitions in metric spaces, and hopefully it won't be as long and boring as this post was.&lt;/p&gt;
&lt;hr class="footnotes-sep"&gt;
&lt;section class="footnotes"&gt;
&lt;ol class="footnotes-list"&gt;
&lt;li id="fn1" class="footnote-item"&gt;&lt;p&gt;I don't believe I've done an 'if and only if' type proof on here before. The basic idea is that '$A$ if and only if $B$' is the same as saying '$A$ implies $B$' and '$B$ implies $A$. That is, all we have to do in order to prove such a statement is show that each half implies the other half. &lt;a href="#fnref1" class="footnote-backref"&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</content:encoded></item><item><title>Mathematical Induction</title><description>Before my next post on bases for topologies, I need to introduce a proof technique that I haven't used so far.</description><link>http://localhost:2368/mathematical-induction/</link><guid isPermaLink="false">5c6c6452a4e2f60287eae219</guid><dc:creator>Eric Shapiro</dc:creator><pubDate>Sun, 02 Apr 2017 22:53:45 GMT</pubDate><content:encoded>&lt;h3 id="contents"&gt;Contents&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#the-axiom-of-choice-and-well-ordering-principle"&gt;The axiom of choice and well-ordering principle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#the-principle-of-mathematical-induction"&gt;The principle of mathematical induction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#examples"&gt;Examples&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;This post is a much needed break from my steady stream of posts concerning topology. Before my next post on bases for topologies, I need to introduce a proof technique that I haven't used so far.&lt;/p&gt;
&lt;p&gt;In mathematics, we come across patterns all the time. For instance, here's a pattern you may have noticed before:&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
1       = 1\phantom{0}  &amp;amp;= 1^2 \\&lt;br&gt;
1+3     = 4\phantom{0}  &amp;amp;= 2^2 \\&lt;br&gt;
1+3+5   = 9\phantom{0}  &amp;amp;= 3^2 \\&lt;br&gt;
1+3+5+7 = 16 &amp;amp;= 4^2 \\&lt;br&gt;
&amp;amp;\phantom{0}\vdots \\&lt;br&gt;
1+3+5+7+\dotsc +(2n+1) &amp;amp;= n^2&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;It turns out that for any natural number $n$, if you add the first $n$ odd numbers the result is always $n^2$. (Remember that the $n$th odd number is $2n-1$.) Here's a visual depiction of the pattern:&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/sum_of_odds-2.svg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;From this image, it is evident that adding together the first $n$ odd numbers literally results in a square of side length $n$. But how can we come up with a convincing argument that this pattern always holds? In answering this question, we will discuss a method that can also be applied to many other similar problems.&lt;/p&gt;
&lt;h3 id="theaxiomofchoiceandwellorderingprincipleanametheaxiomofchoiceandwellorderingprinciple"&gt;The axiom of choice and well-ordering principle&lt;a name="the-axiom-of-choice-and-well-ordering-principle"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Before we start, I should mention that you cannot do a proof by induction unless you accept the &lt;strong&gt;axiom of choice&lt;/strong&gt;. The axiom of choice is an extra axiom of set theory which is somewhat controversial (among mathematicians). This is because at first glance it seems obviously true, but it actually leads to some bizarre and unexpected results.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Axiom of Choice.&lt;/strong&gt; Suppose $I$ is an indexing set and $C$ is a collection of nonempty sets $X_i$ for each $i\in I$. Then there exists a function $f:C\to\bigcup\limits_{i\in I} X_i$ such that $f(X_i)\in X_i$ for every $i$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In simpler words, the axiom of choice ensures that, given any number of nonempty sets, it is possible to choose precisely one element from each set. This is probably something you never would have dreamt was controversial, and it certainly seems like a natural assumption, but as I said before it allows for some strange results.&lt;/p&gt;
&lt;p&gt;For instance, it leads to the &lt;strong&gt;Banach-Tarski Paradox&lt;/strong&gt;, that is, the fact that given a solid ball in three dimensions ($\mathbb{R}^3$), it is possible to break the ball up into a finite number of disjoint pieces and rearrange these pieces using rigid transformations into two solid balls which are each identical to the original. This is perhaps at least slightly suspicious.&lt;/p&gt;
&lt;p&gt;I'm always going to assume the axiom of choice, mostly because I like it and it makes a lot of proofs considerably easier. Sometimes it is the only thing that makes proofs possible at all, like the proof of the principle of mathematical induction. Which I promise I'm getting to.&lt;/p&gt;
&lt;p&gt;For this proof, we're going to need the axiom of choice in a slightly different form. This form is actually so commonly referred to that it even has a special name. The axiom of choice is equivalent to the statement that any set can be well-ordered. I'm not going to go into orderings right now, but I will state what this means for the natural numbers because we'll need to use it in our proof.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Well-Ordering Principle.&lt;/strong&gt; Any nonempty set of natural numbers contains a least element.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This assumes the ordering you're familiar with for the natural numbers. You know, the one where $0&amp;lt;1&amp;lt;2&amp;lt;3$ and so on. This only holds because the natural numbers are bounded below. That is, there is a smallest natural number: $0$. If we wanted to extend this principle to the integers, we'd have to add the condition that our nonempty set of integers has a lower bound.&lt;/p&gt;
&lt;p&gt;The well-ordering principle should hopefully seem very obvious to you as well, and I'm not going to show how it implies the principle of mathematical induction.&lt;/p&gt;
&lt;h3 id="theprincipleofmathematicalinductionanametheprincipleofmathematicalinduction"&gt;The principle of mathematical induction&lt;a name="the-principle-of-mathematical-induction"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I'll stop beating around the bush and just do the thing already.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Principle of Mathematical Induction.&lt;/strong&gt; Suppose P(n) is a (true/false) statement about a natural number $n$, and that the following two criteria hold:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Base Case:&lt;/strong&gt; $P(0)$ is true.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Inductive Step:&lt;/strong&gt; If $P(n)$ is true for some $n\in\mathbb{N}$ then so is $P(n+1)$.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Then $P(n)$ is true for every $n\in\mathbb{N}$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; We give a proof by contradiction. That is, we're going to assume that the statement is false and show that this leads to an absurd result. We will then be forced to accept the principle of mathematical induction because we will have shown that it cannot be false.&lt;/p&gt;
&lt;p&gt;Suppose then that both criteria hold, but that $P$ is not true for at least one natural number. Let $S$ denote the set of natural numbers for which $P$ is false. By assumption, $S$ is not empty, so the well-ordering theorem tells us that $S$ contains a least element. Call this element $x$. Then $x-1\notin S$ since $x$ is the smallest element of $S$. That is, $P(x)$ is false but $P(x-1)$ is true. However, the second criterion tells us that $P\big((x-1)+1\big)=P(x)$ must be true. This is a contradiction, since $P(x)$ cannot be simultaneously true and false. It follows that $P(n)$ is true for every natural number $n$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The proof is not terribly important, so don't spend too much time dissecting it. What really matters to us is the statement itself, which might seem daunting at first, so let's break it down piece by piece.&lt;/p&gt;
&lt;p&gt;We start off with a statement which is either true or false depending on what number we feed it. The following are examples of such statements&lt;sup class="footnote-ref"&gt;&lt;a href="#fn1" id="fnref1"&gt;[1]&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$P(n):=n$ is a prime number.&lt;/li&gt;
&lt;li&gt;$Q(n):=n$ sandwiches are on fire.&lt;/li&gt;
&lt;li&gt;$R(n):=1+3+5+\dotsc+(2n-1)=n^2$.&lt;/li&gt;
&lt;li&gt;$S(n):=$ the $n$th domino will fall over.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If we want to show that such a statement is true for all natural numbers, we must first verify the base case, which means showing that if we set $n=1$ then the resulting statement is true. This is usually the easy part of a proof by induction, but it is still necessary.&lt;/p&gt;
&lt;p&gt;The last thing we have to do is show that if the statement holds for an arbitrary natural number $n$, then the statement also holds for $n+1$. This is the inductive step, which is usually where the most work and insight are needed.&lt;/p&gt;
&lt;p&gt;If we can do these two things, then we have shown that the statement is true for every natural number! Just remember: base case, then inductive step. Now let's look more closely at the example statements from above:&lt;/p&gt;
&lt;p&gt;By definition, $P(n)$ is true only when $n$ is prime. For instance, $P(1)$ is false because $1$ is not prime, but $P(2)$ is true because $2$ is prime.&lt;/p&gt;
&lt;p&gt;On the other hand, $Q(n)$ is presumably false for all $n&amp;gt;0$. I, for one, have never seen an exploding sandwich.&lt;/p&gt;
&lt;p&gt;$R(n)$ is the same statement we discussed earlier: that the sum of the first $n$ odd numbers is $n^2$. We will come back to this in a few moments and show it to be true for any $n$ using an inductive argument.&lt;/p&gt;
&lt;p&gt;For now, let's focus on $S(n)$ because it is a helpful and illustrative example of why induction works. Suppose we have a line of dominoes extending infinitely to the right, all standing up and close enough together that if one falls over it will hit the next domino in line:&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/dominoes-1.svg" alt="line of dominoes"&gt;&lt;/p&gt;
&lt;p&gt;What are the base case and inductive step for this example? The base case would be $S(1)$, which corresponds to whether or not the first domino will be knocked over. The inductive step is the fact that, if the $n$th domino falls, then the $(n+1)$th domino will also fall. The inductive step is clearly true because each domino knocks over the next one when it falls. However, if the first domino is never knocked over, none of the other ones will be either. This illustrates the importance of the base case! If the base case does not hold, then a proof by induction is invalid even if the inductive step does hold.&lt;/p&gt;
&lt;p&gt;So in other words, if we know for certain that the first domino will fall, this means that &lt;em&gt;every&lt;/em&gt; domino will fall because we have verified both the base case and the inductive step.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/dominoes_falling.svg" alt="dominoes falling"&gt;&lt;/p&gt;
&lt;p&gt;The argument we have just given shows an infinite number of things to be true! This is part of the power of inductive arguments.&lt;/p&gt;
&lt;h3 id="examplesanameexamples"&gt;Examples&lt;a name="examples"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Let's now prove that the pattern I introduced at beginning of this post always holds.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; For any $n\geq 1$,&lt;/p&gt;
&lt;p&gt;$$1+3+5+\dotsc+(2n-1)=n^2.$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; We give a proof by induction on $n$.&lt;/p&gt;
&lt;p&gt;For our base case, we need to show that the statement is true when we let $n=1$. This is simple enough, because $1$ is certainly the sum of the first $1$ odd numbers, and it is equal to its square. That is, $1=1^2$, so we have shown that our base case is true.&lt;/p&gt;
&lt;p&gt;Now for the inductive step. We will assume that&lt;/p&gt;
&lt;p&gt;$$1+3+5+\dotsc+(2n-1)=n^2,$$&lt;/p&gt;
&lt;p&gt;and use this to show that&lt;/p&gt;
&lt;p&gt;$$1+3+5+\dotsc+(2n-1)+(2n+1)=(n+1)^2.$$&lt;/p&gt;
&lt;p&gt;This requires a tiny bit of algebraic manipulation, but isn't at all difficult:&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
1+3+5+\dotsc+(2n-1)+(2n+1) &amp;amp;= n^2+(2n+1) \\&lt;br&gt;
&amp;amp;= (n+1)^2.&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;In the first step above, we used our assumption that the sum of the first $n$ odd numbers is $n^2$ and substituted this result into the equation. In the second step, we factored our resulting quadratic, and subsequently showed that our inductive step holds.&lt;/p&gt;
&lt;p&gt;It follows from the principle of mathematical induction that our assertion is true.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This proof is a good indicator of a trend that such proofs tend to follow. If we can show that the base case is true, we can frequently break down the statement for higher numbers into smaller pieces and then use our base case to glue everything back together.&lt;/p&gt;
&lt;p&gt;In my first post on set theory, I stated without proof that De Morgan's Laws extend to arbitrary collections of sets. I still won't prove that in full, but I'll prove something that's nearly as powerful.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; Let $A_1,A_2,\dotsc,A_n\subseteq X$. Then&lt;/p&gt;
&lt;p&gt;$$X-\bigcup\limits_{i=1}^n A_i=\bigcap\limits_{i=1}^n (X-A_i).$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; We proceed by induction on $n$. For our base case, we choose $n=2$. That is, we need to show that&lt;/p&gt;
&lt;p&gt;$$X-(A_1\cup A_2)=(X-A_1)\cap (X-A_2).$$&lt;/p&gt;
&lt;p&gt;But this is just one of De Morgan's Laws, which we already know to be true! So we don't actually have to do any work to establish that the first criterion holds.&lt;/p&gt;
&lt;p&gt;Next, let $n\geq 2$ be a natural number and suppose that&lt;/p&gt;
&lt;p&gt;$$X-\bigcup\limits_{i=1}^n A_i=\bigcap\limits_{i=1}^n (X-A_i).$$&lt;/p&gt;
&lt;p&gt;It is easy to see that&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
X-\bigcup\limits_{i=1}^{n+1}A_i &amp;amp;= X-\left(\bigcup\limits_{i=1}^nA_i\cup A_{n+1}\right) \\&lt;br&gt;
&amp;amp;= \left(X-\bigcup\limits_{i=1}^nA_i\right)\cap (X-A_{n+1}) \\&lt;br&gt;
&amp;amp;= \bigcap\limits_{i=1}^n(X-A_i)\cap(X-A_{n+1}) \\&lt;br&gt;
&amp;amp;= \bigcap\limits_{i=1}^{n+1}(X-A_i).&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;This completes the proof.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Let's look at another example. This is one of my favorites, and it lends itself nicely to a visual representation.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; A $2^n\times 2^n$ checkerboard can be covered by L-shaped tiles, with the exception of one arbitrary square.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Let's break down this statement a little bit first. When we talk about a $2^n\times 2^n$ checkerboard, we are talking about a square board with sides of length $2^n$. So&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$n=1$ corresponds to the $2\times 2$ board,&lt;/li&gt;
&lt;li&gt;$n=2$ corresponds to the $4\times 4$ board,&lt;/li&gt;
&lt;li&gt;$n=3$ corresponds to the $8\times 8$ board, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For instance, here is the $2^3\times 2^3$ checkerboard:&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/2-3_x_2-3_board.svg" alt="2^3 by 2^3 board"&gt;&lt;/p&gt;
&lt;p&gt;By 'L-shaped tile,' we mean a tile comprised of three squares which is shaped sort of like the letter L:&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/L_shaped_tile-1.svg" alt="L-shaped tile"&gt;&lt;/p&gt;
&lt;p&gt;Lastly, when we say that a board can be covered by these tiles with the exception of one arbitrary square, we mean something like this:&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/tiled_4x4_board.svg" alt="tiled 4 by 4 board"&gt;&lt;/p&gt;
&lt;p&gt;It's important to point out that we could have left out &lt;em&gt;any&lt;/em&gt; one square on the board above and still been able to tile the rest of the board. It does not matter which square we choose to exclude; we should still be able to cover the rest of the board. Try playing around with boards of different sizes, leaving one random square empty, and trying to come up with such a tiling. For larger boards, this quickly becomes no easy task.&lt;/p&gt;
&lt;p&gt;Now that we have a better understanding of the problem, it is our goal to show that we can cover any $2^n\times 2^n$ board in this manner, and we will do so by induction on $n$.&lt;/p&gt;
&lt;p&gt;For our base case ($n=1$), we must show that the $2\times 2$ board can be tiled by L-shaped tiles, no matter which square we choose to omit. Since there are only four squares on this board, we can 'brute-force' the base case by demonstrating that with any square ommitted, the rest of the board can be tiled quite trivially using a single L-shaped tile:&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/base_case.svg" alt="base case"&gt;&lt;/p&gt;
&lt;p&gt;We have shown that any $2\times 2$ board can be covered in the desired manner, so the base case has been verified.&lt;/p&gt;
&lt;p&gt;Next we argue the inductive step. We begin with the assumption that for an arbitrary $n\geq 1$, we can cover the $2^n\times 2^n$ checkerboard (with any one arbitrary square omitted) as desired. We must use this information to show that we can then tile the $2^{n+1}\times 2^{n+1}$ board in the same manner.&lt;/p&gt;
&lt;p&gt;Notice that if we are given a $2^{n+1}\times 2^{n+1}$ board, the missing tile will necessarily lie in precisely one of its four quadrants:&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/quadrants.svg" alt="quadrants"&gt;&lt;/p&gt;
&lt;p&gt;But each of these quadrants is actually a $2^n\times 2^n$ board, which we already know can be covered! So one of our quadrants has a missing tile already chosen for us, and the other three quadrants we can cover however we choose. So we do so in the following crafty way:&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/quadrants_tiled.svg" alt="quadrants tiled"&gt;&lt;/p&gt;
&lt;p&gt;We've now covered the entire $2^{n+1}\times 2^{n+1}$ board with the exception of our arbitrary missing square and a nice L-shaped hole in the middle, which we can fill in with a single L-shaped tile, leaving only the chosen square uncovered. We have thus shown that the inductive step holds, completing the proof.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I think that's more than enough for one post, so I'm going to leave it at that. We will be using induction for many of our future proofs, though, so this won't be the last time you'll see it!&lt;/p&gt;
&lt;hr class="footnotes-sep"&gt;
&lt;section class="footnotes"&gt;
&lt;ol class="footnotes-list"&gt;
&lt;li id="fn1" class="footnote-item"&gt;&lt;p&gt;The symbol $:=$ means 'is defined as.' &lt;a href="#fnref1" class="footnote-backref"&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</content:encoded></item><item><title>A First Look at Topological Spaces</title><description>There are also many circumstances in which we care about the shape of a space but couldn't care less about distances. For instance, a famous puzzle that influenced the development of the entire field of topology is the problem of the **Seven Bridges of Königsberg**.</description><link>http://localhost:2368/a-first-look-at-topological-spaces/</link><guid isPermaLink="false">5c6c6452a4e2f60287eae218</guid><dc:creator>Eric Shapiro</dc:creator><pubDate>Fri, 31 Mar 2017 17:01:23 GMT</pubDate><content:encoded>&lt;h3 id="contents"&gt;Contents&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#motivation"&gt;Motivation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#the-definition"&gt;The definition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#examples"&gt;Examples&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="motivationanamemotivation"&gt;Motivation&lt;a name="motivation"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;So far we've put a lot of effort into defining notions of distance, even giving these ideas fancy names. Distance is an important property in many situations, and you probably don't need me telling you this because you think about distances every day.&lt;/p&gt;
&lt;p&gt;However, there are also many circumstances in which we care about the shape of a space but couldn't care less about distances. For instance, a famous puzzle that influenced the development of the entire field of topology is the problem of the &lt;strong&gt;Seven Bridges of Königsberg&lt;/strong&gt;. Basically, the city of Königsberg had two major islands at its center, completely disconnected from the mainland by a river except for seven bridges.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/bridges.svg" alt="bridges of Königsberg"&gt;&lt;/p&gt;
&lt;p&gt;Here is my &lt;em&gt;beautiful&lt;/em&gt; depiction of the scenario. It should be obvious from my exceptional artistic ability, but the blue crud is the river and the grey smudges are the bridges. For a far inferior — though perhaps more descriptive — picture of the problem, I suggest a Google Image search.&lt;/p&gt;
&lt;p&gt;The puzzle is as follows: &lt;strong&gt;Is it possible to walk across every bridge precisely once without getting wet?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Try drawing a couple paths and you'll quickly begin to suspect that the answer is no. This is correct, but proving it is tricky. The solution to a problem like this has nothing whatsoever to do with the distance between bridges. Stretch the river, move the bridges slightly, and the solution remains the same. This indicates that there may be more fundamental properties intrinsic to the space in this puzzle than distance.&lt;/p&gt;
&lt;p&gt;The branch of mathematics called &lt;strong&gt;topology&lt;/strong&gt; is, loosely speaking, the study of the properties of space which remain unaltered by continuous deformations. This probably sounds kind of like poo at this point, but bear with me. Continuous deformations are, intuitively, ways in which we can stretch, bend and move objects but not tear or cut them. As an example, an egg and a pancake are in some sense topologically equivalent, since you can squish an egg down until it becomes sufficiently cake-shaped. You won't even see this idea again for a while, but I find it helps to have some idea of where we're headed in the long run.&lt;/p&gt;
&lt;h3 id="thedefinitionanamethedefinition"&gt;The definition&lt;a name="the-definition"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Before we proceed, let's recall a few of the nice properties I've previously showed are true of open sets in metric spaces:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The empty set and the space itself are open.&lt;/li&gt;
&lt;li&gt;The union of any collection of open sets is open.&lt;/li&gt;
&lt;li&gt;The intersection of any finite collection of open sets is open.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As I mentioned before, we need to trash any definitions we have that mention metrics or distances, so the old definition of open sets in a metric space won't work for the more general topological spaces. What we do instead is kind of neat.&lt;/p&gt;
&lt;p&gt;We define a topology in terms of which sets are open, and these open sets must obey certain properties. Actually, they must obey the properties I just listed! These properties talk about open sets only in terms of set theory, and never mention distance, so we simply demand that all of these properties hold.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; A &lt;strong&gt;topology&lt;/strong&gt; $\cal T$ on a set $X$ is a collection of subsets of $X$ called &lt;strong&gt;open sets&lt;/strong&gt; which satisfy the following properties.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The empty set $\varnothing$ and the set $X$ are in $\cal T$.&lt;/li&gt;
&lt;li&gt;The union of any collection of sets in $\cal T$ is in $\cal T$.&lt;/li&gt;
&lt;li&gt;The intersection of any finite collection of sets in $\cal T$ is in $\cal T$.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;A &lt;strong&gt;topological space&lt;/strong&gt; is a set $X$ together with a topology $\cal T$ on $X$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;As a slight abuse of notation, the set $X$ will usually be referred to as a topological space, and it will go without saying that we're talking about some topology on $X$. This is much the same as when we talk about a set as a metric space and it is implicitly understood to have some distance function.&lt;/p&gt;
&lt;p&gt;This probably all feels a bit anticlimactic. I've been building up to this for a while, and it probably seems like this isn't anything new at all. At first, it might seem odd to define a topological space as a collection of sets that are open, but it's actually fairly natural. Hopefully at the very least you understand why the three properties in the definition are a natural choice. I spent the last two posts trying to get it to feel that way.&lt;/p&gt;
&lt;p&gt;There is a sort of topological analogue to the concept in metric spaces of an open ball centered at a point:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; A &lt;strong&gt;neighborhood&lt;/strong&gt; of a point $x$ in a topological space is an open set containing $x$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;And of course, whenever there are open sets there are also closed sets:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; A subset $U$ of a topological space $X$ is &lt;strong&gt;closed&lt;/strong&gt; in $X$ if its complement, $X-U$, is open.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Notice again that sets in a topological space can be open, closed, both or neither. In every topological space $X$, we have that $\varnothing$ and $X$ are both open and closed. This information is now part of the very definition of open and closed sets!&lt;/p&gt;
&lt;h3 id="examplesanameexamples"&gt;Examples&lt;a name="examples"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I haven't been including terribly many examples so far, so I should probably try to fix that. Most people don't learn too well being relentlessly bombarded by definitions and theorems and not ever having an opportunity to step back and apply what they've just learned.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; Consider the set $X=\{a,b,c\}$ with just three elements. Let's determine whether the following is a valid topology on $X$:&lt;/p&gt;
&lt;p&gt;$${\cal T} = \big\{\varnothing,\{a\}, \{a,b\}, \{a,b,c\}\big\}$$&lt;/p&gt;
&lt;p&gt;Let's look at this topology visually:&lt;/p&gt;
&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2017/04/top-abc-1.svg" alt="example topology"&gt;&lt;/p&gt;
&lt;p&gt;The ellipses in this diagram depict the open sets in the topology. Each ellipse is a subset of all the ellipses that encompass it. The empty set is a subset of every set and is not depicted.&lt;/p&gt;
&lt;p&gt;Even without the picture, it's easy to verify that all the required properties hold and that this is a topology on $X$. If you take the union of any collection of these open sets, you wind up with another open set in the topology. The same is true of &amp;gt; intersections. (We could list out all such unions and intersections, but that would take up too much space.) The empty set and $X$ itself are explicitly listed and so clearly they are open, and thus $\cal T$ is indeed a topology on $X$.&lt;/p&gt;
&lt;p&gt;One last thing: the set $\{b\}$ in this topological space is neither open nor closed, as an example of what I was saying before.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;There are two topologies that we can define right off the bat on any set $X$.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; The &lt;strong&gt;trivial topology&lt;/strong&gt; on $X$ is the set $\{\varnothing, X\}$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; The &lt;strong&gt;discrete topology&lt;/strong&gt; on $X$ is the set $2^X$ of all subsets of $X$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The trivial topology only has two&lt;sup class="footnote-ref"&gt;&lt;a href="#fn1" id="fnref1"&gt;[1]&lt;/a&gt;&lt;/sup&gt; open sets, and it is in a sense the smallest topology we can define because those sets are required to be open by the definition of a topology. On the other hand, every set is open in the discrete topology, so it is in some sense the largest. Let's make rigorous these notions by defining the concepts of coarseness and fineness.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; Given two topologies ${\cal T}_1, {\cal T}_2$ on a set $X$, we say that ${\cal T}_1$ is &lt;strong&gt;coarser&lt;/strong&gt; than ${\cal T}_2$ if ${\cal T}_1\subseteq {\cal T}_2$. That is, every open set in ${\cal T}_1$ is also open in ${\cal T}_2$. Equivalently, we also sometimes say that ${\cal T}_2$ is &lt;strong&gt;finer&lt;/strong&gt; than ${\cal T}_1$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Notice that the trivial topology is always the coarsest topology we can define, and the discrete topology is always the finest. Also notice that there can exist topologies on a set that cannot be compared with each other in this way because it is possible for each topology to contain open sets that are not contained in the other.&lt;/p&gt;
&lt;p&gt;Here's just one more example for now, and this should hopefully feel a lot like the &amp;quot;correct&amp;quot; definition to you. We can still talk about open balls in $\mathbb{R}^n$ purely as the sets $B(x_0,r)=\{x\in\mathbb{R}^n\mid d(x,x_0)&amp;lt; r\}$. We can define a topology using these that is very similar to the standard metric on $\mathbb{R}^n$:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; The &lt;strong&gt;standard topology&lt;/strong&gt; on $\mathbb{R}^n$ is the topology whose nonempty open sets are precisely the unions of open balls in $\mathbb{R}^n$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The last thing I want to mention right now is that our definition of a topological space is broad. So broad, in fact, that many such spaces often behave in ways that are not at all desirable. Very frequently, we will talk about certain &amp;quot;tame&amp;quot; types of topological spaces. For instance, soon I'll introduce you to Hausdorff spaces, which have a number of nice properties that we'd generally expect &amp;quot;space&amp;quot; to have.&lt;/p&gt;
&lt;p&gt;Next time we'll look again at some more properties of metric spaces. Fair warning: the next post is where things will start getting fairly technical, so make sure you're really comfortable with everything I've discussed so far!&lt;/p&gt;
&lt;hr class="footnotes-sep"&gt;
&lt;section class="footnotes"&gt;
&lt;ol class="footnotes-list"&gt;
&lt;li id="fn1" class="footnote-item"&gt;&lt;p&gt;Unless $X=\varnothing$, in which case it only has one and is particularly uninteresting. &lt;a href="#fnref1" class="footnote-backref"&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</content:encoded></item><item><title>Metric Spaces (2)</title><description>Looking back through my first post about metric spaces, it occurred to me that I should probably have emphasized a few things that could be a bit confusing, so let me address those first before pressing forward. </description><link>http://localhost:2368/metric-spaces-2/</link><guid isPermaLink="false">5c6c6452a4e2f60287eae217</guid><dc:creator>Eric Shapiro</dc:creator><pubDate>Fri, 31 Mar 2017 14:42:15 GMT</pubDate><content:encoded>&lt;h3 id="contents"&gt;Contents&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#review-from-previous-post"&gt;Review from previous post&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#open-sets"&gt;Open sets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#closed-sets"&gt;Closed sets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#now-what"&gt;Now what?&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="reviewfrompreviouspostanamereviewfrompreviouspost"&gt;Review from previous post&lt;a name="review-from-previous-post"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Looking back through my first post about metric spaces, it occurred to me that I should probably have emphasized a few things that could be a bit confusing, so let me address those first before pressing forward.&lt;/p&gt;
&lt;p&gt;I briefly mentioned the &lt;strong&gt;standard metric&lt;/strong&gt; on $\mathbb{R}^n$ ($n$-dimensional Euclidean space), but I didn't relate it back to anything concrete. I defined this metric by&lt;/p&gt;
&lt;p&gt;$$d({\bf x},{\bf y})=\sqrt{\sum\limits_{i=1}^n(x_i-y_i)^2},$$&lt;/p&gt;
&lt;p&gt;where ${\bf x},{\bf y}\in\mathbb{R}^n$. For $n=1$, this whole thing collapses down to&lt;/p&gt;
&lt;p&gt;$$d(x,y)=\sqrt{(x-y)^2}=\vert x-y\vert,$$&lt;/p&gt;
&lt;p&gt;where $x,y\in\mathbb{R}$. Thus, the standard metric in one-dimensional Euclidean space is precisely the distance function that motivated the entirety of my last post. Moreover, the open balls $B(x,r)$ in this metric are open intervals of the form $(x-r,x+r)$. I'm sure you can figure out for yourself what the closed balls are.&lt;/p&gt;
&lt;p&gt;For ${\bf x},{\bf y}\in\mathbb{R}^2$, where ${\bf x}=(x_1,x_2)$ and ${\bf y}=(y_1,y_2)$, the standard metric becomes&lt;/p&gt;
&lt;p&gt;$$d({\bf x},{\bf y})=\sqrt{(x_1-y_1)^2+(x_2-y_2)^2}.$$&lt;/p&gt;
&lt;p&gt;This is the distance function we all saw in high school, and it's easy enough to verify that it is, in fact, a metric. However, it's somewhat challenging to show that the standard metric satisfied the properties of a metric for Euclidean spaces of arbitrary dimension, so I won't do that here.&lt;/p&gt;
&lt;p&gt;I also want to be clear that the standard metric isn't even close to the only metric we can define. In fact, we can define the following metric on any set at all:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; Let $X$ be a metric space. The &lt;strong&gt;discrete metric&lt;/strong&gt; on $X$ is specified by&lt;/p&gt;
&lt;p&gt;$$d(a,b)=&lt;br&gt;
\begin{cases}&lt;br&gt;
0 &amp;amp; \text{if } a=b,\\&lt;br&gt;
1 &amp;amp; \text{if } a\neq b&lt;br&gt;
\end{cases}$$&lt;/p&gt;
&lt;p&gt;for $a,b\in X$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It's easy to show that the discrete metric is in fact a metric. Furthermore, we can actually use the discrete metric as a basis to generate an infinite number of metrics on any set! (How?)&lt;/p&gt;
&lt;p&gt;There are less trivial metrics, too. For instance, if $X$ is the set of real-valued functions which are continuous on the closed interval $[a,b]$, then&lt;/p&gt;
&lt;p&gt;$$d(f,g)=\int\limits_0^1\vert f(x)-g(x)\vert\mathrm{d}x,$$&lt;/p&gt;
&lt;p&gt;where $f,g\in X$, is a metric on $X$. If this example is gibberish to you, don't worry. I haven't defined integration, or even continuity, yet. I just wanted to show that there are even meaningful concepts of distance between functions, which is an enticing concept.&lt;/p&gt;
&lt;p&gt;I think that's about all I wanted to clarify from last time. Now we can move on to some more exciting new stuff!&lt;/p&gt;
&lt;h3 id="opensetsanameopensets"&gt;Open sets&lt;a name="open-sets"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;We already defined open sets in the last post, but let's restate that definition here so you don't have to go looking it up:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; A subset $U$ of a metric space $X$ is &lt;strong&gt;open&lt;/strong&gt; in $X$ if for every point $x\in U$ there exists a real number $r&amp;gt;0$ for which the open ball $B(x,r)\subseteq U$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I didn't explicitly say this last time, but this definition for open sets applies only for metric spaces. When we talk about the more general topological spaces, we'll have to throw out this definition (although it will serve to motivate the general definition).&lt;/p&gt;
&lt;p&gt;Now, armed only with this definition and a few notions from set theory, we can already say quite a bit about open sets.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; The union of any collection of open sets in a metric space is open.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Let $X$ denote a metric space and let $I$ be an indexing set such that $A_i\subseteq X$ is an open set for each $i\in I$. Define $U=\bigcup\limits_{i\in I}A_i$.&lt;/p&gt;
&lt;p&gt;If every $A_i$ is empty then $U=\varnothing$, which is open. So if this is the case, then we're done.&lt;/p&gt;
&lt;p&gt;Suppose then that $U\neq\varnothing$. We need to show that for any $x\in U$, there exists a real number $r&amp;gt;0$ for which $B(x,r)\subseteq U$. But this is extremely easy!&lt;/p&gt;
&lt;p&gt;Since $x\in U$, we know from the definition of the union operation that $x\in A_j$ for some $j\in I$. Since $A_j$ is open by assumption, there exists a real number $r_j&amp;gt;0$ such that $B(x,r_j)\subseteq A_j$. Since every point in $A_j$ is also in $U$, choosing $r=r_j$ gives us that $B(x,r)\subseteq U$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is an important property, so never forget it. Also notice that essentially all we had to do in the above proof was notice that, for each point in the union, we already had an open ball that served our purposes.&lt;/p&gt;
&lt;p&gt;Next, let's prove a similar result:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; The intersection of a finite collection of open sets in a metric space is open.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Let $X$ denote a metric space and let $A_1,A_2,\dotsc,A_n\subseteq X$ be open sets for some $n\in\mathbb{N}$. Define $I=\bigcap\limits_{i=1}^n A_i$.&lt;/p&gt;
&lt;p&gt;First, consider the case where the intersection $I$ is empty. If this is true, then we're done since the empty set is open.&lt;/p&gt;
&lt;p&gt;Suppose then that $I\neq\varnothing$. We need to show that for every $x\in I$ there exists some real number $r&amp;gt;0$ for which $B(x,r)\subseteq I$. This time the choice of $r$ isn't quite so obvious, but hopefully my reasoning is clear. (If it isn't, try drawing a picture!)&lt;/p&gt;
&lt;p&gt;Since $x\in I$, the point $x$ is in every set $A_1,A_2,\dotsc,A_n$. Since each of these sets is open, there exist real numbers $r_1,r_2,\dotsc,r_n&amp;gt;0$ such that&lt;/p&gt;
&lt;p&gt;$$B(x,r_1)\subseteq A_1, \\&lt;br&gt;
B(x,r_2)\subseteq A_2, \\&lt;br&gt;
\vdots                  \\&lt;br&gt;
B(x,r_n)\subseteq A_n.$$&lt;/p&gt;
&lt;p&gt;Since there are only a finite number of sets, simply picking the smallest radius, that is, $r=\min\limits_{1\leq i\leq n} r_i$, will ensure that $B(x,r)\subseteq A_i$ for $1\leq i\leq n$. It follows immediately that $B(x,r)\subseteq I$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Hopefully you're wondering why I only argued that a &lt;em&gt;finite&lt;/em&gt; intersection of open sets is open. After all, I showed that an infinite union work, and unions and intersections are pretty similar, right? Well, not really. In fact, I can easily come up with an example of an infinite collection of open sets whose intersection isn't open:&lt;/p&gt;
&lt;p&gt;Consider $\mathbb{R}$ equipped with the standard metric, and the infinite collection of open intervals defined by $A_n=\left(-\frac{1}{n},\frac{1}{n}\right)$ for $n\in\mathbb{N}$. It's easy enough to see that $\bigcap\limits_{n=1}^\infty \left(-\frac{1}{n},\frac{1}{n}\right)=\{0\}$. For any $x&amp;gt;0$, the quantity $\frac{1}{n}$ eventually becomes smaller than $x$ as $n$ grows larger, so the only point common to all these sets is $0$ because $\frac{1}{n}\neq 0$ for any $n\in\mathbb{N}$, no matter how large.&lt;sup class="footnote-ref"&gt;&lt;a href="#fn1" id="fnref1"&gt;[1]&lt;/a&gt;&lt;/sup&gt; The set $\{0\}$ is not open because no open ball of positive radius is contained within it.&lt;/p&gt;
&lt;h3 id="closedsetsanameclosedsets"&gt;Closed sets&lt;a name="closed-sets"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Again, we defined closed sets last time, but we'll restate their definition here as well for convenience:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition.&lt;/strong&gt; A subset $U$ of a metric space $X$ is &lt;strong&gt;closed&lt;/strong&gt; in $X$ if its complement, $X-U$, is open in $X$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Let's pause for a second to think about what this means in terms of open balls. This definition tells us that $U$ is closed when any point that it not in $U$ is at the center of some open ball which is disjoint from $U$. This is the concept we used in the last post to prove that a closed ball was closed.&lt;/p&gt;
&lt;p&gt;Now we're going to prove two theorems about closed sets that closely mirror the theorems about open sets that we just proved above. Rather than go through a similar process of trying to find a radius which works, we'll make use of the previous results and apply De Morgan's Laws.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; The union of a finite collection of closed sets in a metric space is closed.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Let $X$ denote a metric space and let $A_1,A_2,\dotsc,A_n\subseteq X$ be closed sets for some $n\in\mathbb{N}$. From the definition of a closed set we see immediately that their complements, $X-A_1$, $X-A_2$, $\dotsc$, $X-A_n$ are each open. Since the intersection of a finite number of open sets is open,&lt;/p&gt;
&lt;p&gt;$$\bigcap\limits_{i=1}^n (X-A_i)=X-\bigcup\limits_{i=1}^n A_i$$&lt;/p&gt;
&lt;p&gt;is open by De Morgan's Laws. Since the complement of an open set is closed, we have that $\bigcup\limits_{i=1}^n A_i$ is closed, and we are done.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Hopefully by now you can see the next theorem coming from a mile away, simply from the symmetry of things. I'll prove it anyway for completeness.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; The intersection of any collection of closed sets in a metric space is closed.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt; Let $X$ denote a metric space and let $I$ be an indexing set such that $A_i\subseteq X$ is a closed set for each $i\in I$. Then the complement of each set, $X-A_i$, is open for every $i\in I$. Since the union of an arbitrary collection of open sets is open,&lt;/p&gt;
&lt;p&gt;$$\bigcup\limits_{i\in I} (X-A_i)=X-\bigcap\limits_{i\in I}A_i$$&lt;/p&gt;
&lt;p&gt;is open by De Morgan's Laws. Therefore its complement, $\bigcap\limits_{i\in I}A_i$, is closed, completing the proof.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id="nowwhatanamenowwhat"&gt;Now what?&lt;a name="now-what"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;What's fairly awesome is that we now actually know everything we need to know about open and closed sets. Well, not really. But we &lt;em&gt;do&lt;/em&gt; know enough now to take another leap forward and define a &lt;strong&gt;topology&lt;/strong&gt; on a set! I'm not going to do that right now, though. Instead I'm going to show you that everything we've done so far is really perfectly natural, in that it gives us the results we'd expect when talking about familiar sets.&lt;/p&gt;
&lt;p&gt;Let's first look at the set of real numbers. To be formal, I'm talking about $\mathbb{R}$ equipped with the standard metric $d(x,y)=\vert x-y\vert$. I think I said this earlier, but unless I say otherwise you should always assume that I'm talking about the standard metric whenever I say words about the real numbers. I asserted above that the open balls in this metric space are open intervals. That is,&lt;/p&gt;
&lt;p&gt;$$\begin{align}&lt;br&gt;
B(x,r) &amp;amp;= \{x\in\mathbb{R}\mid d(x,y)&amp;lt; r\} \\&lt;br&gt;
&amp;amp;= (x-r,x+r).&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;What are the simplest open sets in this metric space? We'll talk about this in a more formal sense when we discuss bases for topologies, but it turns out that in a very real sense, these open intervals are the fundamental building blocks for all open sets on the real number line. That is, any nonempty open set in $\mathbb{R}$ can actually be written as the union of some collection of open intervals!&lt;/p&gt;
&lt;p&gt;This may seem obvious, but it's actually a very nice property. I'll give you a hand-wavy reason why it's true. The definition of an open set is that every point in the set is at the center of some open ball which is, in turn, contained entirely in the set. So if we take any open set and union together the largest such open balls centered at each point, we really ought to get our entire open set!&lt;/p&gt;
&lt;p&gt;In the plane, $\mathbb{R}^2$ or $\mathbb{C}$, the same is true. However, we're now talking about the standard metric in two dimensions, so open balls look like open disks instead of open line segments. Nonempty open sets in the plane can all be formed by joining together these open balls. Even open &lt;em&gt;rectangles&lt;/em&gt; can be expressed as unions of open balls.&lt;/p&gt;
&lt;p&gt;An &lt;strong&gt;open rectangle&lt;/strong&gt; is the Cartesian product of two open intervals, say $(a,b)\times(c,d)$. The proof that they are open is similar to the proof that open balls are open, and it is not particularly informative so I won't include it . here. But I think it's pretty neat that even the &lt;em&gt;corners&lt;/em&gt; of these rectangles can be expressed as the union of a bunch of sufficiently small open balls. What might be even more interesting is that open rectangles can alternatively be thought as the primitive open sets in the plane, and you can get any open set by unioning rectangles together. That includes open balls!&lt;/p&gt;
&lt;p&gt;In my next post I'll finally define topological spaces. It will likely be fairly short, since we don't have much to say about them yet, but it will at least give you a sense of what we'll be working with from here on out. From then on, I'll probably alternate between metric spaces and topological spaces. It's usually easiest to introduce topological concepts such as convergence, continuity, connectedness and compactness in terms of metric spaces first, and then take what we need from those definitions to talk about them in the more general setting of topological spaces.&lt;/p&gt;
&lt;hr class="footnotes-sep"&gt;
&lt;section class="footnotes"&gt;
&lt;ol class="footnotes-list"&gt;
&lt;li id="fn1" class="footnote-item"&gt;&lt;p&gt;Technically I should have used the Archimedian property of the real numbers to show this, but it's extremely obvious and not particularly necessary for any of our other purposes. After all, this isn't a post about analysis or the foundations of the real number system. &lt;a href="#fnref1" class="footnote-backref"&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</content:encoded></item></channel></rss>